config= {'b_value': 5.0, 'c_value': 1.0, 'd_value': 0.0, 'n_agents': 2, 'algorithm': 'dqn', 'wandb_mode': 'offline', 'num_game_iterations': 10, 'n_epochs': 2000, 'obs_size': 4, 'action_size': 2, 'random_baseline': False, 'embedding_dim': 1, 'binary_reputation': 1, 'other_reputation_threshold': 0.4, 'cooperation_threshold': 0.4, 'optuna_': 0, 'device': 'cpu', 'reputation_in_reward': 0, 'memory_size': 500, 'n_hidden_act': 2, 'hidden_size_act': 16, 'batch_size': 128, 'lr_actor': 0.01, 'decayRate': 0.999}
DD= tensor(1.)
Dc= tensor(6.)
Cd= tensor(0.)
CC= tensor(5.)
mv= tensor(6.)
mat= tensor([[1., 6.],
        [0., 5.]])
norm mat= tensor([[0.1667, 1.0000],
        [0.0000, 0.8333]])
is_dummy= [0, 0]
==========>Epoch= 0
epsilon= 0.5
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 0
frame= 0
actions= {'agent_0': tensor(0), 'agent_1': tensor(1)}
frame= 0
frame= 0
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 0
frame= 0
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 0
frame= 0
actions= {'agent_0': tensor(0), 'agent_1': tensor(1)}
frame= 0
frame= 0
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 0
frame= 0
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 0
frame= 0
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 0
frame= 0
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 0
frame= 0
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 0
frame= 0
Epoch : 0 	 Measure: 0
==========>Epoch= 1
epsilon= 0.49950034986670416
actions= {'agent_0': tensor(0), 'agent_1': tensor(1)}
frame= 0
frame= 0
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 1
frame= 1
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 2
frame= 2
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 3
frame= 3
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 4
frame= 4
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 5
frame= 5
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 6
frame= 6
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 7
frame= 7
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 8
frame= 8
actions= {'agent_0': tensor(0), 'agent_1': tensor(1)}
frame= 9
frame= 9
==========>Epoch= 2
epsilon= 0.4990011991337998
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 0
frame= 0
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 2
frame= 2
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 4
frame= 4
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 6
frame= 6
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 8
frame= 8
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 10
frame= 10
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 12
frame= 12
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 14
frame= 14
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 16
frame= 16
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 18
frame= 18
==========>Epoch= 3
epsilon= 0.49850254730213617
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 0
frame= 0
actions= {'agent_0': tensor(0), 'agent_1': tensor(1)}
frame= 3
frame= 3
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 6
frame= 6
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 9
frame= 9
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 12
frame= 12
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 15
frame= 15
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 18
frame= 18
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 21
frame= 21
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 24
frame= 24
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 27
frame= 27
==========>Epoch= 4
epsilon= 0.49800439387306134
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 0
frame= 0
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 4
frame= 4
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 8
frame= 8
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 12
frame= 12
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 16
frame= 16
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 20
frame= 20
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 24
frame= 24
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 28
frame= 28
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 32
frame= 32
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 36
frame= 36
==========>Epoch= 5
epsilon= 0.4975067383484219
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 0
frame= 0
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 5
frame= 5
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 10
frame= 10
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 15
frame= 15
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 20
frame= 20
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 25
frame= 25
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 30
frame= 30
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 35
frame= 35
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 40
frame= 40
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 45
frame= 45
==========>Epoch= 6
epsilon= 0.49700958023056224
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 0
frame= 0
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 6
frame= 6
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 12
frame= 12
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 18
frame= 18
actions= {'agent_0': tensor(0), 'agent_1': tensor(1)}
frame= 24
frame= 24
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 30
frame= 30
actions= {'agent_0': tensor(0), 'agent_1': tensor(1)}
frame= 36
frame= 36
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 42
frame= 42
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 48
frame= 48
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 54
frame= 54
==========>Epoch= 7
epsilon= 0.49651291902232425
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 0
frame= 0
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 7
frame= 7
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 14
frame= 14
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 21
frame= 21
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 28
frame= 28
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 35
frame= 35
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 42
frame= 42
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 49
frame= 49
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 56
frame= 56
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 63
frame= 63
==========>Epoch= 8
epsilon= 0.4960167542270466
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 0
frame= 0
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 8
frame= 8
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 16
frame= 16
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 24
frame= 24
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 32
frame= 32
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 40
frame= 40
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 48
frame= 48
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 56
frame= 56
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 64
frame= 64
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 72
frame= 72
==========>Epoch= 9
epsilon= 0.49552108534856454
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 0
frame= 0
actions= {'agent_0': tensor(0), 'agent_1': tensor(1)}
frame= 9
frame= 9
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 18
frame= 18
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 27
frame= 27
actions= {'agent_0': tensor(0), 'agent_1': tensor(1)}
frame= 36
frame= 36
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 45
frame= 45
actions= {'agent_0': tensor(0), 'agent_1': tensor(0)}
frame= 54
frame= 54
actions= {'agent_0': tensor(1), 'agent_1': tensor(1)}
frame= 63
frame= 63
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 72
frame= 72
actions= {'agent_0': tensor(1), 'agent_1': tensor(0)}
frame= 81
frame= 81
==========>Epoch= 10
epsilon= 0.49502591189120915
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 0
frame= 0
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 10
frame= 10
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 20
frame= 20
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 30
frame= 30
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 40
frame= 40
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 50
frame= 50
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 60
frame= 60
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 70
frame= 70
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 80
frame= 80
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 90
frame= 90
Epoch : 10 	 Measure: 0
==========>Epoch= 11
epsilon= 0.4945312333598068
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 0
frame= 0
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 11
frame= 11
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 22
frame= 22
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 33
frame= 33
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 44
frame= 44
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 55
frame= 55
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 66
frame= 66
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 77
frame= 77
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 88
frame= 88
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 99
frame= 99
==========>Epoch= 12
epsilon= 0.49403704925967906
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 0
frame= 0
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 12
frame= 12
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 24
frame= 24
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 36
frame= 36
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 48
frame= 48
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 60
frame= 60
actions= {'agent_1': tensor(0), 'agent_0': tensor(0)}
frame= 72
frame= 72
actions= {'agent_1': tensor(1), 'agent_0': tensor(0)}
frame= 84
frame= 84
actions= {'agent_1': tensor(0), 'agent_0': tensor(1)}
frame= 96
frame= 96
actions= {'agent_1': tensor(1), 'agent_0': tensor(1)}
frame= 108
===>UPDATING!
batch state= (tensor([1., 0., 0., 0.]), tensor([1., 0., 1., 0.]), tensor([1., 0., 1., 1.]), tensor([1., 1., 0., 0.]), tensor([0., 0., 0., 0.]), tensor([0., 0., 0., 0.]), tensor([0., 1., 1., 0.]), tensor([0., 0., 1., 1.]), tensor([1., 1., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 1., 0., 0.]), tensor([0., 1., 1., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 1., 0., 1.]), tensor([0., 0., 1., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 0., 0., 1.]), tensor([0., 1., 0., 1.]), tensor([1., 1., 1., 0.]), tensor([1., 1., 1., 1.]), tensor([0., 0., 1., 0.]), tensor([1., 0., 0., 1.]), tensor([0., 1., 0., 0.]), tensor([1., 1., 0., 1.]), tensor([1., 0., 0., 1.]), tensor([1., 0., 0., 1.]), tensor([1., 0., 0., 0.]), tensor([0., 0., 1., 1.]), tensor([0., 0., 1., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 1., 1., 1.]), tensor([1., 1., 1., 1.]), tensor([0., 1., 1., 0.]), tensor([1., 1., 1., 1.]), tensor([0., 1., 1., 1.]), tensor([0., 0., 1., 1.]), tensor([1., 0., 0., 1.]), tensor([1., 1., 1., 1.]), tensor([0., 1., 1., 1.]), tensor([0., 1., 1., 1.]), tensor([0., 0., 1., 0.]), tensor([1., 1., 1., 1.]), tensor([1., 1., 0., 1.]), tensor([0., 1., 0., 1.]), tensor([0., 0., 0., 0.]), tensor([1., 0., 1., 0.]), tensor([1., 1., 0., 1.]), tensor([0., 0., 0., 0.]), tensor([1., 1., 1., 0.]), tensor([0., 1., 1., 1.]), tensor([1., 0., 1., 1.]), tensor([1., 0., 0., 0.]), tensor([0., 0., 1., 1.]), tensor([1., 0., 0., 1.]), tensor([1., 0., 1., 0.]), tensor([1., 1., 0., 1.]), tensor([0., 1., 0., 0.]), tensor([1., 1., 1., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 1., 0., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 1., 1., 0.]), tensor([0., 0., 0., 1.]), tensor([1., 1., 0., 0.]), tensor([0., 1., 1., 0.]), tensor([1., 1., 1., 0.]), tensor([1., 0., 1., 1.]), tensor([1., 1., 0., 1.]), tensor([1., 1., 0., 0.]), tensor([0., 1., 0., 1.]), tensor([0., 1., 0., 1.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([1., 1., 0., 1.]), tensor([1., 0., 1., 1.]), tensor([1., 0., 0., 0.]), tensor([0., 1., 1., 0.]), tensor([0., 0., 0., 1.]), tensor([1., 0., 1., 0.]), tensor([1., 1., 1., 1.]), tensor([1., 1., 0., 0.]), tensor([1., 0., 0., 1.]), tensor([0., 1., 1., 0.]), tensor([0., 1., 0., 1.]), tensor([1., 0., 1., 1.]), tensor([0., 1., 1., 1.]), tensor([1., 0., 0., 0.]), tensor([0., 1., 1., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 0., 1., 1.]), tensor([0., 1., 0., 0.]), tensor([1., 0., 1., 0.]), tensor([1., 1., 1., 0.]), tensor([1., 1., 1., 0.]), tensor([1., 1., 0., 1.]), tensor([0., 0., 0., 0.]), tensor([0., 0., 0., 0.]), tensor([0., 0., 1., 0.]), tensor([1., 0., 1., 1.]), tensor([1., 0., 1., 1.]), tensor([0., 1., 1., 1.]), tensor([1., 1., 0., 1.]), tensor([1., 0., 1., 1.]), tensor([0., 1., 1., 0.]), tensor([0., 0., 1., 1.]), tensor([0., 0., 1., 0.]), tensor([1., 0., 1., 0.]), tensor([1., 0., 1., 0.]), tensor([0., 0., 0., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 0., 0.]), tensor([0., 0., 1., 1.]), tensor([1., 0., 0., 1.]), tensor([0., 0., 0., 0.]), tensor([0., 0., 0., 1.]), tensor([1., 1., 1., 1.]), tensor([1., 1., 1., 1.]), tensor([1., 0., 1., 1.]), tensor([0., 1., 1., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 1., 1.]), tensor([1., 1., 1., 0.]), tensor([1., 1., 1., 0.]), tensor([1., 0., 0., 0.]), tensor([0., 0., 0., 1.]), tensor([1., 1., 1., 1.]), tensor([1., 1., 1., 0.]), tensor([1., 1., 1., 0.]))
Traceback (most recent call last):
  File "caller.py", line 61, in <module>
    train_dqn(args)
  File "/home/nicole/marl-emecom/src/experiments_anastassacos/train_dqn.py", line 207, in train_dqn
    objective(args, repo_name)
  File "/home/nicole/marl-emecom/src/experiments_anastassacos/train_dqn.py", line 110, in objective
    agent.update(states[ag_idx], actions[ag_idx], rewards[ag_idx], next_states[ag_idx], i*epoch)
  File "/home/nicole/marl-emecom/src/algos/anast/DQN_anast.py", line 148, in update
    batch_vars = self.prep_minibatch()
  File "/home/nicole/marl-emecom/src/algos/anast/DQN_anast.py", line 100, in prep_minibatch
    batch_state = torch.tensor(batch_state, device=self.device, dtype=torch.float)#.view(-1)
ValueError: only one element tensors can be converted to Python scalars