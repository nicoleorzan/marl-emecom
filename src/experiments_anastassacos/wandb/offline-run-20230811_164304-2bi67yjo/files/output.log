config= {'b_value': 5.0, 'c_value': 1.0, 'd_value': 0.0, 'n_agents': 2, 'algorithm': 'reinforce', 'wandb_mode': 'offline', 'num_game_iterations': 10, 'n_epochs': 2000, 'obs_size': 4, 'action_size': 2, 'random_baseline': False, 'embedding_dim': 1, 'binary_reputation': 1, 'other_reputation_threshold': 0.4, 'cooperation_threshold': 0.4, 'optuna_': 0, 'device': 'cpu', 'reputation_in_reward': 0, 'lr_actor': 0.01, 'n_hidden_act': 2, 'hidden_size_act': 16, 'batch_size': 1, 'decayRate': 0.999}
DD= tensor(1.)
Dc= tensor(6.)
Cd= tensor(0.)
CC= tensor(5.)
mv= tensor(6.)
mat= tensor([[1., 6.],
        [0., 5.]])
norm mat= tensor([[0.1667, 1.0000],
        [0.0000, 0.8333]])
is_dummy= [0, 0]
Agent 0
Agent 1
==========>Epoch= 0
 action, distrib= tensor(0) tensor([0.4041, 0.5959], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5449, 0.4551], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5568, 0.4432], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4160, 0.5840], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.6192, 0.3808], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4041, 0.5959], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5449, 0.4551], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4041, 0.5959], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5667, 0.4333], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4687, 0.5313], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.6028, 0.3972], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4056, 0.5944], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5771, 0.4229], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4664, 0.5336], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.6289, 0.3711], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4459, 0.5541], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5102, 0.4898], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4459, 0.5541], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5102, 0.4898], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(30.3434), 'agent_0': tensor(42.3981)}
Epoch : 0 	 Measure: nan
==========>Epoch= 1
 action, distrib= tensor(0) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4697, 0.5303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5321, 0.4679], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4835, 0.5165], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5528, 0.4472], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4720, 0.5280], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4571, 0.5429], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4849, 0.5151], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5174, 0.4826], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4847, 0.5153], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5791, 0.4209], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4592, 0.5408], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4746, 0.5254], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4678, 0.5322], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4871, 0.5129], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4639, 0.5361], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5665, 0.4335], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4926, 0.5074], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5438, 0.4562], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(33.3035), 'agent_0': tensor(27.6022)}
==========>Epoch= 2
 action, distrib= tensor(0) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4514, 0.5486], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5127, 0.4873], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4999, 0.5001], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5263, 0.4737], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.5359, 0.4641], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5175, 0.4825], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.5123, 0.4877], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5382, 0.4618], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4518, 0.5482], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4999, 0.5001], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5263, 0.4737], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.5459, 0.4541], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5122, 0.4878], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.5459, 0.4541], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5122, 0.4878], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.5378, 0.4622], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5005, 0.4995], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(13.4655), 'agent_1': tensor(36.4126)}
==========>Epoch= 3
 action, distrib= tensor(1) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4589, 0.5411], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5234, 0.4766], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4831, 0.5169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5043, 0.4957], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4549, 0.5451], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4993, 0.5007], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.5066, 0.4934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5265, 0.4735], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.5399, 0.4601], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4926, 0.5074], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4825, 0.5175], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5054, 0.4946], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.5129, 0.4871], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5212, 0.4788], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(22.9465), 'agent_1': tensor(34.4223)}
==========>Epoch= 4
 action, distrib= tensor(1) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4525, 0.5475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5057, 0.4943], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4732, 0.5268], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4966, 0.5034], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4525, 0.5475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5057, 0.4943], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4949, 0.5051], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4721, 0.5279], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4807, 0.5193], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.5300, 0.4700], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4813, 0.5187], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4487, 0.5513], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4952, 0.5048], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4949, 0.5051], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(28.4476), 'agent_1': tensor(28.8459)}
==========>Epoch= 5
 action, distrib= tensor(0) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.5130, 0.4870], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4802, 0.5198], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4702, 0.5298], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5067, 0.4933], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4311, 0.5689], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4837, 0.5163], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4689, 0.5311], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4827, 0.5173], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4982, 0.5018], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4917, 0.5083], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4282, 0.5718], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5027, 0.4973], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4982, 0.5018], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4917, 0.5083], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4311, 0.5689], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4837, 0.5163], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(19.0963), 'agent_1': tensor(30.3975)}
==========>Epoch= 6
 action, distrib= tensor(1) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.5084, 0.4916], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4543, 0.5457], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4999, 0.5001], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4432, 0.5568], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4865, 0.5135], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4351, 0.5649], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4878, 0.5122], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4821, 0.5179], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4936, 0.5064], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4680, 0.5320], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4936, 0.5064], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4680, 0.5320], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.5046, 0.4954], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4185, 0.5815], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(48.8287), 'agent_0': tensor(19.8863)}
==========>Epoch= 7
 action, distrib= tensor(0) tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4915, 0.5085], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3868, 0.6132], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4692, 0.5308], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4881, 0.5119], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4839, 0.5161], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4136, 0.5864], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4923, 0.5077], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4172, 0.5828], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4923, 0.5077], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4172, 0.5828], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4723, 0.5277], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4552, 0.5448], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4957, 0.5043], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4009, 0.5991], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4786, 0.5214], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5047, 0.4953], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4832, 0.5168], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4381, 0.5619], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(22.9200), 'agent_0': tensor(34.1048)}
==========>Epoch= 8
 action, distrib= tensor(1) tensor([0.4855, 0.5145], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4074, 0.5926], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4878, 0.5122], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4020, 0.5980], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4950, 0.5050], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4257, 0.5743], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4769, 0.5231], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4536, 0.5464], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4719, 0.5281], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4719, 0.5281], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4808, 0.5192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3842, 0.6158], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4878, 0.5122], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4020, 0.5980], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4837, 0.5163], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4775, 0.5225], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4785, 0.5215], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4410, 0.5590], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(31.3868), 'agent_0': tensor(36.9781)}
==========>Epoch= 9
 action, distrib= tensor(0) tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3697, 0.6303], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4860, 0.5140], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3895, 0.6105], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4914, 0.5086], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4614, 0.5386], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4703, 0.5297], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4031, 0.5969], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4668, 0.5332], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4478, 0.5522], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4914, 0.5086], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4614, 0.5386], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4830, 0.5170], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4287, 0.5713], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4791, 0.5209], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4289, 0.5711], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4830, 0.5170], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4287, 0.5713], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4687, 0.5313], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4031, 0.5969], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(47.6259), 'agent_0': tensor(24.9642)}
==========>Epoch= 10
 action, distrib= tensor(1) tensor([0.3650, 0.6350], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3863, 0.6137], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5048, 0.4952], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4048, 0.5952], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4913, 0.5087], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4088, 0.5912], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4813, 0.5187], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4411, 0.5589], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5029, 0.4971], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3642, 0.6358], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4844, 0.5156], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4048, 0.5952], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4913, 0.5087], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3642, 0.6358], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4844, 0.5156], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3863, 0.6137], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5048, 0.4952], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4088, 0.5912], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4813, 0.5187], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(33.7026), 'agent_1': tensor(27.4790)}
Epoch : 10 	 Measure: nan
==========>Epoch= 11
 action, distrib= tensor(1) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3448, 0.6552], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3842, 0.6158], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5086, 0.4914], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3216, 0.6784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4826, 0.5174], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3601, 0.6399], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4744, 0.5256], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3917, 0.6083], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4988, 0.5012], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3216, 0.6784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4826, 0.5174], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3842, 0.6158], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5086, 0.4914], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3917, 0.6083], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4988, 0.5012], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(22.7465), 'agent_1': tensor(34.2783)}
==========>Epoch= 12
 action, distrib= tensor(1) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3242, 0.6758], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5173, 0.4827], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3218, 0.6782], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4986, 0.5014], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3492, 0.6508], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5310, 0.4690], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3762, 0.6238], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4948, 0.5052], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.2993, 0.7007], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4873, 0.5127], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3533, 0.6467], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4532, 0.5468], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3492, 0.6508], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5310, 0.4690], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4059, 0.5941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4682, 0.5318], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4067, 0.5933], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5328, 0.4672], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(23.8857), 'agent_1': tensor(29.7169)}
==========>Epoch= 13
 action, distrib= tensor(0) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4524, 0.5476], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3260, 0.6740], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4388, 0.5612], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2869, 0.7131], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4964, 0.5036], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3015, 0.6985], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4787, 0.5213], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3176, 0.6824], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.5410, 0.4590], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3821, 0.6179], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.5069, 0.4931], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3398, 0.6602], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.5069, 0.4931], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3398, 0.6602], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(53.5080), 'agent_0': tensor(19.3138)}
==========>Epoch= 14
 action, distrib= tensor(0) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.5195, 0.4805], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2947, 0.7053], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4500, 0.5500], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3150, 0.6850], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4324, 0.5676], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2776, 0.7224], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4787, 0.5213], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2648, 0.7352], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4896, 0.5104], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2836, 0.7164], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4764, 0.5236], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3121, 0.6879], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.5329, 0.4671], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3172, 0.6828], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.5067, 0.4933], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3266, 0.6734], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4964, 0.5036], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2924, 0.7076], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(33.1723), 'agent_0': tensor(27.8083)}
==========>Epoch= 15
 action, distrib= tensor(1) tensor([0.3066, 0.6934], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5107, 0.4893], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3244, 0.6756], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5268, 0.4732], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3273, 0.6727], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4984, 0.5016], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3431, 0.6569], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5300, 0.4700], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3244, 0.6756], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5268, 0.4732], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3273, 0.6727], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4984, 0.5016], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.2985, 0.7015], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4852, 0.5148], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3789, 0.6211], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5428, 0.4572], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3652, 0.6348], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4898, 0.5102], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3200, 0.6800], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4672, 0.5328], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(29.6883), 'agent_1': tensor(46.6331)}
==========>Epoch= 16
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2669, 0.7331], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4544, 0.5456], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3210, 0.6790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5283, 0.4717], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3468, 0.6532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4468, 0.5532], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3395, 0.6605], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5293, 0.4707], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3210, 0.6790], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5283, 0.4717], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3186, 0.6814], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4922, 0.5078], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3186, 0.6814], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4922, 0.5078], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3572, 0.6428], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4867, 0.5133], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(27.6122), 'agent_1': tensor(33.6751)}
==========>Epoch= 17
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.5024, 0.4976], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3028, 0.6972], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4117, 0.5883], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2833, 0.7167], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4791, 0.5209], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3341, 0.6659], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.5274, 0.4726], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3177, 0.6823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.5024, 0.4976], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3028, 0.6972], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(35.8079), 'agent_0': tensor(17.8703)}
==========>Epoch= 18
 action, distrib= tensor(1) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3167, 0.6833], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.5222, 0.4778], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3034, 0.6966], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4901, 0.5099], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2764, 0.7236], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3983, 0.6017], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3034, 0.6966], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4901, 0.5099], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2585, 0.7415], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4206, 0.5794], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2582, 0.7418], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3734, 0.6266], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3034, 0.6966], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4901, 0.5099], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3679, 0.6321], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5427, 0.4573], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3038, 0.6962], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4745, 0.5255], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(33.4903), 'agent_1': tensor(27.8397)}
==========>Epoch= 19
 action, distrib= tensor(1) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2613, 0.7387], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3974, 0.6026], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3093, 0.6907], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4693, 0.5307], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3712, 0.6288], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.5301, 0.4699], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3042, 0.6958], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4574, 0.5426], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3415, 0.6585], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4973, 0.5027], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3093, 0.6907], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4693, 0.5307], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3483, 0.6517], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4526, 0.5474], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3209, 0.6791], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4090, 0.5910], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3093, 0.6907], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4693, 0.5307], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(27.0012), 'agent_1': tensor(38.1347)}
==========>Epoch= 20
 action, distrib= tensor(1) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2528, 0.7472], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3826, 0.6174], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2618, 0.7382], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4161, 0.5839], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3006, 0.6994], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4131, 0.5869], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3150, 0.6850], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4940, 0.5060], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.2965, 0.7035], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4451, 0.5549], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.2965, 0.7035], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4451, 0.5549], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.2782, 0.7218], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3677, 0.6323], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2746, 0.7254], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4098, 0.5902], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(27.8898), 'agent_1': tensor(33.2515)}
Epoch : 20 	 Measure: nan
==========>Epoch= 21
 action, distrib= tensor(0) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4373, 0.5627], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2960, 0.7040], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4329, 0.5671], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3357, 0.6643], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4726, 0.5274], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3815, 0.6185], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.5099, 0.4901], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3613, 0.6387], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3610, 0.6390], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3530, 0.6470], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2721, 0.7279], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3610, 0.6390], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3970, 0.6030], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2563, 0.7437], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3296, 0.6704], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2438, 0.7562], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(40.2674), 'agent_0': tensor(40.3233)}
==========>Epoch= 22
 action, distrib= tensor(1) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2468, 0.7532], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3525, 0.6475], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2561, 0.7439], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3845, 0.6155], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3206, 0.6794], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4318, 0.5682], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3206, 0.6794], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4318, 0.5682], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2974, 0.7026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4301, 0.5699], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2608, 0.7392], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3503, 0.6497], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2974, 0.7026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4301, 0.5699], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.2974, 0.7026], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4301, 0.5699], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2703, 0.7297], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3493, 0.6507], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(35.4918), 'agent_1': tensor(40.9076)}
==========>Epoch= 23
 action, distrib= tensor(0) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2496, 0.7504], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3361, 0.6639], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2644, 0.7356], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3362, 0.6638], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2966, 0.7034], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3889, 0.6111], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2596, 0.7404], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3671, 0.6329], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.2496, 0.7504], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3361, 0.6639], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2698, 0.7302], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3653, 0.6347], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.2984, 0.7016], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2698, 0.7302], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3653, 0.6347], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2457, 0.7543], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3139, 0.6861], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(22.6850), 'agent_1': tensor(34.3857)}
==========>Epoch= 24
 action, distrib= tensor(0) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3106, 0.6894], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4540, 0.5460], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3853, 0.6147], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4864, 0.5136], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3695, 0.6305], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3131, 0.6869], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2636, 0.7364], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4540, 0.5460], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3853, 0.6147], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4159, 0.5841], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3432, 0.6568], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3150, 0.6850], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2756, 0.7244], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3131, 0.6869], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2636, 0.7364], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4456, 0.5544], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3392, 0.6608], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(41.9565), 'agent_0': tensor(30.7158)}
==========>Epoch= 25
 action, distrib= tensor(0) tensor([0.2808, 0.7192], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2934, 0.7066], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2878, 0.7122], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3253, 0.6747], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3204, 0.6796], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3589, 0.6411], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3354, 0.6646], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4345, 0.5655], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3777, 0.6223], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4862, 0.5138], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3354, 0.6646], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4345, 0.5655], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.2878, 0.7122], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3253, 0.6747], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3318, 0.6682], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3506, 0.6494], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4435, 0.5565], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2988, 0.7012], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3318, 0.6682], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(37.4869), 'agent_1': tensor(31.6028)}
==========>Epoch= 26
 action, distrib= tensor(0) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4221, 0.5779], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3506, 0.6494], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.4383, 0.5617], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3659, 0.6341], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2672, 0.7328], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3085, 0.6915], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3758, 0.6242], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3440, 0.6560], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3101, 0.6899], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3449, 0.6551], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.2993, 0.7007], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3084, 0.6916], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4028, 0.5972], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3658, 0.6342], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4221, 0.5779], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3506, 0.6494], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(42.1221), 'agent_0': tensor(30.5868)}
==========>Epoch= 27
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2432, 0.7568], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3591, 0.6409], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3585, 0.6415], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3379, 0.6621], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2889, 0.7111], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3511, 0.6489], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3241, 0.6759], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3508, 0.6492], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3280, 0.6720], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3627, 0.6373], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4054, 0.5946], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3511, 0.6489], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3241, 0.6759], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(43.9181), 'agent_1': tensor(43.9763)}
==========>Epoch= 28
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3438, 0.6562], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3592, 0.6408], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4740, 0.5260], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3949, 0.6051], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.4740, 0.5260], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3949, 0.6051], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2411, 0.7589], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3367, 0.6633], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2216, 0.7784], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3268, 0.6732], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(25.8873), 'agent_0': tensor(43.2450)}
==========>Epoch= 29
 action, distrib= tensor(0) tensor([0.3783, 0.6217], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3559, 0.6441], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2270, 0.7730], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3238, 0.6762], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.4148, 0.5852], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3687, 0.6313], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2270, 0.7730], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3238, 0.6762], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3278, 0.6722], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3506, 0.6494], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3278, 0.6722], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3506, 0.6494], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.2215, 0.7785], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3324, 0.6676], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.1828, 0.8172], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3127, 0.6873], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.1999, 0.8001], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3201, 0.6799], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3278, 0.6722], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3506, 0.6494], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_1': tensor(25.7978), 'agent_0': tensor(43.2616)}
==========>Epoch= 30
 action, distrib= tensor(0) tensor([0.3193, 0.6807], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2059, 0.7941], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3493, 0.6507], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3690, 0.6310], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3228, 0.6772], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1782, 0.8218], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3623, 0.6377], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4073, 0.5927], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3493, 0.6507], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3690, 0.6310], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3822, 0.6178], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4688, 0.5312], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3493, 0.6507], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3690, 0.6310], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3493, 0.6507], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3690, 0.6310], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3441, 0.6559], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3135, 0.6865], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3411, 0.6589], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2771, 0.7229], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(44.0540), 'agent_1': tensor(43.7600)}
Epoch : 30 	 Measure: nan
==========>Epoch= 31
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3346, 0.6654], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3040, 0.6960], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3404, 0.6596], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3675, 0.6325], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3734, 0.6266], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4750, 0.5250], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3092, 0.6908], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.1603, 0.8397], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3601, 0.6399], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3567, 0.6433], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3382, 0.6618], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2501, 0.7499], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3346, 0.6654], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3040, 0.6960], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3136, 0.6864], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1890, 0.8110], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3346, 0.6654], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3040, 0.6960], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(0) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(49.7410), 'agent_1': tensor(38.1486)}
==========>Epoch= 32
 action, distrib= tensor(0) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3338, 0.6662], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3755, 0.6245], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3191, 0.6809], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1516, 0.8484], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3462, 0.6538], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4115, 0.5885], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3094, 0.6906], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1813, 0.8187], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3338, 0.6662], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3755, 0.6245], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3451, 0.6549], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3117, 0.6883], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3048, 0.6952], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.1526, 0.8474], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3862, 0.6138], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.4167, 0.5833], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3536, 0.6464], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1945, 0.8055], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(25.7092), 'agent_1': tensor(43.1902)}
==========>Epoch= 33
 action, distrib= tensor(0) tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3831, 0.6169], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3188, 0.6812], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3104, 0.6896], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3001, 0.6999], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1235, 0.8765], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3143, 0.6857], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1392, 0.8608], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3236, 0.6764], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2566, 0.7434], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2975, 0.7025], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1416, 0.8584], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3143, 0.6857], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1392, 0.8608], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3387, 0.6613], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3091, 0.6909], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3387, 0.6613], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3091, 0.6909], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3030, 0.6970], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.1709, 0.8291], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(0)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
R eval= {'agent_0': tensor(40.8323), 'agent_1': tensor(35.4100)}
==========>Epoch= 34
 action, distrib= tensor(1) tensor([0.3008, 0.6992], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1480, 0.8520], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3173, 0.6827], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.2951, 0.7049], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3238, 0.6762], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.3718, 0.6282], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(1) tensor([0.3254, 0.6746], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2077, 0.7923], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.3360, 0.6640], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.4146, 0.5854], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2959, 0.7041], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.1214, 0.8786], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(0)]
 action, distrib= tensor(0) tensor([0.3229, 0.6771], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2369, 0.7631], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.3095, 0.6905], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1643, 0.8357], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(1) tensor([0.2992, 0.7008], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1043, 0.8957], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(1)]
self.saved_actions[ag_idx]= [tensor(1)]
 action, distrib= tensor(0) tensor([0.2959, 0.7041], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1214, 0.8786], grad_fn=<SoftmaxBackward0>)
self.saved_actions[ag_idx]= [tensor(0)]
self.saved_actions[ag_idx]= [tensor(1)]
UPDATE
inside update
inside update
done
 action, distrib= tensor(1) tensor([0.2928, 0.7072], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1330, 0.8670], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2928, 0.7072], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1330, 0.8670], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2928, 0.7072], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(0) tensor([0.1330, 0.8670], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2928, 0.7072], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1330, 0.8670], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2928, 0.7072], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1330, 0.8670], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2928, 0.7072], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.1330, 0.8670], grad_fn=<SoftmaxBackward0>)
 action, distrib= tensor(1) tensor([0.2928, 0.7072], grad_fn=<SoftmaxBackward0>)
/home/nicole/marl-emecom/env1/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/home/nicole/marl-emecom/env1/lib/python3.8/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
Traceback (most recent call last):
  File "caller.py", line 63, in <module>
    train_reinforce(args)
  File "/home/nicole/marl-emecom/src/experiments_anastassacos/train_reinforce.py", line 212, in train_reinforce
    objective(args, repo_name)
  File "/home/nicole/marl-emecom/src/experiments_anastassacos/train_reinforce.py", line 138, in objective
    returns_eval = eval_anast(parallel_env, active_agents, active_agents_idxs, config.num_game_iterations, social_norm, 0.99)
  File "/home/nicole/marl-emecom/src/utils/utils.py", line 92, in eval_anast
    a, d = active_agents[agent].select_action()#states[idx_agent])
  File "/home/nicole/marl-emecom/src/algos/anast/agent_anast.py", line 49, in select_action
    action, action_logprob, entropy, distrib = self.policy_act.act(state=state_to_act, greedy=False, get_distrib=True)
  File "/home/nicole/marl-emecom/src/algos/anast/Actor.py", line 41, in act
    out = self.actor(state)
  File "/home/nicole/marl-emecom/env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nicole/marl-emecom/env1/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/nicole/marl-emecom/env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nicole/marl-emecom/env1/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/lib/python3.8/traceback.py", line 193, in format_stack
    def format_stack(f=None, limit=None):
KeyboardInterrupt