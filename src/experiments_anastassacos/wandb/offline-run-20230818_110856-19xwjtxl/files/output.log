config= {'b_value': 5.0, 'c_value': 1.0, 'd_value': 0.0, 'n_agents': 10, 'algorithm': 'reinforce', 'wandb_mode': 'offline', 'num_game_iterations': 1, 'n_epochs': 2000, 'obs_size': 4, 'action_size': 2, 'random_baseline': False, 'embedding_dim': 1, 'binary_reputation': None, 'other_reputation_threshold': 0.4, 'cooperation_threshold': 0.4, 'optuna_': 0, 'device': 'cpu', 'reputation_in_reward': 0, 'lr_actor': 0.001, 'n_hidden_act': 2, 'hidden_size_act': 16, 'batch_size': 1, 'decayRate': 0.999}
DD= tensor(1.)
Dc= tensor(6.)
Cd= tensor(0.)
CC= tensor(5.)
mv= tensor(6.)
mat= tensor([[1., 6.],
        [0., 5.]])
norm mat= tensor([[0.1667, 1.0000],
        [0.0000, 0.8333]])
is_dummy= [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Agent 0
Agent 1
Agent 2
Agent 3
Agent 4
Agent 5
Agent 6
Agent 7
Agent 8
Agent 9
==========>Epoch= 0
agent= agent_1 distrib= tensor([0.4583, 0.5417], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6418, 0.3582], grad_fn=<SoftmaxBackward0>)
Epoch : 0 	 Measure: 0.800000011920929
==========>Epoch= 1
agent= agent_5 distrib= tensor([0.4957, 0.5043], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6047, 0.3953], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 2
agent= agent_2 distrib= tensor([0.6095, 0.3905], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.4949, 0.5051], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 3
agent= agent_6 distrib= tensor([0.6303, 0.3697], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4490, 0.5510], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 4
agent= agent_5 distrib= tensor([0.4889, 0.5111], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6051, 0.3949], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 5
agent= agent_2 distrib= tensor([0.6515, 0.3485], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5050, 0.4950], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 6
agent= agent_9 distrib= tensor([0.5976, 0.4024], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5104, 0.4896], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 7
agent= agent_8 distrib= tensor([0.4654, 0.5346], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6045, 0.3955], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 8
agent= agent_8 distrib= tensor([0.4447, 0.5553], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5025, 0.4975], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 9
agent= agent_0 distrib= tensor([0.4207, 0.5793], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4540, 0.5460], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 10
agent= agent_4 distrib= tensor([0.5004, 0.4996], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6121, 0.3879], grad_fn=<SoftmaxBackward0>)
Epoch : 10 	 Measure: 0.6000000238418579
==========>Epoch= 11
agent= agent_0 distrib= tensor([0.4298, 0.5702], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5105, 0.4895], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 12
agent= agent_0 distrib= tensor([0.4186, 0.5814], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5090, 0.4910], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 13
agent= agent_5 distrib= tensor([0.4944, 0.5056], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4884, 0.5116], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 14
agent= agent_9 distrib= tensor([0.6214, 0.3786], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4878, 0.5122], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 15
agent= agent_5 distrib= tensor([0.5008, 0.4992], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6163, 0.3837], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 16
agent= agent_4 distrib= tensor([0.5083, 0.4917], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6081, 0.3919], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 17
agent= agent_7 distrib= tensor([0.5011, 0.4989], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4432, 0.5568], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 18
agent= agent_0 distrib= tensor([0.4059, 0.5941], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5140, 0.4860], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 19
agent= agent_7 distrib= tensor([0.4995, 0.5005], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5104, 0.4896], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 20
agent= agent_8 distrib= tensor([0.4579, 0.5421], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.4971, 0.5029], grad_fn=<SoftmaxBackward0>)
Epoch : 20 	 Measure: 0.6000000238418579
==========>Epoch= 21
agent= agent_9 distrib= tensor([0.5809, 0.4191], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.4771, 0.5229], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 22
agent= agent_1 distrib= tensor([0.4333, 0.5667], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6148, 0.3852], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 23
agent= agent_4 distrib= tensor([0.5367, 0.4633], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6333, 0.3667], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 24
agent= agent_1 distrib= tensor([0.5097, 0.4903], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5129, 0.4871], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 25
agent= agent_0 distrib= tensor([0.3942, 0.6058], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4359, 0.5641], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 26
agent= agent_8 distrib= tensor([0.4372, 0.5628], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4912, 0.5088], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 27
agent= agent_7 distrib= tensor([0.4963, 0.5037], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.4879, 0.5121], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 28
agent= agent_1 distrib= tensor([0.4736, 0.5264], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4576, 0.5424], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 29
agent= agent_6 distrib= tensor([0.6570, 0.3430], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4694, 0.5306], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 30
agent= agent_3 distrib= tensor([0.4921, 0.5079], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4383, 0.5617], grad_fn=<SoftmaxBackward0>)
Epoch : 30 	 Measure: 0.8999999761581421
==========>Epoch= 31
agent= agent_1 distrib= tensor([0.4188, 0.5812], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4412, 0.5588], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 32
agent= agent_3 distrib= tensor([0.4902, 0.5098], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5196, 0.4804], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 33
agent= agent_0 distrib= tensor([0.4160, 0.5840], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6343, 0.3657], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 34
agent= agent_2 distrib= tensor([0.6331, 0.3669], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4514, 0.5486], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 35
agent= agent_5 distrib= tensor([0.5218, 0.4782], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4200, 0.5800], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 36
agent= agent_2 distrib= tensor([0.6240, 0.3760], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5108, 0.4892], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 37
agent= agent_9 distrib= tensor([0.5844, 0.4156], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5076, 0.4924], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 38
agent= agent_0 distrib= tensor([0.4068, 0.5932], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5307, 0.4693], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 39
agent= agent_2 distrib= tensor([0.6279, 0.3721], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6656, 0.3344], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 40
agent= agent_6 distrib= tensor([0.6339, 0.3661], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4466, 0.5534], grad_fn=<SoftmaxBackward0>)
Epoch : 40 	 Measure: 0.6000000238418579
==========>Epoch= 41
agent= agent_1 distrib= tensor([0.4939, 0.5061], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5082, 0.4918], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 42
agent= agent_4 distrib= tensor([0.5198, 0.4802], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6633, 0.3367], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 43
agent= agent_1 distrib= tensor([0.4078, 0.5922], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6324, 0.3676], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 44
agent= agent_5 distrib= tensor([0.5238, 0.4762], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6501, 0.3499], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 45
agent= agent_0 distrib= tensor([0.4660, 0.5340], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4819, 0.5181], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 46
agent= agent_2 distrib= tensor([0.6373, 0.3627], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.4977, 0.5023], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 47
agent= agent_6 distrib= tensor([0.6337, 0.3663], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5020, 0.4980], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 48
agent= agent_2 distrib= tensor([0.6830, 0.3171], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5046, 0.4954], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 49
agent= agent_6 distrib= tensor([0.6507, 0.3493], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5262, 0.4738], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 50
agent= agent_5 distrib= tensor([0.5212, 0.4788], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4839, 0.5161], grad_fn=<SoftmaxBackward0>)
Epoch : 50 	 Measure: 0.5
==========>Epoch= 51
agent= agent_9 distrib= tensor([0.6384, 0.3616], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4439, 0.5561], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 52
agent= agent_8 distrib= tensor([0.4205, 0.5795], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5046, 0.4954], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 53
agent= agent_3 distrib= tensor([0.4806, 0.5194], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.3942, 0.6058], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 54
agent= agent_7 distrib= tensor([0.5016, 0.4984], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5296, 0.4704], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 55
agent= agent_7 distrib= tensor([0.5055, 0.4945], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6217, 0.3783], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 56
agent= agent_0 distrib= tensor([0.4563, 0.5437], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5070, 0.4930], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 57
agent= agent_3 distrib= tensor([0.4809, 0.5191], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5221, 0.4779], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 58
agent= agent_6 distrib= tensor([0.6489, 0.3511], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4800, 0.5200], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 59
agent= agent_9 distrib= tensor([0.5893, 0.4107], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4591, 0.5409], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 60
agent= agent_6 distrib= tensor([0.6217, 0.3783], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4776, 0.5224], grad_fn=<SoftmaxBackward0>)
Epoch : 60 	 Measure: 0.20000000298023224
==========>Epoch= 61
agent= agent_0 distrib= tensor([0.4653, 0.5347], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 62
agent= agent_6 distrib= tensor([0.6606, 0.3394], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5341, 0.4659], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 63
agent= agent_4 distrib= tensor([0.5133, 0.4867], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6689, 0.3311], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 64
agent= agent_4 distrib= tensor([0.5404, 0.4596], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6590, 0.3410], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 65
agent= agent_3 distrib= tensor([0.4817, 0.5183], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4820, 0.5180], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 66
agent= agent_1 distrib= tensor([0.4198, 0.5802], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.5912, 0.4088], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 67
agent= agent_5 distrib= tensor([0.5269, 0.4731], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4437, 0.5563], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 68
agent= agent_2 distrib= tensor([0.6429, 0.3571], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6589, 0.3411], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 69
agent= agent_1 distrib= tensor([0.4330, 0.5670], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4402, 0.5598], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 70
agent= agent_9 distrib= tensor([0.6511, 0.3489], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4302, 0.5698], grad_fn=<SoftmaxBackward0>)
Epoch : 70 	 Measure: 0.6000000238418579
==========>Epoch= 71
agent= agent_9 distrib= tensor([0.6296, 0.3704], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6429, 0.3571], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 72
agent= agent_8 distrib= tensor([0.4116, 0.5884], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4141, 0.5859], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 73
agent= agent_4 distrib= tensor([0.5546, 0.4454], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4241, 0.5759], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 74
agent= agent_6 distrib= tensor([0.6414, 0.3586], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6568, 0.3432], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 75
agent= agent_1 distrib= tensor([0.4122, 0.5878], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5148, 0.4852], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 76
agent= agent_9 distrib= tensor([0.6336, 0.3664], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4190, 0.5810], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 77
agent= agent_1 distrib= tensor([0.4104, 0.5896], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5078, 0.4922], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 78
agent= agent_1 distrib= tensor([0.4284, 0.5716], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4561, 0.5439], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 79
agent= agent_3 distrib= tensor([0.4807, 0.5193], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5270, 0.4730], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 80
agent= agent_9 distrib= tensor([0.6306, 0.3694], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6413, 0.3587], grad_fn=<SoftmaxBackward0>)
Epoch : 80 	 Measure: 0.6000000238418579
==========>Epoch= 81
agent= agent_3 distrib= tensor([0.5042, 0.4958], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5142, 0.4858], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 82
agent= agent_6 distrib= tensor([0.6410, 0.3590], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6568, 0.3432], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 83
agent= agent_0 distrib= tensor([0.4405, 0.5595], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4188, 0.5812], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 84
agent= agent_4 distrib= tensor([0.5543, 0.4457], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6362, 0.3638], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 85
agent= agent_5 distrib= tensor([0.5012, 0.4988], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5167, 0.4833], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 86
agent= agent_5 distrib= tensor([0.5012, 0.4988], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5105, 0.4895], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 87
agent= agent_7 distrib= tensor([0.5164, 0.4836], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6411, 0.3589], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 88
agent= agent_7 distrib= tensor([0.5189, 0.4811], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6379, 0.3621], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 89
agent= agent_9 distrib= tensor([0.6333, 0.3667], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5437, 0.4563], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 90
agent= agent_3 distrib= tensor([0.5039, 0.4961], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4793, 0.5207], grad_fn=<SoftmaxBackward0>)
Epoch : 90 	 Measure: 0.30000001192092896
==========>Epoch= 91
agent= agent_1 distrib= tensor([0.3828, 0.6172], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4823, 0.5177], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 92
agent= agent_8 distrib= tensor([0.4197, 0.5803], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5282, 0.4718], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 93
agent= agent_6 distrib= tensor([0.6323, 0.3677], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5149, 0.4851], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 94
agent= agent_6 distrib= tensor([0.6599, 0.3401], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6411, 0.3589], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 95
agent= agent_2 distrib= tensor([0.6767, 0.3233], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4484, 0.5516], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 96
agent= agent_3 distrib= tensor([0.4830, 0.5170], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6335, 0.3665], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 97
agent= agent_5 distrib= tensor([0.5027, 0.4973], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6615, 0.3385], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 98
agent= agent_1 distrib= tensor([0.4119, 0.5881], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5035, 0.4965], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 99
agent= agent_2 distrib= tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6442, 0.3558], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 100
agent= agent_7 distrib= tensor([0.5277, 0.4723], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4717, 0.5283], grad_fn=<SoftmaxBackward0>)
Epoch : 100 	 Measure: 0.5
==========>Epoch= 101
agent= agent_9 distrib= tensor([0.6611, 0.3389], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4338, 0.5662], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 102
agent= agent_9 distrib= tensor([0.6401, 0.3599], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5049, 0.4951], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 103
agent= agent_1 distrib= tensor([0.4123, 0.5877], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5173, 0.4827], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 104
agent= agent_6 distrib= tensor([0.6378, 0.3622], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4127, 0.5873], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 105
agent= agent_6 distrib= tensor([0.6382, 0.3618], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4119, 0.5881], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 106
agent= agent_3 distrib= tensor([0.5058, 0.4942], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6413, 0.3587], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 107
agent= agent_5 distrib= tensor([0.5281, 0.4719], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5334, 0.4666], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 108
agent= agent_6 distrib= tensor([0.6375, 0.3625], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5160, 0.4840], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 109
agent= agent_9 distrib= tensor([0.6426, 0.3574], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5069, 0.4931], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 110
agent= agent_7 distrib= tensor([0.5308, 0.4692], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5031, 0.4969], grad_fn=<SoftmaxBackward0>)
Epoch : 110 	 Measure: 0.5
==========>Epoch= 111
agent= agent_0 distrib= tensor([0.4557, 0.5443], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6666, 0.3334], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 112
agent= agent_4 distrib= tensor([0.5537, 0.4463], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5013, 0.4987], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 113
agent= agent_4 distrib= tensor([0.5818, 0.4182], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5277, 0.4723], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 114
agent= agent_3 distrib= tensor([0.4894, 0.5106], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6372, 0.3628], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 115
agent= agent_0 distrib= tensor([0.4768, 0.5232], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5275, 0.4725], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 116
agent= agent_6 distrib= tensor([0.6157, 0.3843], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5294, 0.4706], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 117
agent= agent_1 distrib= tensor([0.4102, 0.5898], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5248, 0.4752], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 118
agent= agent_3 distrib= tensor([0.5068, 0.4932], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5486, 0.4514], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 119
agent= agent_9 distrib= tensor([0.5981, 0.4019], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5077, 0.4923], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 120
agent= agent_8 distrib= tensor([0.4170, 0.5830], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6402, 0.3598], grad_fn=<SoftmaxBackward0>)
Epoch : 120 	 Measure: 0.4000000059604645
==========>Epoch= 121
agent= agent_3 distrib= tensor([0.5069, 0.4931], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6393, 0.3607], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 122
agent= agent_6 distrib= tensor([0.6343, 0.3657], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5248, 0.4752], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 123
agent= agent_2 distrib= tensor([0.6425, 0.3575], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6631, 0.3369], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 124
agent= agent_8 distrib= tensor([0.4165, 0.5835], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5528, 0.4472], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 125
agent= agent_6 distrib= tensor([0.6634, 0.3366], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4904, 0.5096], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 126
agent= agent_7 distrib= tensor([0.5403, 0.4597], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6594, 0.3406], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 127
agent= agent_8 distrib= tensor([0.4015, 0.5985], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5262, 0.4738], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 128
agent= agent_8 distrib= tensor([0.4129, 0.5871], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5699, 0.4301], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 129
agent= agent_7 distrib= tensor([0.5253, 0.4747], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4003, 0.5997], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 130
agent= agent_2 distrib= tensor([0.6439, 0.3561], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5075, 0.4925], grad_fn=<SoftmaxBackward0>)
Epoch : 130 	 Measure: 0.6000000238418579
==========>Epoch= 131
agent= agent_9 distrib= tensor([0.6394, 0.3606], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5259, 0.4741], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 132
agent= agent_3 distrib= tensor([0.4909, 0.5091], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6647, 0.3353], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 133
agent= agent_1 distrib= tensor([0.4609, 0.5391], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6786, 0.3214], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 134
agent= agent_7 distrib= tensor([0.5344, 0.4656], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5744, 0.4256], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 135
agent= agent_9 distrib= tensor([0.6631, 0.3369], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4313, 0.5687], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 136
agent= agent_5 distrib= tensor([0.5261, 0.4739], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5420, 0.4580], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 137
agent= agent_3 distrib= tensor([0.5102, 0.4898], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.4976, 0.5024], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 138
agent= agent_3 distrib= tensor([0.4912, 0.5088], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4182, 0.5818], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 139
agent= agent_9 distrib= tensor([0.6404, 0.3596], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4195, 0.5805], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 140
agent= agent_8 distrib= tensor([0.4046, 0.5954], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.5966, 0.4034], grad_fn=<SoftmaxBackward0>)
Epoch : 140 	 Measure: 0.699999988079071
==========>Epoch= 141
agent= agent_5 distrib= tensor([0.5272, 0.4728], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6604, 0.3396], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 142
agent= agent_3 distrib= tensor([0.4915, 0.5085], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5044, 0.4956], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 143
agent= agent_6 distrib= tensor([0.6659, 0.3341], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5352, 0.4648], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 144
agent= agent_8 distrib= tensor([0.4056, 0.5944], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4881, 0.5119], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 145
agent= agent_2 distrib= tensor([0.6608, 0.3392], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4856, 0.5144], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 146
agent= agent_5 distrib= tensor([0.5015, 0.4985], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5794, 0.4206], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 147
agent= agent_2 distrib= tensor([0.6799, 0.3201], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5034, 0.4966], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 148
agent= agent_9 distrib= tensor([0.6372, 0.3628], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4165, 0.5835], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 149
agent= agent_3 distrib= tensor([0.4913, 0.5087], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.3779, 0.6221], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 150
agent= agent_3 distrib= tensor([0.4926, 0.5074], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5842, 0.4158], grad_fn=<SoftmaxBackward0>)
Epoch : 150 	 Measure: 0.4000000059604645
==========>Epoch= 151
agent= agent_0 distrib= tensor([0.5027, 0.4973], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4948, 0.5052], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 152
agent= agent_1 distrib= tensor([0.4573, 0.5427], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6672, 0.3328], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 153
agent= agent_1 distrib= tensor([0.4024, 0.5976], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6373, 0.3627], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 154
agent= agent_1 distrib= tensor([0.4251, 0.5749], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 155
agent= agent_0 distrib= tensor([0.5036, 0.4964], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4174, 0.5826], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 156
agent= agent_1 distrib= tensor([0.4056, 0.5944], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5268, 0.4732], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 157
agent= agent_1 distrib= tensor([0.3824, 0.6176], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5366, 0.4634], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 158
agent= agent_4 distrib= tensor([0.5851, 0.4149], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.3857, 0.6143], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 159
agent= agent_0 distrib= tensor([0.4572, 0.5428], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5109, 0.4891], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 160
agent= agent_9 distrib= tensor([0.6391, 0.3609], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4197, 0.5803], grad_fn=<SoftmaxBackward0>)
Epoch : 160 	 Measure: 0.4000000059604645
==========>Epoch= 161
agent= agent_2 distrib= tensor([0.6427, 0.3573], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5047, 0.4953], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 162
agent= agent_2 distrib= tensor([0.6621, 0.3379], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5280, 0.4720], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 163
agent= agent_8 distrib= tensor([0.4282, 0.5718], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5908, 0.4092], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 164
agent= agent_3 distrib= tensor([0.5168, 0.4832], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4150, 0.5850], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 165
agent= agent_9 distrib= tensor([0.6731, 0.3269], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5320, 0.4680], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 166
agent= agent_3 distrib= tensor([0.5007, 0.4993], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6783, 0.3217], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 167
agent= agent_1 distrib= tensor([0.3925, 0.6075], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4231, 0.5769], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 168
agent= agent_7 distrib= tensor([0.5367, 0.4633], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5055, 0.4945], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 169
agent= agent_4 distrib= tensor([0.5966, 0.4034], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5391, 0.4609], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 170
agent= agent_9 distrib= tensor([0.6755, 0.3245], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5483, 0.4517], grad_fn=<SoftmaxBackward0>)
Epoch : 170 	 Measure: 0.4000000059604645
==========>Epoch= 171
agent= agent_8 distrib= tensor([0.4288, 0.5712], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5080, 0.4920], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 172
agent= agent_3 distrib= tensor([0.4950, 0.5050], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5390, 0.4610], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 173
agent= agent_1 distrib= tensor([0.4765, 0.5235], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5410, 0.4590], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 174
agent= agent_9 distrib= tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5422, 0.4578], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 175
agent= agent_1 distrib= tensor([0.4792, 0.5208], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6004, 0.3996], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 176
agent= agent_7 distrib= tensor([0.5407, 0.4593], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.3999, 0.6001], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 177
agent= agent_5 distrib= tensor([0.5432, 0.4568], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 178
agent= agent_1 distrib= tensor([0.4837, 0.5163], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6783, 0.3217], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 179
agent= agent_4 distrib= tensor([0.6048, 0.3952], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6196, 0.3804], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 180
agent= agent_5 distrib= tensor([0.5439, 0.4561], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6453, 0.3547], grad_fn=<SoftmaxBackward0>)
Epoch : 180 	 Measure: 0.6000000238418579
==========>Epoch= 181
agent= agent_7 distrib= tensor([0.5327, 0.4673], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5171, 0.4829], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 182
agent= agent_0 distrib= tensor([0.4572, 0.5428], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4304, 0.5696], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 183
agent= agent_7 distrib= tensor([0.5538, 0.4462], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4508, 0.5492], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 184
agent= agent_1 distrib= tensor([0.4513, 0.5487], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6599, 0.3401], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 185
agent= agent_0 distrib= tensor([0.4762, 0.5238], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6800, 0.3200], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 186
agent= agent_2 distrib= tensor([0.6786, 0.3214], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6205, 0.3795], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 187
agent= agent_8 distrib= tensor([0.4247, 0.5753], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6789, 0.3211], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 188
agent= agent_3 distrib= tensor([0.4947, 0.5052], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4756, 0.5244], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 189
agent= agent_6 distrib= tensor([0.6398, 0.3602], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6101, 0.3899], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 190
agent= agent_6 distrib= tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6494, 0.3506], grad_fn=<SoftmaxBackward0>)
Epoch : 190 	 Measure: 0.699999988079071
==========>Epoch= 191
agent= agent_6 distrib= tensor([0.6560, 0.3440], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5542, 0.4458], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 192
agent= agent_5 distrib= tensor([0.5472, 0.4528], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4440, 0.5560], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 193
agent= agent_1 distrib= tensor([0.4351, 0.5649], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6446, 0.3554], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 194
agent= agent_6 distrib= tensor([0.6277, 0.3723], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4314, 0.5686], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 195
agent= agent_3 distrib= tensor([0.5110, 0.4890], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6295, 0.3705], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 196
agent= agent_6 distrib= tensor([0.6320, 0.3680], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6799, 0.3201], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 197
agent= agent_6 distrib= tensor([0.6843, 0.3157], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4256, 0.5744], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 198
agent= agent_7 distrib= tensor([0.5437, 0.4563], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5205, 0.4795], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 199
agent= agent_0 distrib= tensor([0.4741, 0.5259], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6701, 0.3299], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 200
agent= agent_4 distrib= tensor([0.5735, 0.4265], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5175, 0.4825], grad_fn=<SoftmaxBackward0>)
Epoch : 200 	 Measure: 0.4000000059604645
==========>Epoch= 201
agent= agent_9 distrib= tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5442, 0.4558], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 202
agent= agent_2 distrib= tensor([0.6619, 0.3381], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6597, 0.3403], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 203
agent= agent_6 distrib= tensor([0.6533, 0.3467], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4156, 0.5844], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 204
agent= agent_3 distrib= tensor([0.5172, 0.4828], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4161, 0.5839], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 205
agent= agent_6 distrib= tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5227, 0.4773], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 206
agent= agent_8 distrib= tensor([0.4470, 0.5530], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6805, 0.3195], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 207
agent= agent_4 distrib= tensor([0.5821, 0.4179], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4359, 0.5641], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 208
agent= agent_5 distrib= tensor([0.5250, 0.4750], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5014, 0.4986], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 209
agent= agent_2 distrib= tensor([0.6665, 0.3335], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6144, 0.3856], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 210
agent= agent_7 distrib= tensor([0.5471, 0.4529], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6846, 0.3154], grad_fn=<SoftmaxBackward0>)
Epoch : 210 	 Measure: 0.4000000059604645
==========>Epoch= 211
agent= agent_8 distrib= tensor([0.4300, 0.5700], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5439, 0.4561], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 212
agent= agent_5 distrib= tensor([0.5272, 0.4728], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4098, 0.5902], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 213
agent= agent_5 distrib= tensor([0.5306, 0.4694], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4401, 0.5599], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 214
agent= agent_5 distrib= tensor([0.5646, 0.4354], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 215
agent= agent_0 distrib= tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4318, 0.5682], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 216
agent= agent_6 distrib= tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5860, 0.4140], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 217
agent= agent_8 distrib= tensor([0.4386, 0.5614], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6464, 0.3536], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 218
agent= agent_1 distrib= tensor([0.4609, 0.5391], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6874, 0.3126], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 219
agent= agent_4 distrib= tensor([0.6335, 0.3665], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5686, 0.4314], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 220
agent= agent_7 distrib= tensor([0.5435, 0.4565], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4501, 0.5499], grad_fn=<SoftmaxBackward0>)
Epoch : 220 	 Measure: 0.5
==========>Epoch= 221
agent= agent_7 distrib= tensor([0.5352, 0.4648], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4837, 0.5163], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 222
agent= agent_0 distrib= tensor([0.4985, 0.5015], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4983, 0.5017], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 223
agent= agent_5 distrib= tensor([0.5732, 0.4268], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5449, 0.4551], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 224
agent= agent_9 distrib= tensor([0.6917, 0.3083], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6644, 0.3356], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 225
agent= agent_6 distrib= tensor([0.6661, 0.3339], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5471, 0.4529], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 226
agent= agent_3 distrib= tensor([0.5169, 0.4831], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5357, 0.4643], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 227
agent= agent_0 distrib= tensor([0.5001, 0.4999], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4991, 0.5009], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 228
agent= agent_6 distrib= tensor([0.6947, 0.3053], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4530, 0.5470], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 229
agent= agent_4 distrib= tensor([0.6771, 0.3229], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4736, 0.5264], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 230
agent= agent_8 distrib= tensor([0.4431, 0.5569], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6471, 0.3529], grad_fn=<SoftmaxBackward0>)
Epoch : 230 	 Measure: 0.699999988079071
==========>Epoch= 231
agent= agent_5 distrib= tensor([0.5508, 0.4492], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.5964, 0.4036], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 232
agent= agent_1 distrib= tensor([0.4638, 0.5362], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6859, 0.3141], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 233
agent= agent_4 distrib= tensor([0.6496, 0.3504], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6860, 0.3140], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 234
agent= agent_6 distrib= tensor([0.6617, 0.3383], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5051, 0.4949], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 235
agent= agent_5 distrib= tensor([0.5847, 0.4153], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5012, 0.4988], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 236
agent= agent_0 distrib= tensor([0.4780, 0.5220], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6944, 0.3056], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 237
agent= agent_6 distrib= tensor([0.6759, 0.3241], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6066, 0.3934], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 238
agent= agent_1 distrib= tensor([0.5028, 0.4972], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4465, 0.5535], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 239
agent= agent_3 distrib= tensor([0.4899, 0.5101], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4617, 0.5383], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 240
agent= agent_6 distrib= tensor([0.7072, 0.2928], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5560, 0.4440], grad_fn=<SoftmaxBackward0>)
Epoch : 240 	 Measure: 0.6000000238418579
==========>Epoch= 241
agent= agent_8 distrib= tensor([0.4654, 0.5346], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6667, 0.3333], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 242
agent= agent_9 distrib= tensor([0.6717, 0.3283], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6571, 0.3429], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 243
agent= agent_8 distrib= tensor([0.4687, 0.5313], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5859, 0.4141], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 244
agent= agent_1 distrib= tensor([0.4224, 0.5776], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4992, 0.5008], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 245
agent= agent_5 distrib= tensor([0.5616, 0.4384], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4951, 0.5049], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 246
agent= agent_8 distrib= tensor([0.4624, 0.5376], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6727, 0.3273], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 247
agent= agent_2 distrib= tensor([0.6708, 0.3292], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6860, 0.3140], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 248
agent= agent_8 distrib= tensor([0.4516, 0.5484], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6603, 0.3397], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 249
agent= agent_0 distrib= tensor([0.4822, 0.5178], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7053, 0.2947], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 250
agent= agent_2 distrib= tensor([0.6717, 0.3283], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5172, 0.4828], grad_fn=<SoftmaxBackward0>)
Epoch : 250 	 Measure: 0.6000000238418579
==========>Epoch= 251
agent= agent_4 distrib= tensor([0.7091, 0.2909], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5936, 0.4064], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 252
agent= agent_2 distrib= tensor([0.6714, 0.3286], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6227, 0.3773], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 253
agent= agent_6 distrib= tensor([0.7312, 0.2688], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6727, 0.3273], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 254
agent= agent_1 distrib= tensor([0.4240, 0.5760], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6778, 0.3222], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 255
agent= agent_0 distrib= tensor([0.4646, 0.5354], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5993, 0.4007], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 256
agent= agent_3 distrib= tensor([0.4997, 0.5003], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6682, 0.3318], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 257
agent= agent_8 distrib= tensor([0.4770, 0.5230], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7057, 0.2943], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 258
agent= agent_1 distrib= tensor([0.4529, 0.5471], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4498, 0.5502], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 259
agent= agent_6 distrib= tensor([0.6859, 0.3141], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5081, 0.4919], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 260
agent= agent_2 distrib= tensor([0.6712, 0.3288], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5716, 0.4284], grad_fn=<SoftmaxBackward0>)
Epoch : 260 	 Measure: 0.699999988079071
==========>Epoch= 261
agent= agent_5 distrib= tensor([0.6054, 0.3946], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6904, 0.3096], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 262
agent= agent_4 distrib= tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7086, 0.2914], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 263
agent= agent_1 distrib= tensor([0.4250, 0.5750], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5759, 0.4241], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 264
agent= agent_8 distrib= tensor([0.4759, 0.5241], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.6954, 0.3046], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 265
agent= agent_7 distrib= tensor([0.5577, 0.4423], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7113, 0.2887], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 266
agent= agent_7 distrib= tensor([0.5489, 0.4511], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 267
agent= agent_8 distrib= tensor([0.4554, 0.5446], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5038, 0.4962], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 268
agent= agent_9 distrib= tensor([0.6834, 0.3166], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4640, 0.5360], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 269
agent= agent_7 distrib= tensor([0.5620, 0.4380], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 270
agent= agent_7 distrib= tensor([0.5543, 0.4457], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4995, 0.5005], grad_fn=<SoftmaxBackward0>)
Epoch : 270 	 Measure: 0.4000000059604645
==========>Epoch= 271
agent= agent_6 distrib= tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5061, 0.4939], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 272
agent= agent_8 distrib= tensor([0.4834, 0.5166], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4995, 0.5005], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 273
agent= agent_2 distrib= tensor([0.6892, 0.3108], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 274
agent= agent_2 distrib= tensor([0.6716, 0.3284], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 275
agent= agent_6 distrib= tensor([0.7054, 0.2946], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5249, 0.4751], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 276
agent= agent_5 distrib= tensor([0.5784, 0.4216], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5569, 0.4431], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 277
agent= agent_6 distrib= tensor([0.7565, 0.2435], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4661, 0.5339], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 278
agent= agent_4 distrib= tensor([0.7301, 0.2699], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4908, 0.5092], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 279
agent= agent_9 distrib= tensor([0.6993, 0.3007], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4844, 0.5156], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 280
agent= agent_9 distrib= tensor([0.6484, 0.3516], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5831, 0.4169], grad_fn=<SoftmaxBackward0>)
Epoch : 280 	 Measure: 0.5
==========>Epoch= 281
agent= agent_9 distrib= tensor([0.6980, 0.3020], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5849, 0.4151], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 282
agent= agent_3 distrib= tensor([0.4981, 0.5019], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4851, 0.5149], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 283
agent= agent_3 distrib= tensor([0.5143, 0.4857], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6396, 0.3604], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 284
agent= agent_9 distrib= tensor([0.6553, 0.3447], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.5898, 0.4102], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 285
agent= agent_8 distrib= tensor([0.4677, 0.5323], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6239, 0.3761], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 286
agent= agent_9 distrib= tensor([0.6583, 0.3417], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5500, 0.4500], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 287
agent= agent_6 distrib= tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4983, 0.5017], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 288
agent= agent_0 distrib= tensor([0.5289, 0.4711], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4684, 0.5316], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 289
agent= agent_9 distrib= tensor([0.7427, 0.2573], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5715, 0.4285], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 290
agent= agent_1 distrib= tensor([0.4716, 0.5284], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4960, 0.5040], grad_fn=<SoftmaxBackward0>)
Epoch : 290 	 Measure: 0.6000000238418579
==========>Epoch= 291
agent= agent_3 distrib= tensor([0.4911, 0.5089], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4945, 0.5055], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 292
agent= agent_1 distrib= tensor([0.4256, 0.5744], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6531, 0.3469], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 293
agent= agent_0 distrib= tensor([0.5155, 0.4845], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5125, 0.4875], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 294
agent= agent_1 distrib= tensor([0.5070, 0.4930], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6276, 0.3724], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 295
agent= agent_9 distrib= tensor([0.7200, 0.2800], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5067, 0.4933], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 296
agent= agent_3 distrib= tensor([0.4995, 0.5005], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 297
agent= agent_2 distrib= tensor([0.6916, 0.3084], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5003, 0.4997], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 298
agent= agent_6 distrib= tensor([0.7693, 0.2307], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.4819, 0.5181], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 299
agent= agent_5 distrib= tensor([0.6311, 0.3689], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4654, 0.5346], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 300
agent= agent_2 distrib= tensor([0.6725, 0.3275], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5156, 0.4844], grad_fn=<SoftmaxBackward0>)
Epoch : 300 	 Measure: 0.6000000238418579
==========>Epoch= 301
agent= agent_5 distrib= tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7239, 0.2761], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 302
agent= agent_7 distrib= tensor([0.5736, 0.4264], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7696, 0.2304], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 303
agent= agent_6 distrib= tensor([0.7756, 0.2244], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5065, 0.4935], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 304
agent= agent_6 distrib= tensor([0.7738, 0.2262], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4924, 0.5076], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 305
agent= agent_9 distrib= tensor([0.7282, 0.2718], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5640, 0.4360], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 306
agent= agent_8 distrib= tensor([0.4816, 0.5184], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6090, 0.3910], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 307
agent= agent_8 distrib= tensor([0.4599, 0.5401], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7228, 0.2772], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 308
agent= agent_7 distrib= tensor([0.5752, 0.4248], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7738, 0.2262], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 309
agent= agent_3 distrib= tensor([0.5104, 0.4896], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6916, 0.3084], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 310
agent= agent_0 distrib= tensor([0.5359, 0.4641], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7341, 0.2659], grad_fn=<SoftmaxBackward0>)
Epoch : 310 	 Measure: 0.6000000238418579
==========>Epoch= 311
agent= agent_5 distrib= tensor([0.6414, 0.3586], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6533, 0.3467], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 312
agent= agent_3 distrib= tensor([0.5120, 0.4880], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5661, 0.4339], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 313
agent= agent_9 distrib= tensor([0.7620, 0.2380], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5088, 0.4912], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 314
agent= agent_1 distrib= tensor([0.4228, 0.5772], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7321, 0.2679], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 315
agent= agent_9 distrib= tensor([0.6788, 0.3212], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6404, 0.3596], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 316
agent= agent_0 distrib= tensor([0.4891, 0.5109], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6437, 0.3563], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 317
agent= agent_1 distrib= tensor([0.4677, 0.5323], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5009, 0.4991], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 318
agent= agent_0 distrib= tensor([0.5143, 0.4857], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4661, 0.5339], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 319
agent= agent_9 distrib= tensor([0.7391, 0.2609], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5155, 0.4845], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 320
agent= agent_9 distrib= tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)
Epoch : 320 	 Measure: 0.6000000238418579
==========>Epoch= 321
agent= agent_4 distrib= tensor([0.6967, 0.3033], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7324, 0.2676], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 322
agent= agent_6 distrib= tensor([0.7366, 0.2634], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5301, 0.4699], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 323
agent= agent_9 distrib= tensor([0.7681, 0.2319], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5193, 0.4807], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 324
agent= agent_4 distrib= tensor([0.6986, 0.3014], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6468, 0.3532], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 325
agent= agent_7 distrib= tensor([0.5782, 0.4218], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7672, 0.2328], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 326
agent= agent_2 distrib= tensor([0.6534, 0.3466], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6505, 0.3495], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 327
agent= agent_9 distrib= tensor([0.7294, 0.2706], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5041, 0.4959], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 328
agent= agent_7 distrib= tensor([0.5696, 0.4304], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4754, 0.5246], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 329
agent= agent_9 distrib= tensor([0.7662, 0.2338], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4638, 0.5362], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 330
agent= agent_1 distrib= tensor([0.4617, 0.5383], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7758, 0.2242], grad_fn=<SoftmaxBackward0>)
Epoch : 330 	 Measure: 0.6000000238418579
==========>Epoch= 331
agent= agent_5 distrib= tensor([0.6236, 0.3764], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6732, 0.3268], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 332
agent= agent_4 distrib= tensor([0.7436, 0.2564], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6770, 0.3230], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 333
agent= agent_0 distrib= tensor([0.5508, 0.4492], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4529, 0.5471], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 334
agent= agent_4 distrib= tensor([0.7032, 0.2968], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5732, 0.4268], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 335
agent= agent_7 distrib= tensor([0.5831, 0.4169], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5034, 0.4966], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 336
agent= agent_5 distrib= tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5036, 0.4964], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 337
agent= agent_9 distrib= tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6562, 0.3438], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 338
agent= agent_1 distrib= tensor([0.4160, 0.5840], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7360, 0.2640], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 339
agent= agent_0 distrib= tensor([0.5338, 0.4662], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6523, 0.3477], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 340
agent= agent_5 distrib= tensor([0.6586, 0.3414], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4742, 0.5258], grad_fn=<SoftmaxBackward0>)
Epoch : 340 	 Measure: 0.5
==========>Epoch= 341
agent= agent_5 distrib= tensor([0.6305, 0.3695], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5518, 0.4482], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 342
agent= agent_7 distrib= tensor([0.5826, 0.4174], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7786, 0.2214], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 343
agent= agent_1 distrib= tensor([0.4162, 0.5838], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7082, 0.2918], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 344
agent= agent_5 distrib= tensor([0.6369, 0.3631], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6804, 0.3196], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 345
agent= agent_3 distrib= tensor([0.5287, 0.4713], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5629, 0.4371], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 346
agent= agent_2 distrib= tensor([0.6779, 0.3221], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4596, 0.5404], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 347
agent= agent_0 distrib= tensor([0.5360, 0.4640], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6801, 0.3199], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 348
agent= agent_9 distrib= tensor([0.6797, 0.3203], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5292, 0.4708], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 349
agent= agent_3 distrib= tensor([0.5297, 0.4703], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6564, 0.3436], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 350
agent= agent_6 distrib= tensor([0.7418, 0.2582], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4398, 0.5602], grad_fn=<SoftmaxBackward0>)
Epoch : 350 	 Measure: 0.5
==========>Epoch= 351
agent= agent_8 distrib= tensor([0.4666, 0.5334], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7611, 0.2389], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 352
agent= agent_7 distrib= tensor([0.5686, 0.4314], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7861, 0.2139], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 353
agent= agent_3 distrib= tensor([0.5156, 0.4844], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5721, 0.4279], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 354
agent= agent_4 distrib= tensor([0.7110, 0.2890], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4560, 0.5440], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 355
agent= agent_9 distrib= tensor([0.7590, 0.2410], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6676, 0.3324], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 356
agent= agent_6 distrib= tensor([0.7830, 0.2170], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4598, 0.5402], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 357
agent= agent_8 distrib= tensor([0.4524, 0.5476], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6567, 0.3433], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 358
agent= agent_4 distrib= tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4570, 0.5430], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 359
agent= agent_1 distrib= tensor([0.4511, 0.5489], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6793, 0.3207], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 360
agent= agent_4 distrib= tensor([0.7129, 0.2871], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7332, 0.2668], grad_fn=<SoftmaxBackward0>)
Epoch : 360 	 Measure: 0.5
==========>Epoch= 361
agent= agent_1 distrib= tensor([0.4191, 0.5809], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7440, 0.2560], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 362
agent= agent_0 distrib= tensor([0.5239, 0.4761], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4621, 0.5379], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 363
agent= agent_5 distrib= tensor([0.6755, 0.3245], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7461, 0.2539], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 364
agent= agent_9 distrib= tensor([0.6795, 0.3205], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6568, 0.3432], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 365
agent= agent_9 distrib= tensor([0.7564, 0.2436], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4632, 0.5368], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 366
agent= agent_4 distrib= tensor([0.7139, 0.2861], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5650, 0.4350], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 367
agent= agent_6 distrib= tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4243, 0.5757], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 368
agent= agent_7 distrib= tensor([0.5565, 0.4435], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4317, 0.5683], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 369
agent= agent_7 distrib= tensor([0.5735, 0.4265], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4653, 0.5347], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 370
agent= agent_0 distrib= tensor([0.5405, 0.4595], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5547, 0.4453], grad_fn=<SoftmaxBackward0>)
Epoch : 370 	 Measure: 0.6000000238418579
==========>Epoch= 371
agent= agent_5 distrib= tensor([0.6787, 0.3213], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5051, 0.4949], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 372
agent= agent_5 distrib= tensor([0.6775, 0.3225], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5292, 0.4708], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 373
agent= agent_6 distrib= tensor([0.7501, 0.2499], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5598, 0.4402], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 374
agent= agent_0 distrib= tensor([0.5297, 0.4703], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 375
agent= agent_0 distrib= tensor([0.5444, 0.4556], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6578, 0.3422], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 376
agent= agent_3 distrib= tensor([0.5188, 0.4812], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7519, 0.2481], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 377
agent= agent_1 distrib= tensor([0.4664, 0.5336], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6790, 0.3210], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 378
agent= agent_1 distrib= tensor([0.4662, 0.5338], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 379
agent= agent_1 distrib= tensor([0.4647, 0.5353], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7560, 0.2440], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 380
agent= agent_1 distrib= tensor([0.5108, 0.4892], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4552, 0.5448], grad_fn=<SoftmaxBackward0>)
Epoch : 380 	 Measure: 0.6000000238418579
==========>Epoch= 381
agent= agent_5 distrib= tensor([0.6787, 0.3213], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4663, 0.5337], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 382
agent= agent_5 distrib= tensor([0.6487, 0.3513], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4580, 0.5420], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 383
agent= agent_3 distrib= tensor([0.5183, 0.4817], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5603, 0.4397], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 384
agent= agent_4 distrib= tensor([0.7171, 0.2829], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6846, 0.3154], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 385
agent= agent_7 distrib= tensor([0.5522, 0.4478], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6809, 0.3191], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 386
agent= agent_2 distrib= tensor([0.6966, 0.3034], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5080, 0.4920], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 387
agent= agent_8 distrib= tensor([0.4619, 0.5381], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5576, 0.4424], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 388
agent= agent_6 distrib= tensor([0.8013, 0.1987], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7188, 0.2812], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 389
agent= agent_8 distrib= tensor([0.4406, 0.5594], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5493, 0.4507], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 390
agent= agent_9 distrib= tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7215, 0.2785], grad_fn=<SoftmaxBackward0>)
Epoch : 390 	 Measure: 0.6000000238418579
==========>Epoch= 391
agent= agent_4 distrib= tensor([0.7198, 0.2802], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5607, 0.4393], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 392
agent= agent_2 distrib= tensor([0.6571, 0.3429], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6849, 0.3151], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 393
agent= agent_1 distrib= tensor([0.5116, 0.4884], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7220, 0.2780], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 394
agent= agent_6 distrib= tensor([0.8038, 0.1962], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5566, 0.4434], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 395
agent= agent_8 distrib= tensor([0.4715, 0.5285], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5298, 0.4702], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 396
agent= agent_5 distrib= tensor([0.6555, 0.3445], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6628, 0.3372], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 397
agent= agent_3 distrib= tensor([0.5043, 0.4957], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6785, 0.3215], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 398
agent= agent_9 distrib= tensor([0.7537, 0.2463], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4737, 0.5263], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 399
agent= agent_1 distrib= tensor([0.4669, 0.5331], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7638, 0.2362], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 400
agent= agent_3 distrib= tensor([0.5262, 0.4738], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6632, 0.3368], grad_fn=<SoftmaxBackward0>)
Epoch : 400 	 Measure: 0.699999988079071
==========>Epoch= 401
agent= agent_1 distrib= tensor([0.4314, 0.5686], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5132, 0.4868], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 402
agent= agent_8 distrib= tensor([0.4745, 0.5255], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5285, 0.4715], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 403
agent= agent_3 distrib= tensor([0.5184, 0.4816], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 404
agent= agent_4 distrib= tensor([0.7216, 0.2784], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5121, 0.4879], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 405
agent= agent_0 distrib= tensor([0.5048, 0.4952], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7237, 0.2763], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 406
agent= agent_2 distrib= tensor([0.6790, 0.3210], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7511, 0.2489], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 407
agent= agent_3 distrib= tensor([0.5240, 0.4760], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4506, 0.5494], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 408
agent= agent_9 distrib= tensor([0.7169, 0.2831], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5096, 0.4904], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 409
agent= agent_7 distrib= tensor([0.5480, 0.4520], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6740, 0.3260], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 410
agent= agent_5 distrib= tensor([0.6786, 0.3214], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)
Epoch : 410 	 Measure: 0.4000000059604645
==========>Epoch= 411
agent= agent_0 distrib= tensor([0.5426, 0.4574], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4512, 0.5488], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 412
agent= agent_8 distrib= tensor([0.4790, 0.5210], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5053, 0.4947], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 413
agent= agent_4 distrib= tensor([0.6691, 0.3309], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6573, 0.3427], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 414
agent= agent_1 distrib= tensor([0.4659, 0.5341], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6797, 0.3203], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 415
agent= agent_3 distrib= tensor([0.5024, 0.4976], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6799, 0.3201], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 416
agent= agent_1 distrib= tensor([0.4300, 0.5700], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6538, 0.3462], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 417
agent= agent_2 distrib= tensor([0.6752, 0.3248], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.6710, 0.3290], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 418
agent= agent_0 distrib= tensor([0.5058, 0.4942], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4312, 0.5688], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 419
agent= agent_1 distrib= tensor([0.4693, 0.5307], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 420
agent= agent_1 distrib= tensor([0.4664, 0.5336], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5273, 0.4727], grad_fn=<SoftmaxBackward0>)
Epoch : 420 	 Measure: 0.699999988079071
==========>Epoch= 421
agent= agent_7 distrib= tensor([0.5475, 0.4525], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5432, 0.4568], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 422
agent= agent_7 distrib= tensor([0.5680, 0.4320], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4665, 0.5335], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 423
agent= agent_8 distrib= tensor([0.4781, 0.5219], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8066, 0.1934], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 424
agent= agent_4 distrib= tensor([0.7741, 0.2259], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6836, 0.3164], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 425
agent= agent_0 distrib= tensor([0.5598, 0.4402], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6574, 0.3426], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 426
agent= agent_4 distrib= tensor([0.6763, 0.3237], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5479, 0.4521], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 427
agent= agent_5 distrib= tensor([0.6591, 0.3409], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8103, 0.1897], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 428
agent= agent_0 distrib= tensor([0.5607, 0.4393], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6609, 0.3391], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 429
agent= agent_9 distrib= tensor([0.7157, 0.2843], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6627, 0.3373], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 430
agent= agent_1 distrib= tensor([0.4321, 0.5679], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7218, 0.2782], grad_fn=<SoftmaxBackward0>)
Epoch : 430 	 Measure: 0.6000000238418579
==========>Epoch= 431
agent= agent_9 distrib= tensor([0.7202, 0.2798], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5140, 0.4860], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 432
agent= agent_3 distrib= tensor([0.5048, 0.4952], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7351, 0.2649], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 433
agent= agent_1 distrib= tensor([0.4709, 0.5291], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5150, 0.4850], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 434
agent= agent_0 distrib= tensor([0.5303, 0.4697], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7401, 0.2599], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 435
agent= agent_5 distrib= tensor([0.6904, 0.3096], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8061, 0.1939], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 436
agent= agent_5 distrib= tensor([0.6708, 0.3292], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7677, 0.2323], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 437
agent= agent_4 distrib= tensor([0.7379, 0.2621], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5083, 0.4917], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 438
agent= agent_3 distrib= tensor([0.5013, 0.4987], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7413, 0.2587], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 439
agent= agent_5 distrib= tensor([0.6694, 0.3306], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4700, 0.5300], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 440
agent= agent_9 distrib= tensor([0.7150, 0.2850], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5636, 0.4364], grad_fn=<SoftmaxBackward0>)
Epoch : 440 	 Measure: 0.6000000238418579
==========>Epoch= 441
agent= agent_7 distrib= tensor([0.5583, 0.4417], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4817, 0.5183], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 442
agent= agent_6 distrib= tensor([0.7663, 0.2337], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6639, 0.3361], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 443
agent= agent_6 distrib= tensor([0.8034, 0.1966], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4656, 0.5344], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 444
agent= agent_9 distrib= tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6887, 0.3113], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 445
agent= agent_3 distrib= tensor([0.4962, 0.5038], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7888, 0.2112], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 446
agent= agent_0 distrib= tensor([0.5332, 0.4668], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4782, 0.5218], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 447
agent= agent_9 distrib= tensor([0.6616, 0.3384], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4590, 0.5410], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 448
agent= agent_9 distrib= tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6879, 0.3121], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 449
agent= agent_0 distrib= tensor([0.5656, 0.4344], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7617, 0.2383], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 450
agent= agent_9 distrib= tensor([0.6616, 0.3384], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5094, 0.4906], grad_fn=<SoftmaxBackward0>)
Epoch : 450 	 Measure: 0.30000001192092896
==========>Epoch= 451
agent= agent_2 distrib= tensor([0.6759, 0.3241], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5494, 0.4506], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 452
agent= agent_9 distrib= tensor([0.7086, 0.2914], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7488, 0.2512], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 453
agent= agent_0 distrib= tensor([0.5351, 0.4649], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 454
agent= agent_8 distrib= tensor([0.4607, 0.5393], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7641, 0.2359], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 455
agent= agent_2 distrib= tensor([0.6833, 0.3167], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7302, 0.2698], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 456
agent= agent_5 distrib= tensor([0.6583, 0.3417], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4307, 0.5693], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 457
agent= agent_4 distrib= tensor([0.7597, 0.2403], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8072, 0.1928], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 458
agent= agent_5 distrib= tensor([0.6666, 0.3334], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4622, 0.5378], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 459
agent= agent_9 distrib= tensor([0.7279, 0.2721], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5731, 0.4269], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 460
agent= agent_2 distrib= tensor([0.6829, 0.3171], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5360, 0.4640], grad_fn=<SoftmaxBackward0>)
Epoch : 460 	 Measure: 0.30000001192092896
==========>Epoch= 461
agent= agent_6 distrib= tensor([0.7645, 0.2355], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5512, 0.4488], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 462
agent= agent_8 distrib= tensor([0.4636, 0.5364], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4686, 0.5314], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 463
agent= agent_1 distrib= tensor([0.4648, 0.5352], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8032, 0.1968], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 464
agent= agent_2 distrib= tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4635, 0.5365], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 465
agent= agent_6 distrib= tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4853, 0.5147], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 466
agent= agent_3 distrib= tensor([0.5075, 0.4925], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6751, 0.3249], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 467
agent= agent_8 distrib= tensor([0.4666, 0.5334], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6561, 0.3439], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 468
agent= agent_6 distrib= tensor([0.7589, 0.2411], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4281, 0.5719], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 469
agent= agent_2 distrib= tensor([0.6804, 0.3196], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4615, 0.5385], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 470
agent= agent_0 distrib= tensor([0.5674, 0.4326], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7577, 0.2423], grad_fn=<SoftmaxBackward0>)
Epoch : 470 	 Measure: 0.4000000059604645
==========>Epoch= 471
agent= agent_1 distrib= tensor([0.4672, 0.5328], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7605, 0.2395], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 472
agent= agent_2 distrib= tensor([0.6963, 0.3037], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7559, 0.2441], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 473
agent= agent_0 distrib= tensor([0.5355, 0.4645], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 474
agent= agent_7 distrib= tensor([0.5650, 0.4350], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4961, 0.5039], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 475
agent= agent_6 distrib= tensor([0.7552, 0.2448], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5674, 0.4326], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 476
agent= agent_7 distrib= tensor([0.5820, 0.4180], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7951, 0.2049], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 477
agent= agent_4 distrib= tensor([0.7074, 0.2926], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4670, 0.5330], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 478
agent= agent_1 distrib= tensor([0.4720, 0.5280], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6536, 0.3464], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 479
agent= agent_2 distrib= tensor([0.6802, 0.3198], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4944, 0.5056], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 480
agent= agent_4 distrib= tensor([0.7661, 0.2339], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6588, 0.3412], grad_fn=<SoftmaxBackward0>)
Epoch : 480 	 Measure: 0.699999988079071
==========>Epoch= 481
agent= agent_5 distrib= tensor([0.6889, 0.3111], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5852, 0.4148], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 482
agent= agent_8 distrib= tensor([0.4946, 0.5054], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5733, 0.4267], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 483
agent= agent_2 distrib= tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6513, 0.3487], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 484
agent= agent_7 distrib= tensor([0.5654, 0.4346], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6493, 0.3507], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 485
agent= agent_9 distrib= tensor([0.7174, 0.2826], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8121, 0.1879], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 486
agent= agent_3 distrib= tensor([0.5035, 0.4965], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4590, 0.5410], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 487
agent= agent_1 distrib= tensor([0.4708, 0.5292], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7161, 0.2839], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 488
agent= agent_1 distrib= tensor([0.4409, 0.5591], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5798, 0.4202], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 489
agent= agent_8 distrib= tensor([0.4597, 0.5403], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6992, 0.3008], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 490
agent= agent_5 distrib= tensor([0.6609, 0.3391], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4444, 0.5556], grad_fn=<SoftmaxBackward0>)
Epoch : 490 	 Measure: 0.30000001192092896
==========>Epoch= 491
agent= agent_6 distrib= tensor([0.7547, 0.2453], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7005, 0.2995], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 492
agent= agent_5 distrib= tensor([0.6708, 0.3292], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4695, 0.5305], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 493
agent= agent_2 distrib= tensor([0.6850, 0.3150], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4936, 0.5064], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 494
agent= agent_6 distrib= tensor([0.7548, 0.2452], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4980, 0.5020], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 495
agent= agent_3 distrib= tensor([0.5023, 0.4977], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6644, 0.3356], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 496
agent= agent_2 distrib= tensor([0.6844, 0.3156], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5712, 0.4288], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 497
agent= agent_1 distrib= tensor([0.5273, 0.4727], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7020, 0.2980], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 498
agent= agent_2 distrib= tensor([0.6900, 0.3100], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4932, 0.5068], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 499
agent= agent_8 distrib= tensor([0.4991, 0.5009], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7774, 0.2226], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 500
agent= agent_0 distrib= tensor([0.5354, 0.4646], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6023, 0.3977], grad_fn=<SoftmaxBackward0>)
Epoch : 500 	 Measure: 0.20000000298023224
==========>Epoch= 501
agent= agent_2 distrib= tensor([0.6877, 0.3123], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.5766, 0.4234], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 502
agent= agent_1 distrib= tensor([0.5301, 0.4699], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7037, 0.2963], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 503
agent= agent_7 distrib= tensor([0.5911, 0.4089], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7110, 0.2890], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 504
agent= agent_7 distrib= tensor([0.5945, 0.4055], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5016, 0.4984], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 505
agent= agent_3 distrib= tensor([0.4982, 0.5018], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4921, 0.5079], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 506
agent= agent_7 distrib= tensor([0.5860, 0.4140], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4724, 0.5276], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 507
agent= agent_6 distrib= tensor([0.7592, 0.2408], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6467, 0.3533], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 508
agent= agent_8 distrib= tensor([0.4642, 0.5358], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7054, 0.2946], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 509
agent= agent_5 distrib= tensor([0.7079, 0.2921], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7821, 0.2179], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 510
agent= agent_3 distrib= tensor([0.5011, 0.4989], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5114, 0.4886], grad_fn=<SoftmaxBackward0>)
Epoch : 510 	 Measure: 0.699999988079071
==========>Epoch= 511
agent= agent_3 distrib= tensor([0.5016, 0.4984], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 512
agent= agent_2 distrib= tensor([0.6738, 0.3262], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 513
agent= agent_9 distrib= tensor([0.7154, 0.2846], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4949, 0.5051], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 514
agent= agent_2 distrib= tensor([0.7151, 0.2849], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.6732, 0.3268], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 515
agent= agent_6 distrib= tensor([0.8011, 0.1989], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 516
agent= agent_5 distrib= tensor([0.6838, 0.3162], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4995, 0.5005], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 517
agent= agent_9 distrib= tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5678, 0.4322], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 518
agent= agent_9 distrib= tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5682, 0.4318], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 519
agent= agent_5 distrib= tensor([0.6788, 0.3212], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6860, 0.3140], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 520
agent= agent_6 distrib= tensor([0.7960, 0.2040], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4979, 0.5021], grad_fn=<SoftmaxBackward0>)
Epoch : 520 	 Measure: 0.5
==========>Epoch= 521
agent= agent_7 distrib= tensor([0.6083, 0.3917], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.4963, 0.5037], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 522
agent= agent_4 distrib= tensor([0.7922, 0.2078], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6926, 0.3074], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 523
agent= agent_1 distrib= tensor([0.4564, 0.5436], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.6790, 0.3210], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 524
agent= agent_9 distrib= tensor([0.6933, 0.3067], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5697, 0.4303], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 525
agent= agent_8 distrib= tensor([0.5020, 0.4980], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7563, 0.2437], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 526
agent= agent_5 distrib= tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5713, 0.4287], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 527
agent= agent_9 distrib= tensor([0.6940, 0.3060], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5739, 0.4261], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 528
agent= agent_1 distrib= tensor([0.4919, 0.5081], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6269, 0.3731], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 529
agent= agent_0 distrib= tensor([0.5431, 0.4569], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4961, 0.5039], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 530
agent= agent_9 distrib= tensor([0.6474, 0.3526], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7436, 0.2564], grad_fn=<SoftmaxBackward0>)
Epoch : 530 	 Measure: 0.5
==========>Epoch= 531
agent= agent_5 distrib= tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5425, 0.4575], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 532
agent= agent_4 distrib= tensor([0.7999, 0.2001], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4667, 0.5333], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 533
agent= agent_1 distrib= tensor([0.5457, 0.4543], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 534
agent= agent_2 distrib= tensor([0.7039, 0.2961], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4995, 0.5005], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 535
agent= agent_1 distrib= tensor([0.5092, 0.4908], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 536
agent= agent_2 distrib= tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7238, 0.2762], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 537
agent= agent_7 distrib= tensor([0.6004, 0.3996], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5596, 0.4404], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 538
agent= agent_4 distrib= tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5011, 0.4989], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 539
agent= agent_7 distrib= tensor([0.6379, 0.3621], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5005, 0.4995], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 540
agent= agent_4 distrib= tensor([0.8471, 0.1529], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7183, 0.2817], grad_fn=<SoftmaxBackward0>)
Epoch : 540 	 Measure: 0.4000000059604645
==========>Epoch= 541
agent= agent_9 distrib= tensor([0.6486, 0.3514], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5615, 0.4385], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 542
agent= agent_3 distrib= tensor([0.5000, 0.5000], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5835, 0.4165], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 543
agent= agent_7 distrib= tensor([0.6412, 0.3588], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7200, 0.2800], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 544
agent= agent_4 distrib= tensor([0.8156, 0.1844], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5867, 0.4133], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 545
agent= agent_6 distrib= tensor([0.7573, 0.2427], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5123, 0.4877], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 546
agent= agent_2 distrib= tensor([0.6843, 0.3157], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7263, 0.2737], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 547
agent= agent_4 distrib= tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5073, 0.4927], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 548
agent= agent_4 distrib= tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8030, 0.1970], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 549
agent= agent_7 distrib= tensor([0.6131, 0.3869], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4785, 0.5215], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 550
agent= agent_1 distrib= tensor([0.5058, 0.4942], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7982, 0.2018], grad_fn=<SoftmaxBackward0>)
Epoch : 550 	 Measure: 0.699999988079071
==========>Epoch= 551
agent= agent_4 distrib= tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5073, 0.4927], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 552
agent= agent_0 distrib= tensor([0.5686, 0.4314], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4790, 0.5210], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 553
agent= agent_2 distrib= tensor([0.7254, 0.2746], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4678, 0.5322], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 554
agent= agent_7 distrib= tensor([0.6360, 0.3640], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5273, 0.4727], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 555
agent= agent_0 distrib= tensor([0.5293, 0.4707], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7294, 0.2706], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 556
agent= agent_1 distrib= tensor([0.5091, 0.4909], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7116, 0.2884], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 557
agent= agent_8 distrib= tensor([0.4775, 0.5225], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 558
agent= agent_9 distrib= tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4984, 0.5016], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 559
agent= agent_8 distrib= tensor([0.5072, 0.4928], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7592, 0.2408], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 560
agent= agent_0 distrib= tensor([0.5312, 0.4688], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4833, 0.5167], grad_fn=<SoftmaxBackward0>)
Epoch : 560 	 Measure: 0.4000000059604645
==========>Epoch= 561
agent= agent_4 distrib= tensor([0.8343, 0.1657], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.4879, 0.5121], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 562
agent= agent_7 distrib= tensor([0.6203, 0.3797], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7829, 0.2171], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 563
agent= agent_6 distrib= tensor([0.7609, 0.2391], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5974, 0.4026], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 564
agent= agent_2 distrib= tensor([0.6898, 0.3102], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5145, 0.4855], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 565
agent= agent_1 distrib= tensor([0.5671, 0.4329], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7324, 0.2676], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 566
agent= agent_7 distrib= tensor([0.6351, 0.3649], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7360, 0.2640], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 567
agent= agent_7 distrib= tensor([0.6235, 0.3765], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 568
agent= agent_7 distrib= tensor([0.6383, 0.3617], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7299, 0.2701], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 569
agent= agent_5 distrib= tensor([0.7319, 0.2681], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6593, 0.3407], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 570
agent= agent_0 distrib= tensor([0.5770, 0.4230], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5108, 0.4892], grad_fn=<SoftmaxBackward0>)
Epoch : 570 	 Measure: 0.5
==========>Epoch= 571
agent= agent_2 distrib= tensor([0.7161, 0.2839], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8052, 0.1948], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 572
agent= agent_1 distrib= tensor([0.4959, 0.5041], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6994, 0.3006], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 573
agent= agent_6 distrib= tensor([0.7680, 0.2320], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6917, 0.3083], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 574
agent= agent_7 distrib= tensor([0.6276, 0.3724], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 575
agent= agent_2 distrib= tensor([0.7187, 0.2813], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 576
agent= agent_5 distrib= tensor([0.7134, 0.2866], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4797, 0.5203], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 577
agent= agent_3 distrib= tensor([0.5173, 0.4827], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5723, 0.4277], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 578
agent= agent_3 distrib= tensor([0.5133, 0.4867], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6624, 0.3376], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 579
agent= agent_1 distrib= tensor([0.5268, 0.4732], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4997, 0.5003], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 580
agent= agent_2 distrib= tensor([0.7119, 0.2881], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7839, 0.2161], grad_fn=<SoftmaxBackward0>)
Epoch : 580 	 Measure: 0.6000000238418579
==========>Epoch= 581
agent= agent_1 distrib= tensor([0.5768, 0.4232], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7457, 0.2543], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 582
agent= agent_5 distrib= tensor([0.7116, 0.2884], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6010, 0.3990], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 583
agent= agent_3 distrib= tensor([0.5152, 0.4848], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 584
agent= agent_7 distrib= tensor([0.6312, 0.3688], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5174, 0.4826], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 585
agent= agent_3 distrib= tensor([0.5202, 0.4798], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7415, 0.2585], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 586
agent= agent_6 distrib= tensor([0.7684, 0.2316], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8340, 0.1660], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 587
agent= agent_9 distrib= tensor([0.6496, 0.3504], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5789, 0.4211], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 588
agent= agent_1 distrib= tensor([0.5438, 0.4562], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 589
agent= agent_8 distrib= tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 590
agent= agent_1 distrib= tensor([0.5369, 0.4631], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6673, 0.3327], grad_fn=<SoftmaxBackward0>)
Epoch : 590 	 Measure: 0.6000000238418579
==========>Epoch= 591
agent= agent_9 distrib= tensor([0.6894, 0.3106], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4714, 0.5286], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 592
agent= agent_9 distrib= tensor([0.6961, 0.3039], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6539, 0.3461], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 593
agent= agent_2 distrib= tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5672, 0.4328], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 594
agent= agent_8 distrib= tensor([0.4846, 0.5154], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5211, 0.4789], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 595
agent= agent_7 distrib= tensor([0.6477, 0.3523], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5291, 0.4709], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 596
agent= agent_7 distrib= tensor([0.6482, 0.3518], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 597
agent= agent_2 distrib= tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7201, 0.2799], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 598
agent= agent_3 distrib= tensor([0.5277, 0.4723], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7251, 0.2749], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 599
agent= agent_3 distrib= tensor([0.5258, 0.4742], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6017, 0.3983], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 600
agent= agent_2 distrib= tensor([0.7181, 0.2819], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)
Epoch : 600 	 Measure: 0.5
==========>Epoch= 601
agent= agent_7 distrib= tensor([0.6350, 0.3650], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4863, 0.5137], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 602
agent= agent_2 distrib= tensor([0.7443, 0.2557], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7131, 0.2869], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 603
agent= agent_5 distrib= tensor([0.7225, 0.2775], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7223, 0.2777], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 604
agent= agent_3 distrib= tensor([0.5322, 0.4678], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5386, 0.4614], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 605
agent= agent_1 distrib= tensor([0.5139, 0.4861], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6479, 0.3521], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 606
agent= agent_0 distrib= tensor([0.6031, 0.3969], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6960, 0.3040], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 607
agent= agent_3 distrib= tensor([0.5323, 0.4677], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6333, 0.3667], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 608
agent= agent_5 distrib= tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6960, 0.3040], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 609
agent= agent_4 distrib= tensor([0.8361, 0.1639], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6961, 0.3039], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 610
agent= agent_6 distrib= tensor([0.7697, 0.2303], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8371, 0.1629], grad_fn=<SoftmaxBackward0>)
Epoch : 610 	 Measure: 0.6000000238418579
==========>Epoch= 611
agent= agent_8 distrib= tensor([0.4867, 0.5133], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7730, 0.2270], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 612
agent= agent_3 distrib= tensor([0.5398, 0.4602], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6964, 0.3036], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 613
agent= agent_9 distrib= tensor([0.6973, 0.3027], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5158, 0.4842], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 614
agent= agent_6 distrib= tensor([0.8107, 0.1893], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7490, 0.2510], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 615
agent= agent_1 distrib= tensor([0.5445, 0.4555], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7210, 0.2790], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 616
agent= agent_7 distrib= tensor([0.6668, 0.3332], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5067, 0.4933], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 617
agent= agent_5 distrib= tensor([0.7593, 0.2407], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7719, 0.2281], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 618
agent= agent_3 distrib= tensor([0.5359, 0.4641], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5205, 0.4795], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 619
agent= agent_7 distrib= tensor([0.6468, 0.3532], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6045, 0.3955], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 620
agent= agent_8 distrib= tensor([0.4782, 0.5218], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6886, 0.3114], grad_fn=<SoftmaxBackward0>)
Epoch : 620 	 Measure: 0.6000000238418579
==========>Epoch= 621
agent= agent_6 distrib= tensor([0.8172, 0.1828], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5390, 0.4610], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 622
agent= agent_5 distrib= tensor([0.7618, 0.2382], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7065, 0.2935], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 623
agent= agent_1 distrib= tensor([0.5947, 0.4053], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6070, 0.3930], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 624
agent= agent_8 distrib= tensor([0.4794, 0.5206], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6522, 0.3478], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 625
agent= agent_8 distrib= tensor([0.5090, 0.4910], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5751, 0.4249], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 626
agent= agent_7 distrib= tensor([0.6451, 0.3549], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8382, 0.1618], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 627
agent= agent_3 distrib= tensor([0.5460, 0.4540], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8144, 0.1856], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 628
agent= agent_7 distrib= tensor([0.6439, 0.3561], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5483, 0.4517], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 629
agent= agent_3 distrib= tensor([0.5454, 0.4546], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7258, 0.2742], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 630
agent= agent_6 distrib= tensor([0.7761, 0.2239], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5523, 0.4477], grad_fn=<SoftmaxBackward0>)
Epoch : 630 	 Measure: 0.5
==========>Epoch= 631
agent= agent_4 distrib= tensor([0.8763, 0.1237], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7194, 0.2806], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 632
agent= agent_6 distrib= tensor([0.7778, 0.2222], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6875, 0.3125], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 633
agent= agent_8 distrib= tensor([0.4896, 0.5104], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7823, 0.2177], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 634
agent= agent_0 distrib= tensor([0.6116, 0.3884], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7098, 0.2902], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 635
agent= agent_7 distrib= tensor([0.6439, 0.3561], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6138, 0.3862], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 636
agent= agent_0 distrib= tensor([0.5909, 0.4091], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7288, 0.2712], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 637
agent= agent_3 distrib= tensor([0.5557, 0.4443], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7398, 0.2602], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 638
agent= agent_8 distrib= tensor([0.4817, 0.5183], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8265, 0.1735], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 639
agent= agent_0 distrib= tensor([0.6147, 0.3853], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6959, 0.3041], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 640
agent= agent_3 distrib= tensor([0.5563, 0.4437], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7831, 0.2169], grad_fn=<SoftmaxBackward0>)
Epoch : 640 	 Measure: 0.4000000059604645
==========>Epoch= 641
agent= agent_6 distrib= tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6462, 0.3538], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 642
agent= agent_1 distrib= tensor([0.5615, 0.4385], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 643
agent= agent_3 distrib= tensor([0.5599, 0.4401], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 644
agent= agent_9 distrib= tensor([0.6963, 0.3037], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6447, 0.3553], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 645
agent= agent_0 distrib= tensor([0.5920, 0.4080], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 646
agent= agent_2 distrib= tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5630, 0.4370], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 647
agent= agent_9 distrib= tensor([0.7205, 0.2795], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 648
agent= agent_4 distrib= tensor([0.7913, 0.2087], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6246, 0.3754], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 649
agent= agent_2 distrib= tensor([0.7367, 0.2633], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7855, 0.2145], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 650
agent= agent_3 distrib= tensor([0.5569, 0.4431], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)
Epoch : 650 	 Measure: 0.5
==========>Epoch= 651
agent= agent_5 distrib= tensor([0.7351, 0.2649], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6512, 0.3488], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 652
agent= agent_9 distrib= tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5614, 0.4386], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 653
agent= agent_3 distrib= tensor([0.5612, 0.4388], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5925, 0.4075], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 654
agent= agent_8 distrib= tensor([0.5191, 0.4809], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7029, 0.2971], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 655
agent= agent_2 distrib= tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 656
agent= agent_4 distrib= tensor([0.8504, 0.1496], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6423, 0.3577], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 657
agent= agent_8 distrib= tensor([0.4814, 0.5186], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7685, 0.2315], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 658
agent= agent_6 distrib= tensor([0.8248, 0.1752], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5689, 0.4311], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 659
agent= agent_1 distrib= tensor([0.5629, 0.4371], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.7957, 0.2043], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 660
agent= agent_9 distrib= tensor([0.7047, 0.2953], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6415, 0.3585], grad_fn=<SoftmaxBackward0>)
Epoch : 660 	 Measure: 0.699999988079071
==========>Epoch= 661
agent= agent_0 distrib= tensor([0.5819, 0.4181], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6571, 0.3429], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 662
agent= agent_1 distrib= tensor([0.5968, 0.4032], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6424, 0.3576], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 663
agent= agent_0 distrib= tensor([0.5520, 0.4480], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8468, 0.1532], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 664
agent= agent_0 distrib= tensor([0.5852, 0.4148], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6580, 0.3420], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 665
agent= agent_7 distrib= tensor([0.6399, 0.3601], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8490, 0.1510], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 666
agent= agent_3 distrib= tensor([0.5710, 0.4290], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7496, 0.2504], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 667
agent= agent_4 distrib= tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7274, 0.2726], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 668
agent= agent_8 distrib= tensor([0.5187, 0.4813], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7281, 0.2719], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 669
agent= agent_1 distrib= tensor([0.5629, 0.4371], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5974, 0.4026], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 670
agent= agent_7 distrib= tensor([0.6406, 0.3594], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6233, 0.3767], grad_fn=<SoftmaxBackward0>)
Epoch : 670 	 Measure: 0.20000000298023224
==========>Epoch= 671
agent= agent_0 distrib= tensor([0.6257, 0.3743], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7282, 0.2718], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 672
agent= agent_7 distrib= tensor([0.6261, 0.3739], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5679, 0.4321], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 673
agent= agent_0 distrib= tensor([0.6042, 0.3958], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 674
agent= agent_5 distrib= tensor([0.7379, 0.2621], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7395, 0.2605], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 675
agent= agent_2 distrib= tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 676
agent= agent_9 distrib= tensor([0.6585, 0.3415], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5630, 0.4370], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 677
agent= agent_7 distrib= tensor([0.6612, 0.3388], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5114, 0.4886], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 678
agent= agent_0 distrib= tensor([0.5960, 0.4040], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6603, 0.3397], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 679
agent= agent_9 distrib= tensor([0.6587, 0.3413], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6092, 0.3908], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 680
agent= agent_1 distrib= tensor([0.5957, 0.4043], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6357, 0.3643], grad_fn=<SoftmaxBackward0>)
Epoch : 680 	 Measure: 0.800000011920929
==========>Epoch= 681
agent= agent_9 distrib= tensor([0.7301, 0.2699], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7529, 0.2471], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 682
agent= agent_1 distrib= tensor([0.5218, 0.4782], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7102, 0.2898], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 683
agent= agent_0 distrib= tensor([0.5707, 0.4293], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7691, 0.2309], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 684
agent= agent_2 distrib= tensor([0.7673, 0.2327], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 685
agent= agent_1 distrib= tensor([0.5912, 0.4088], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8298, 0.1702], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 686
agent= agent_7 distrib= tensor([0.6447, 0.3553], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8637, 0.1363], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 687
agent= agent_9 distrib= tensor([0.7120, 0.2880], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6442, 0.3558], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 688
agent= agent_1 distrib= tensor([0.5551, 0.4449], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8111, 0.1889], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 689
agent= agent_1 distrib= tensor([0.5879, 0.4121], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6439, 0.3561], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 690
agent= agent_0 distrib= tensor([0.5721, 0.4279], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5710, 0.4290], grad_fn=<SoftmaxBackward0>)
Epoch : 690 	 Measure: 0.4000000059604645
==========>Epoch= 691
agent= agent_3 distrib= tensor([0.5717, 0.4283], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5530, 0.4470], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 692
agent= agent_5 distrib= tensor([0.7697, 0.2303], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7266, 0.2734], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 693
agent= agent_7 distrib= tensor([0.6395, 0.3605], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8608, 0.1392], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 694
agent= agent_9 distrib= tensor([0.6618, 0.3382], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6162, 0.3838], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 695
agent= agent_5 distrib= tensor([0.7621, 0.2379], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7370, 0.2630], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 696
agent= agent_9 distrib= tensor([0.7372, 0.2628], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 697
agent= agent_7 distrib= tensor([0.6250, 0.3750], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5512, 0.4488], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 698
agent= agent_7 distrib= tensor([0.6579, 0.3421], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7606, 0.2394], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 699
agent= agent_1 distrib= tensor([0.5394, 0.4606], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5095, 0.4905], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 700
agent= agent_1 distrib= tensor([0.5121, 0.4879], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7165, 0.2835], grad_fn=<SoftmaxBackward0>)
Epoch : 700 	 Measure: 0.6000000238418579
==========>Epoch= 701
agent= agent_7 distrib= tensor([0.6422, 0.3578], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 702
agent= agent_8 distrib= tensor([0.5065, 0.4935], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8284, 0.1716], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 703
agent= agent_5 distrib= tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7911, 0.2089], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 704
agent= agent_1 distrib= tensor([0.5116, 0.4884], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5768, 0.4232], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 705
agent= agent_2 distrib= tensor([0.7289, 0.2711], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5114, 0.4886], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 706
agent= agent_6 distrib= tensor([0.7922, 0.2078], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6227, 0.3773], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 707
agent= agent_9 distrib= tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5771, 0.4229], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 708
agent= agent_7 distrib= tensor([0.6533, 0.3467], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5364, 0.4636], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 709
agent= agent_3 distrib= tensor([0.5730, 0.4270], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8184, 0.1816], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 710
agent= agent_6 distrib= tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7380, 0.2620], grad_fn=<SoftmaxBackward0>)
Epoch : 710 	 Measure: 0.30000001192092896
==========>Epoch= 711
agent= agent_7 distrib= tensor([0.6213, 0.3787], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7459, 0.2541], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 712
agent= agent_9 distrib= tensor([0.7178, 0.2822], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 713
agent= agent_9 distrib= tensor([0.6668, 0.3332], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6207, 0.3793], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 714
agent= agent_1 distrib= tensor([0.5818, 0.4182], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8681, 0.1319], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 715
agent= agent_7 distrib= tensor([0.6384, 0.3616], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7189, 0.2811], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 716
agent= agent_4 distrib= tensor([0.8243, 0.1757], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 717
agent= agent_3 distrib= tensor([0.5747, 0.4253], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6347, 0.3653], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 718
agent= agent_1 distrib= tensor([0.5828, 0.4172], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6377, 0.3623], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 719
agent= agent_0 distrib= tensor([0.6200, 0.3800], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4829, 0.5171], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 720
agent= agent_4 distrib= tensor([0.8259, 0.1741], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4802, 0.5198], grad_fn=<SoftmaxBackward0>)
Epoch : 720 	 Measure: 0.5
==========>Epoch= 721
agent= agent_2 distrib= tensor([0.7602, 0.2398], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 722
agent= agent_7 distrib= tensor([0.6323, 0.3677], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5074, 0.4926], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 723
agent= agent_0 distrib= tensor([0.6203, 0.3797], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4761, 0.5239], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 724
agent= agent_2 distrib= tensor([0.7743, 0.2257], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6323, 0.3677], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 725
agent= agent_5 distrib= tensor([0.7633, 0.2367], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7201, 0.2799], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 726
agent= agent_8 distrib= tensor([0.4617, 0.5383], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7617, 0.2383], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 727
agent= agent_4 distrib= tensor([0.8806, 0.1194], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7085, 0.2915], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 728
agent= agent_1 distrib= tensor([0.5495, 0.4505], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5736, 0.4264], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 729
agent= agent_9 distrib= tensor([0.7422, 0.2578], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 730
agent= agent_7 distrib= tensor([0.6205, 0.3795], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6711, 0.3289], grad_fn=<SoftmaxBackward0>)
Epoch : 730 	 Measure: 0.699999988079071
==========>Epoch= 731
agent= agent_0 distrib= tensor([0.6191, 0.3809], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7972, 0.2028], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 732
agent= agent_9 distrib= tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7633, 0.2367], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 733
agent= agent_4 distrib= tensor([0.8820, 0.1180], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5000, 0.5000], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 734
agent= agent_9 distrib= tensor([0.7433, 0.2567], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5415, 0.4585], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 735
agent= agent_9 distrib= tensor([0.6717, 0.3283], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7967, 0.2033], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 736
agent= agent_2 distrib= tensor([0.7755, 0.2245], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5769, 0.4231], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 737
agent= agent_1 distrib= tensor([0.5888, 0.4112], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7754, 0.2246], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 738
agent= agent_5 distrib= tensor([0.7516, 0.2484], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 739
agent= agent_2 distrib= tensor([0.7357, 0.2643], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7101, 0.2899], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 740
agent= agent_7 distrib= tensor([0.6496, 0.3504], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7418, 0.2582], grad_fn=<SoftmaxBackward0>)
Epoch : 740 	 Measure: 0.5
==========>Epoch= 741
agent= agent_7 distrib= tensor([0.6223, 0.3777], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7522, 0.2478], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 742
agent= agent_6 distrib= tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 743
agent= agent_1 distrib= tensor([0.5451, 0.4549], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6533, 0.3467], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 744
agent= agent_0 distrib= tensor([0.5753, 0.4247], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7778, 0.2222], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 745
agent= agent_8 distrib= tensor([0.4887, 0.5113], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5806, 0.4194], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 746
agent= agent_7 distrib= tensor([0.6264, 0.3736], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7333, 0.2667], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 747
agent= agent_6 distrib= tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 748
agent= agent_5 distrib= tensor([0.7508, 0.2492], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8357, 0.1643], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 749
agent= agent_8 distrib= tensor([0.4679, 0.5321], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7345, 0.2655], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 750
agent= agent_9 distrib= tensor([0.7415, 0.2585], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4884, 0.5116], grad_fn=<SoftmaxBackward0>)
Epoch : 750 	 Measure: 0.6000000238418579
==========>Epoch= 751
agent= agent_1 distrib= tensor([0.5467, 0.4533], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5807, 0.4193], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 752
agent= agent_9 distrib= tensor([0.7084, 0.2916], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7982, 0.2018], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 753
agent= agent_6 distrib= tensor([0.7971, 0.2029], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5587, 0.4413], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 754
agent= agent_2 distrib= tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 755
agent= agent_2 distrib= tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7987, 0.2013], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 756
agent= agent_9 distrib= tensor([0.7378, 0.2622], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4871, 0.5129], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 757
agent= agent_0 distrib= tensor([0.6130, 0.3870], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6700, 0.3300], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 758
agent= agent_7 distrib= tensor([0.6280, 0.3720], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6697, 0.3303], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 759
agent= agent_3 distrib= tensor([0.5743, 0.4257], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 760
agent= agent_5 distrib= tensor([0.7512, 0.2488], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6049, 0.3951], grad_fn=<SoftmaxBackward0>)
Epoch : 760 	 Measure: 0.30000001192092896
==========>Epoch= 761
agent= agent_7 distrib= tensor([0.6295, 0.3705], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7550, 0.2450], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 762
agent= agent_3 distrib= tensor([0.5739, 0.4261], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5606, 0.4394], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 763
agent= agent_1 distrib= tensor([0.5544, 0.4456], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7361, 0.2639], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 764
agent= agent_9 distrib= tensor([0.7183, 0.2817], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5743, 0.4257], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 765
agent= agent_6 distrib= tensor([0.7977, 0.2023], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5646, 0.4354], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 766
agent= agent_6 distrib= tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4950, 0.5050], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 767
agent= agent_2 distrib= tensor([0.7790, 0.2210], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5748, 0.4252], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 768
agent= agent_8 distrib= tensor([0.4523, 0.5477], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5339, 0.4661], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 769
agent= agent_8 distrib= tensor([0.4930, 0.5070], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5758, 0.4242], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 770
agent= agent_1 distrib= tensor([0.5381, 0.4619], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)
Epoch : 770 	 Measure: 0.699999988079071
==========>Epoch= 771
agent= agent_2 distrib= tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7514, 0.2486], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 772
agent= agent_5 distrib= tensor([0.7365, 0.2635], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8355, 0.1645], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 773
agent= agent_3 distrib= tensor([0.5822, 0.4178], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7521, 0.2479], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 774
agent= agent_3 distrib= tensor([0.5759, 0.4241], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 775
agent= agent_5 distrib= tensor([0.7637, 0.2363], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 776
agent= agent_2 distrib= tensor([0.7544, 0.2456], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7960, 0.2040], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 777
agent= agent_2 distrib= tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6066, 0.3934], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 778
agent= agent_5 distrib= tensor([0.7523, 0.2477], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7361, 0.2639], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 779
agent= agent_0 distrib= tensor([0.6128, 0.3872], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6718, 0.3282], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 780
agent= agent_8 distrib= tensor([0.4495, 0.5505], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6358, 0.3642], grad_fn=<SoftmaxBackward0>)
Epoch : 780 	 Measure: 0.6000000238418579
==========>Epoch= 781
agent= agent_8 distrib= tensor([0.4597, 0.5403], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7544, 0.2456], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 782
agent= agent_5 distrib= tensor([0.7257, 0.2743], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8373, 0.1627], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 783
agent= agent_3 distrib= tensor([0.5825, 0.4175], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4879, 0.5121], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 784
agent= agent_0 distrib= tensor([0.6069, 0.3931], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7654, 0.2346], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 785
agent= agent_0 distrib= tensor([0.6071, 0.3929], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 786
agent= agent_8 distrib= tensor([0.4869, 0.5131], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5827, 0.4173], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 787
agent= agent_5 distrib= tensor([0.7621, 0.2379], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5840, 0.4160], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 788
agent= agent_2 distrib= tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8387, 0.1613], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 789
agent= agent_8 distrib= tensor([0.4460, 0.5540], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7076, 0.2924], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 790
agent= agent_5 distrib= tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4768, 0.5232], grad_fn=<SoftmaxBackward0>)
Epoch : 790 	 Measure: 0.6000000238418579
==========>Epoch= 791
agent= agent_1 distrib= tensor([0.5421, 0.4579], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5853, 0.4147], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 792
agent= agent_7 distrib= tensor([0.6608, 0.3392], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7371, 0.2629], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 793
agent= agent_8 distrib= tensor([0.4846, 0.5154], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7206, 0.2794], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 794
agent= agent_1 distrib= tensor([0.5707, 0.4293], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7670, 0.2330], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 795
agent= agent_9 distrib= tensor([0.6749, 0.3251], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7328, 0.2672], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 796
agent= agent_6 distrib= tensor([0.7941, 0.2059], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6129, 0.3871], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 797
agent= agent_8 distrib= tensor([0.4843, 0.5157], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5756, 0.4244], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 798
agent= agent_3 distrib= tensor([0.5787, 0.4213], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7567, 0.2433], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 799
agent= agent_9 distrib= tensor([0.7403, 0.2597], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6082, 0.3918], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 800
agent= agent_8 distrib= tensor([0.4769, 0.5231], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8344, 0.1656], grad_fn=<SoftmaxBackward0>)
Epoch : 800 	 Measure: 0.699999988079071
==========>Epoch= 801
agent= agent_3 distrib= tensor([0.5878, 0.4122], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5494, 0.4506], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 802
agent= agent_7 distrib= tensor([0.6623, 0.3377], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5770, 0.4230], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 803
agent= agent_2 distrib= tensor([0.7701, 0.2299], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4778, 0.5222], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 804
agent= agent_6 distrib= tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7596, 0.2404], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 805
agent= agent_9 distrib= tensor([0.7125, 0.2875], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6459, 0.3541], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 806
agent= agent_3 distrib= tensor([0.5806, 0.4194], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 807
agent= agent_6 distrib= tensor([0.7945, 0.2055], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6359, 0.3641], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 808
agent= agent_5 distrib= tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 809
agent= agent_8 distrib= tensor([0.4469, 0.5531], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6350, 0.3650], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 810
agent= agent_3 distrib= tensor([0.5893, 0.4107], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7609, 0.2391], grad_fn=<SoftmaxBackward0>)
Epoch : 810 	 Measure: 0.4000000059604645
==========>Epoch= 811
agent= agent_9 distrib= tensor([0.7402, 0.2598], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 812
agent= agent_8 distrib= tensor([0.4480, 0.5520], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7615, 0.2385], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 813
agent= agent_0 distrib= tensor([0.6344, 0.3656], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7180, 0.2820], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 814
agent= agent_4 distrib= tensor([0.8416, 0.1584], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6351, 0.3649], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 815
agent= agent_0 distrib= tensor([0.6101, 0.3899], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5881, 0.4119], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 816
agent= agent_8 distrib= tensor([0.4898, 0.5102], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7237, 0.2763], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 817
agent= agent_0 distrib= tensor([0.6096, 0.3904], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7865, 0.2135], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 818
agent= agent_1 distrib= tensor([0.5601, 0.4399], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4469, 0.5531], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 819
agent= agent_3 distrib= tensor([0.5896, 0.4104], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6532, 0.3468], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 820
agent= agent_5 distrib= tensor([0.7175, 0.2825], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7127, 0.2873], grad_fn=<SoftmaxBackward0>)
Epoch : 820 	 Measure: 0.4000000059604645
==========>Epoch= 821
agent= agent_4 distrib= tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8279, 0.1721], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 822
agent= agent_6 distrib= tensor([0.7837, 0.2163], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 823
agent= agent_3 distrib= tensor([0.5909, 0.4091], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8243, 0.1757], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 824
agent= agent_9 distrib= tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6303, 0.3697], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 825
agent= agent_4 distrib= tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5670, 0.4330], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 826
agent= agent_6 distrib= tensor([0.8234, 0.1766], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 827
agent= agent_7 distrib= tensor([0.6350, 0.3650], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7594, 0.2406], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 828
agent= agent_6 distrib= tensor([0.8253, 0.1747], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6664, 0.3336], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 829
agent= agent_7 distrib= tensor([0.6537, 0.3463], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 830
agent= agent_1 distrib= tensor([0.6358, 0.3642], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6331, 0.3669], grad_fn=<SoftmaxBackward0>)
Epoch : 830 	 Measure: 0.5
==========>Epoch= 831
agent= agent_8 distrib= tensor([0.4593, 0.5407], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6053, 0.3947], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 832
agent= agent_0 distrib= tensor([0.6091, 0.3909], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4597, 0.5403], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 833
agent= agent_2 distrib= tensor([0.7724, 0.2276], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5992, 0.4008], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 834
agent= agent_1 distrib= tensor([0.6140, 0.3860], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7593, 0.2407], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 835
agent= agent_8 distrib= tensor([0.4901, 0.5099], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6492, 0.3508], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 836
agent= agent_7 distrib= tensor([0.6541, 0.3459], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6513, 0.3487], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 837
agent= agent_8 distrib= tensor([0.4908, 0.5092], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5923, 0.4077], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 838
agent= agent_0 distrib= tensor([0.6036, 0.3964], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6092, 0.3908], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 839
agent= agent_6 distrib= tensor([0.7887, 0.2113], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5901, 0.4099], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 840
agent= agent_0 distrib= tensor([0.5722, 0.4278], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6557, 0.3443], grad_fn=<SoftmaxBackward0>)
Epoch : 840 	 Measure: 0.699999988079071
==========>Epoch= 841
agent= agent_3 distrib= tensor([0.5928, 0.4072], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6045, 0.3955], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 842
agent= agent_6 distrib= tensor([0.8250, 0.1750], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4842, 0.5158], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 843
agent= agent_3 distrib= tensor([0.5834, 0.4166], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6364, 0.3636], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 844
agent= agent_0 distrib= tensor([0.6095, 0.3905], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7794, 0.2206], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 845
agent= agent_5 distrib= tensor([0.7457, 0.2543], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7374, 0.2626], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 846
agent= agent_7 distrib= tensor([0.6550, 0.3450], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7173, 0.2827], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 847
agent= agent_3 distrib= tensor([0.5954, 0.4046], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9175, 0.0825], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 848
agent= agent_6 distrib= tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6681, 0.3319], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 849
agent= agent_1 distrib= tensor([0.6217, 0.3783], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 850
agent= agent_7 distrib= tensor([0.6503, 0.3497], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6342, 0.3658], grad_fn=<SoftmaxBackward0>)
Epoch : 850 	 Measure: 0.4000000059604645
==========>Epoch= 851
agent= agent_6 distrib= tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5976, 0.4024], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 852
agent= agent_3 distrib= tensor([0.5861, 0.4139], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6791, 0.3209], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 853
agent= agent_0 distrib= tensor([0.6347, 0.3653], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6513, 0.3487], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 854
agent= agent_6 distrib= tensor([0.8217, 0.1783], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7371, 0.2629], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 855
agent= agent_4 distrib= tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8191, 0.1809], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 856
agent= agent_0 distrib= tensor([0.6085, 0.3915], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8508, 0.1492], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 857
agent= agent_0 distrib= tensor([0.5691, 0.4309], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 858
agent= agent_5 distrib= tensor([0.7174, 0.2826], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.5902, 0.4098], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 859
agent= agent_9 distrib= tensor([0.7353, 0.2647], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5994, 0.4006], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 860
agent= agent_4 distrib= tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6129, 0.3871], grad_fn=<SoftmaxBackward0>)
Epoch : 860 	 Measure: 0.5
==========>Epoch= 861
agent= agent_5 distrib= tensor([0.7583, 0.2417], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6027, 0.3973], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 862
agent= agent_0 distrib= tensor([0.6313, 0.3687], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4536, 0.5464], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 863
agent= agent_8 distrib= tensor([0.4555, 0.5445], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6565, 0.3435], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 864
agent= agent_7 distrib= tensor([0.6563, 0.3437], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6049, 0.3951], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 865
agent= agent_8 distrib= tensor([0.4575, 0.5425], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7584, 0.2416], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 866
agent= agent_5 distrib= tensor([0.7459, 0.2541], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 867
agent= agent_9 distrib= tensor([0.6778, 0.3222], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 868
agent= agent_2 distrib= tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 869
agent= agent_1 distrib= tensor([0.5930, 0.4070], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7186, 0.2814], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 870
agent= agent_7 distrib= tensor([0.6485, 0.3515], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6306, 0.3694], grad_fn=<SoftmaxBackward0>)
Epoch : 870 	 Measure: 0.6000000238418579
==========>Epoch= 871
agent= agent_7 distrib= tensor([0.6526, 0.3474], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7191, 0.2809], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 872
agent= agent_3 distrib= tensor([0.6048, 0.3952], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7312, 0.2688], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 873
agent= agent_8 distrib= tensor([0.4596, 0.5404], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6310, 0.3690], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 874
agent= agent_7 distrib= tensor([0.6512, 0.3488], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.4617, 0.5383], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 875
agent= agent_0 distrib= tensor([0.6317, 0.3683], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7197, 0.2803], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 876
agent= agent_3 distrib= tensor([0.5888, 0.4112], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7748, 0.2252], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 877
agent= agent_2 distrib= tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5901, 0.4099], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 878
agent= agent_0 distrib= tensor([0.6026, 0.3974], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6155, 0.3845], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 879
agent= agent_9 distrib= tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6511, 0.3489], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 880
agent= agent_2 distrib= tensor([0.7532, 0.2468], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6274, 0.3726], grad_fn=<SoftmaxBackward0>)
Epoch : 880 	 Measure: 0.699999988079071
==========>Epoch= 881
agent= agent_0 distrib= tensor([0.5689, 0.4311], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7091, 0.2909], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 882
agent= agent_9 distrib= tensor([0.7093, 0.2907], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7204, 0.2796], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 883
agent= agent_4 distrib= tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6654, 0.3346], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 884
agent= agent_8 distrib= tensor([0.4974, 0.5026], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7483, 0.2517], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 885
agent= agent_9 distrib= tensor([0.7100, 0.2900], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6467, 0.3533], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 886
agent= agent_3 distrib= tensor([0.5884, 0.4116], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7217, 0.2783], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 887
agent= agent_1 distrib= tensor([0.6621, 0.3379], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6541, 0.3459], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 888
agent= agent_4 distrib= tensor([0.8596, 0.1404], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6298, 0.3702], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 889
agent= agent_0 distrib= tensor([0.5697, 0.4303], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7783, 0.2217], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 890
agent= agent_5 distrib= tensor([0.7225, 0.2775], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6551, 0.3449], grad_fn=<SoftmaxBackward0>)
Epoch : 890 	 Measure: 0.6000000238418579
==========>Epoch= 891
agent= agent_3 distrib= tensor([0.5887, 0.4113], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7241, 0.2759], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 892
agent= agent_0 distrib= tensor([0.5705, 0.4295], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7772, 0.2228], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 893
agent= agent_2 distrib= tensor([0.7763, 0.2237], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6488, 0.3512], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 894
agent= agent_5 distrib= tensor([0.7523, 0.2477], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.8091, 0.1909], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 895
agent= agent_1 distrib= tensor([0.6210, 0.3790], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7659, 0.2341], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 896
agent= agent_4 distrib= tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 897
agent= agent_2 distrib= tensor([0.7367, 0.2633], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5898, 0.4102], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 898
agent= agent_8 distrib= tensor([0.4760, 0.5240], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5933, 0.4067], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 899
agent= agent_1 distrib= tensor([0.6222, 0.3778], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 900
agent= agent_4 distrib= tensor([0.9272, 0.0728], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6699, 0.3301], grad_fn=<SoftmaxBackward0>)
Epoch : 900 	 Measure: 0.30000001192092896
==========>Epoch= 901
agent= agent_9 distrib= tensor([0.7188, 0.2812], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5917, 0.4083], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 902
agent= agent_2 distrib= tensor([0.7491, 0.2509], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7582, 0.2418], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 903
agent= agent_4 distrib= tensor([0.8640, 0.1360], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6833, 0.3167], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 904
agent= agent_7 distrib= tensor([0.6501, 0.3499], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 905
agent= agent_5 distrib= tensor([0.7269, 0.2731], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7958, 0.2042], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 906
agent= agent_3 distrib= tensor([0.5928, 0.4072], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7283, 0.2717], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 907
agent= agent_0 distrib= tensor([0.5715, 0.4285], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5938, 0.4062], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 908
agent= agent_8 distrib= tensor([0.5016, 0.4984], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6233, 0.3767], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 909
agent= agent_5 distrib= tensor([0.7418, 0.2582], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 910
agent= agent_9 distrib= tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5115, 0.4885], grad_fn=<SoftmaxBackward0>)
Epoch : 910 	 Measure: 0.30000001192092896
==========>Epoch= 911
agent= agent_1 distrib= tensor([0.6693, 0.3307], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7936, 0.2064], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 912
agent= agent_5 distrib= tensor([0.7292, 0.2708], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7918, 0.2082], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 913
agent= agent_7 distrib= tensor([0.6380, 0.3620], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6115, 0.3885], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 914
agent= agent_8 distrib= tensor([0.4809, 0.5191], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6841, 0.3159], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 915
agent= agent_3 distrib= tensor([0.5950, 0.4050], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7288, 0.2712], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 916
agent= agent_8 distrib= tensor([0.4822, 0.5178], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 917
agent= agent_1 distrib= tensor([0.6698, 0.3302], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 918
agent= agent_4 distrib= tensor([0.9269, 0.0731], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7534, 0.2466], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 919
agent= agent_5 distrib= tensor([0.7364, 0.2636], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6387, 0.3613], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 920
agent= agent_2 distrib= tensor([0.7685, 0.2315], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6096, 0.3904], grad_fn=<SoftmaxBackward0>)
Epoch : 920 	 Measure: 0.20000000298023224
==========>Epoch= 921
agent= agent_7 distrib= tensor([0.6379, 0.3621], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 922
agent= agent_3 distrib= tensor([0.5980, 0.4020], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8607, 0.1393], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 923
agent= agent_2 distrib= tensor([0.7394, 0.2606], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 924
agent= agent_7 distrib= tensor([0.6587, 0.3413], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7403, 0.2597], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 925
agent= agent_9 distrib= tensor([0.7387, 0.2613], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6128, 0.3872], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 926
agent= agent_3 distrib= tensor([0.6148, 0.3852], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7902, 0.2098], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 927
agent= agent_3 distrib= tensor([0.5955, 0.4045], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5767, 0.4233], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 928
agent= agent_5 distrib= tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6176, 0.3824], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 929
agent= agent_9 distrib= tensor([0.7247, 0.2753], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6594, 0.3406], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 930
agent= agent_3 distrib= tensor([0.6138, 0.3862], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)
Epoch : 930 	 Measure: 0.4000000059604645
==========>Epoch= 931
agent= agent_4 distrib= tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7266, 0.2734], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 932
agent= agent_3 distrib= tensor([0.6163, 0.3837], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7581, 0.2419], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 933
agent= agent_7 distrib= tensor([0.6381, 0.3619], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6897, 0.3103], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 934
agent= agent_1 distrib= tensor([0.6298, 0.3702], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 935
agent= agent_4 distrib= tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6616, 0.3384], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 936
agent= agent_8 distrib= tensor([0.4834, 0.5166], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6006, 0.3994], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 937
agent= agent_5 distrib= tensor([0.7564, 0.2436], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7301, 0.2699], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 938
agent= agent_1 distrib= tensor([0.6720, 0.3280], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 939
agent= agent_2 distrib= tensor([0.7796, 0.2204], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7317, 0.2683], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 940
agent= agent_2 distrib= tensor([0.7724, 0.2276], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7431, 0.2569], grad_fn=<SoftmaxBackward0>)
Epoch : 940 	 Measure: 0.4000000059604645
==========>Epoch= 941
agent= agent_8 distrib= tensor([0.5184, 0.4816], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6177, 0.3823], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 942
agent= agent_4 distrib= tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6367, 0.3633], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 943
agent= agent_7 distrib= tensor([0.6760, 0.3240], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 944
agent= agent_7 distrib= tensor([0.6647, 0.3353], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 945
agent= agent_6 distrib= tensor([0.7868, 0.2132], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7409, 0.2591], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 946
agent= agent_6 distrib= tensor([0.7399, 0.2601], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6417, 0.3583], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 947
agent= agent_1 distrib= tensor([0.6342, 0.3658], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7402, 0.2598], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 948
agent= agent_5 distrib= tensor([0.7089, 0.2911], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.5976, 0.4024], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 949
agent= agent_6 distrib= tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 950
agent= agent_2 distrib= tensor([0.7780, 0.2220], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6188, 0.3812], grad_fn=<SoftmaxBackward0>)
Epoch : 950 	 Measure: 0.30000001192092896
==========>Epoch= 951
agent= agent_2 distrib= tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6195, 0.3805], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 952
agent= agent_8 distrib= tensor([0.5138, 0.4862], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6174, 0.3826], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 953
agent= agent_4 distrib= tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7777, 0.2223], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 954
agent= agent_6 distrib= tensor([0.7308, 0.2692], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6418, 0.3582], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 955
agent= agent_9 distrib= tensor([0.7333, 0.2667], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7701, 0.2299], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 956
agent= agent_9 distrib= tensor([0.7348, 0.2652], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6161, 0.3839], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 957
agent= agent_8 distrib= tensor([0.5256, 0.4744], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5851, 0.4149], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 958
agent= agent_0 distrib= tensor([0.5888, 0.4112], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7758, 0.2242], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 959
agent= agent_0 distrib= tensor([0.5923, 0.4077], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6180, 0.3820], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 960
agent= agent_9 distrib= tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6639, 0.3361], grad_fn=<SoftmaxBackward0>)
Epoch : 960 	 Measure: 0.5
==========>Epoch= 961
agent= agent_8 distrib= tensor([0.4952, 0.5048], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6034, 0.3966], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 962
agent= agent_1 distrib= tensor([0.6199, 0.3801], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7075, 0.2925], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 963
agent= agent_3 distrib= tensor([0.6002, 0.3998], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.5957, 0.4043], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 964
agent= agent_5 distrib= tensor([0.7064, 0.2936], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8975, 0.1025], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 965
agent= agent_1 distrib= tensor([0.6219, 0.3781], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6236, 0.3764], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 966
agent= agent_5 distrib= tensor([0.7055, 0.2945], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7750, 0.2250], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 967
agent= agent_0 distrib= tensor([0.6000, 0.4000], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 968
agent= agent_8 distrib= tensor([0.5224, 0.4776], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7638, 0.2362], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 969
agent= agent_4 distrib= tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6872, 0.3128], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 970
agent= agent_3 distrib= tensor([0.6081, 0.3919], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6414, 0.3586], grad_fn=<SoftmaxBackward0>)
Epoch : 970 	 Measure: 0.6000000238418579
==========>Epoch= 971
agent= agent_3 distrib= tensor([0.6099, 0.3901], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 972
agent= agent_3 distrib= tensor([0.6303, 0.3697], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7327, 0.2673], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 973
agent= agent_3 distrib= tensor([0.6333, 0.3667], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5343, 0.4657], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 974
agent= agent_0 distrib= tensor([0.6430, 0.3570], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 975
agent= agent_5 distrib= tensor([0.7161, 0.2839], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8500, 0.1500], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 976
agent= agent_0 distrib= tensor([0.6499, 0.3501], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 977
agent= agent_9 distrib= tensor([0.7412, 0.2588], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7744, 0.2256], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 978
agent= agent_8 distrib= tensor([0.4910, 0.5090], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 979
agent= agent_2 distrib= tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7332, 0.2668], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 980
agent= agent_8 distrib= tensor([0.5049, 0.4951], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward0>)
Epoch : 980 	 Measure: 0.30000001192092896
==========>Epoch= 981
agent= agent_2 distrib= tensor([0.7332, 0.2668], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6254, 0.3746], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 982
agent= agent_8 distrib= tensor([0.4940, 0.5060], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6638, 0.3362], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 983
agent= agent_7 distrib= tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6371, 0.3629], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 984
agent= agent_4 distrib= tensor([0.9200, 0.0800], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6509, 0.3491], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 985
agent= agent_6 distrib= tensor([0.7226, 0.2774], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7171, 0.2829], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 986
agent= agent_6 distrib= tensor([0.7199, 0.2801], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6668, 0.3332], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 987
agent= agent_1 distrib= tensor([0.6550, 0.3450], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7444, 0.2556], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 988
agent= agent_0 distrib= tensor([0.6552, 0.3448], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7021, 0.2979], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 989
agent= agent_2 distrib= tensor([0.7636, 0.2364], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 990
agent= agent_9 distrib= tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7634, 0.2366], grad_fn=<SoftmaxBackward0>)
Epoch : 990 	 Measure: 0.5
==========>Epoch= 991
agent= agent_4 distrib= tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5412, 0.4588], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 992
agent= agent_3 distrib= tensor([0.6358, 0.3642], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6546, 0.3454], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 993
agent= agent_1 distrib= tensor([0.6305, 0.3695], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6569, 0.3431], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 994
agent= agent_6 distrib= tensor([0.7561, 0.2439], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 995
agent= agent_6 distrib= tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7199, 0.2801], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 996
agent= agent_7 distrib= tensor([0.6450, 0.3550], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6580, 0.3420], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 997
agent= agent_9 distrib= tensor([0.7458, 0.2542], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7563, 0.2437], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 998
agent= agent_6 distrib= tensor([0.7558, 0.2442], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6588, 0.3412], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 999
agent= agent_9 distrib= tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6386, 0.3614], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1000
agent= agent_0 distrib= tensor([0.6593, 0.3407], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5060, 0.4940], grad_fn=<SoftmaxBackward0>)
Epoch : 1000 	 Measure: 0.5
==========>Epoch= 1001
agent= agent_1 distrib= tensor([0.6346, 0.3654], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7101, 0.2899], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1002
agent= agent_8 distrib= tensor([0.5401, 0.4599], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7321, 0.2679], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1003
agent= agent_3 distrib= tensor([0.6467, 0.3533], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6370, 0.3630], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1004
agent= agent_4 distrib= tensor([0.8875, 0.1125], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6506, 0.3494], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1005
agent= agent_3 distrib= tensor([0.6314, 0.3686], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5056, 0.4944], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1006
agent= agent_7 distrib= tensor([0.6677, 0.3323], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7009, 0.2991], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1007
agent= agent_5 distrib= tensor([0.7215, 0.2785], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6430, 0.3570], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1008
agent= agent_4 distrib= tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6600, 0.3400], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1009
agent= agent_8 distrib= tensor([0.5054, 0.4946], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7074, 0.2926], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1010
agent= agent_8 distrib= tensor([0.4944, 0.5056], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7429, 0.2571], grad_fn=<SoftmaxBackward0>)
Epoch : 1010 	 Measure: 0.6000000238418579
==========>Epoch= 1011
agent= agent_9 distrib= tensor([0.7673, 0.2327], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6763, 0.3237], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1012
agent= agent_6 distrib= tensor([0.7083, 0.2917], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6617, 0.3383], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1013
agent= agent_1 distrib= tensor([0.6395, 0.3605], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7075, 0.2925], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1014
agent= agent_3 distrib= tensor([0.6250, 0.3750], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7068, 0.2932], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1015
agent= agent_0 distrib= tensor([0.6624, 0.3376], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1016
agent= agent_2 distrib= tensor([0.7445, 0.2555], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6659, 0.3341], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1017
agent= agent_3 distrib= tensor([0.6288, 0.3712], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7058, 0.2942], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1018
agent= agent_9 distrib= tensor([0.7127, 0.2873], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6383, 0.3617], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1019
agent= agent_6 distrib= tensor([0.7074, 0.2926], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6356, 0.3644], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1020
agent= agent_6 distrib= tensor([0.7438, 0.2562], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7388, 0.2612], grad_fn=<SoftmaxBackward0>)
Epoch : 1020 	 Measure: 0.5
==========>Epoch= 1021
agent= agent_5 distrib= tensor([0.7131, 0.2869], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6400, 0.3600], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1022
agent= agent_8 distrib= tensor([0.5053, 0.4947], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7071, 0.2929], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1023
agent= agent_7 distrib= tensor([0.6549, 0.3451], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1024
agent= agent_9 distrib= tensor([0.7545, 0.2455], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7740, 0.2260], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1025
agent= agent_9 distrib= tensor([0.7553, 0.2447], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6529, 0.3471], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1026
agent= agent_0 distrib= tensor([0.6670, 0.3330], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6603, 0.3397], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1027
agent= agent_9 distrib= tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8372, 0.1628], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1028
agent= agent_2 distrib= tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7437, 0.2563], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1029
agent= agent_7 distrib= tensor([0.6297, 0.3703], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7076, 0.2924], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1030
agent= agent_6 distrib= tensor([0.7452, 0.2548], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5305, 0.4695], grad_fn=<SoftmaxBackward0>)
Epoch : 1030 	 Measure: 0.800000011920929
==========>Epoch= 1031
agent= agent_6 distrib= tensor([0.7477, 0.2523], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6721, 0.3279], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1032
agent= agent_8 distrib= tensor([0.5291, 0.4709], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6630, 0.3370], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1033
agent= agent_1 distrib= tensor([0.6632, 0.3368], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7415, 0.2585], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1034
agent= agent_2 distrib= tensor([0.7750, 0.2250], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6771, 0.3229], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1035
agent= agent_1 distrib= tensor([0.6432, 0.3568], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7052, 0.2948], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1036
agent= agent_8 distrib= tensor([0.4936, 0.5064], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8827, 0.1173], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1037
agent= agent_7 distrib= tensor([0.6408, 0.3592], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7755, 0.2245], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1038
agent= agent_4 distrib= tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1039
agent= agent_5 distrib= tensor([0.7164, 0.2836], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6449, 0.3551], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1040
agent= agent_8 distrib= tensor([0.5364, 0.4636], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7183, 0.2817], grad_fn=<SoftmaxBackward0>)
Epoch : 1040 	 Measure: 0.30000001192092896
==========>Epoch= 1041
agent= agent_8 distrib= tensor([0.5360, 0.4640], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7201, 0.2799], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1042
agent= agent_7 distrib= tensor([0.6265, 0.3735], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6699, 0.3301], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1043
agent= agent_1 distrib= tensor([0.6667, 0.3333], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5266, 0.4734], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1044
agent= agent_4 distrib= tensor([0.8344, 0.1656], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7062, 0.2938], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1045
agent= agent_8 distrib= tensor([0.4940, 0.5060], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1046
agent= agent_5 distrib= tensor([0.7219, 0.2781], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1047
agent= agent_2 distrib= tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6565, 0.3435], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1048
agent= agent_5 distrib= tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6772, 0.3228], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1049
agent= agent_3 distrib= tensor([0.6913, 0.3087], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5384, 0.4616], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1050
agent= agent_2 distrib= tensor([0.7679, 0.2321], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6865, 0.3135], grad_fn=<SoftmaxBackward0>)
Epoch : 1050 	 Measure: 0.8999999761581421
==========>Epoch= 1051
agent= agent_1 distrib= tensor([0.6678, 0.3322], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7416, 0.2584], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1052
agent= agent_8 distrib= tensor([0.5319, 0.4681], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6742, 0.3258], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1053
agent= agent_2 distrib= tensor([0.7778, 0.2222], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7011, 0.2989], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1054
agent= agent_0 distrib= tensor([0.6750, 0.3250], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1055
agent= agent_4 distrib= tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1056
agent= agent_5 distrib= tensor([0.7627, 0.2373], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7055, 0.2945], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1057
agent= agent_0 distrib= tensor([0.6999, 0.3001], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7596, 0.2404], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1058
agent= agent_4 distrib= tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7060, 0.2940], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1059
agent= agent_8 distrib= tensor([0.5326, 0.4674], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7542, 0.2458], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1060
agent= agent_3 distrib= tensor([0.6989, 0.3011], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7426, 0.2574], grad_fn=<SoftmaxBackward0>)
Epoch : 1060 	 Measure: 0.4000000059604645
==========>Epoch= 1061
agent= agent_9 distrib= tensor([0.7181, 0.2819], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6767, 0.3233], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1062
agent= agent_7 distrib= tensor([0.6471, 0.3529], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6433, 0.3567], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1063
agent= agent_5 distrib= tensor([0.7293, 0.2707], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5429, 0.4571], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1064
agent= agent_6 distrib= tensor([0.7432, 0.2568], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5351, 0.4649], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1065
agent= agent_7 distrib= tensor([0.6377, 0.3623], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7695, 0.2305], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1066
agent= agent_1 distrib= tensor([0.6494, 0.3506], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7364, 0.2636], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1067
agent= agent_8 distrib= tensor([0.5011, 0.4989], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6508, 0.3492], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1068
agent= agent_1 distrib= tensor([0.6534, 0.3466], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1069
agent= agent_6 distrib= tensor([0.7065, 0.2935], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7002, 0.2998], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1070
agent= agent_4 distrib= tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6417, 0.3583], grad_fn=<SoftmaxBackward0>)
Epoch : 1070 	 Measure: 0.4000000059604645
==========>Epoch= 1071
agent= agent_5 distrib= tensor([0.7318, 0.2682], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7556, 0.2444], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1072
agent= agent_2 distrib= tensor([0.7358, 0.2642], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6559, 0.3441], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1073
agent= agent_0 distrib= tensor([0.6410, 0.3590], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6389, 0.3611], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1074
agent= agent_4 distrib= tensor([0.8338, 0.1662], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1075
agent= agent_7 distrib= tensor([0.6366, 0.3634], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7078, 0.2922], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1076
agent= agent_4 distrib= tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1077
agent= agent_8 distrib= tensor([0.5389, 0.4611], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1078
agent= agent_8 distrib= tensor([0.5517, 0.4483], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7103, 0.2897], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1079
agent= agent_3 distrib= tensor([0.7028, 0.2972], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6491, 0.3509], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1080
agent= agent_1 distrib= tensor([0.6584, 0.3416], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5038, 0.4962], grad_fn=<SoftmaxBackward0>)
Epoch : 1080 	 Measure: 0.20000000298023224
==========>Epoch= 1081
agent= agent_9 distrib= tensor([0.7828, 0.2172], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7465, 0.2535], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1082
agent= agent_6 distrib= tensor([0.7115, 0.2885], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5181, 0.4819], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1083
agent= agent_5 distrib= tensor([0.7423, 0.2577], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6814, 0.3186], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1084
agent= agent_7 distrib= tensor([0.6145, 0.3855], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1085
agent= agent_0 distrib= tensor([0.6748, 0.3252], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6796, 0.3204], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1086
agent= agent_7 distrib= tensor([0.6477, 0.3523], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7033, 0.2967], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1087
agent= agent_5 distrib= tensor([0.7407, 0.2593], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6143, 0.3857], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1088
agent= agent_2 distrib= tensor([0.7353, 0.2647], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7667, 0.2333], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1089
agent= agent_6 distrib= tensor([0.7522, 0.2478], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1090
agent= agent_7 distrib= tensor([0.6358, 0.3642], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7362, 0.2638], grad_fn=<SoftmaxBackward0>)
Epoch : 1090 	 Measure: 0.5
==========>Epoch= 1091
agent= agent_9 distrib= tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7662, 0.2338], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1092
agent= agent_4 distrib= tensor([0.8351, 0.1649], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6743, 0.3257], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1093
agent= agent_9 distrib= tensor([0.7274, 0.2726], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7454, 0.2546], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1094
agent= agent_2 distrib= tensor([0.7450, 0.2550], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7381, 0.2619], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1095
agent= agent_8 distrib= tensor([0.5435, 0.4565], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7500, 0.2500], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1096
agent= agent_0 distrib= tensor([0.6731, 0.3269], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5448, 0.4552], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1097
agent= agent_4 distrib= tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7133, 0.2867], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1098
agent= agent_3 distrib= tensor([0.7035, 0.2965], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1099
agent= agent_0 distrib= tensor([0.6738, 0.3262], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7151, 0.2849], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1100
agent= agent_1 distrib= tensor([0.7148, 0.2852], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7565, 0.2435], grad_fn=<SoftmaxBackward0>)
Epoch : 1100 	 Measure: 0.699999988079071
==========>Epoch= 1101
agent= agent_4 distrib= tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7585, 0.2415], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1102
agent= agent_9 distrib= tensor([0.7656, 0.2344], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6274, 0.3726], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1103
agent= agent_4 distrib= tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1104
agent= agent_0 distrib= tensor([0.6729, 0.3271], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7932, 0.2068], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1105
agent= agent_9 distrib= tensor([0.7794, 0.2206], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6690, 0.3310], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1106
agent= agent_7 distrib= tensor([0.6133, 0.3867], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6778, 0.3222], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1107
agent= agent_4 distrib= tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5099, 0.4901], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1108
agent= agent_9 distrib= tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7200, 0.2800], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1109
agent= agent_8 distrib= tensor([0.5476, 0.4524], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6729, 0.3271], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1110
agent= agent_0 distrib= tensor([0.6394, 0.3606], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6336, 0.3664], grad_fn=<SoftmaxBackward0>)
Epoch : 1110 	 Measure: 0.8999999761581421
==========>Epoch= 1111
agent= agent_0 distrib= tensor([0.6735, 0.3265], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1112
agent= agent_3 distrib= tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5590, 0.4410], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1113
agent= agent_8 distrib= tensor([0.5602, 0.4398], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7107, 0.2893], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1114
agent= agent_5 distrib= tensor([0.7557, 0.2443], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1115
agent= agent_9 distrib= tensor([0.7750, 0.2250], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6250, 0.3750], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1116
agent= agent_2 distrib= tensor([0.7340, 0.2660], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7621, 0.2379], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1117
agent= agent_8 distrib= tensor([0.5526, 0.4474], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6436, 0.3564], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1118
agent= agent_9 distrib= tensor([0.8037, 0.1963], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5548, 0.4452], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1119
agent= agent_5 distrib= tensor([0.7279, 0.2721], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1120
agent= agent_2 distrib= tensor([0.7731, 0.2269], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6233, 0.3767], grad_fn=<SoftmaxBackward0>)
Epoch : 1120 	 Measure: 0.6000000238418579
==========>Epoch= 1121
agent= agent_5 distrib= tensor([0.7281, 0.2719], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1122
agent= agent_0 distrib= tensor([0.6988, 0.3012], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1123
agent= agent_1 distrib= tensor([0.6816, 0.3184], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7080, 0.2920], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1124
agent= agent_4 distrib= tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7177, 0.2823], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1125
agent= agent_4 distrib= tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1126
agent= agent_6 distrib= tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7284, 0.2716], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1127
agent= agent_4 distrib= tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7238, 0.2762], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1128
agent= agent_9 distrib= tensor([0.7905, 0.2095], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5673, 0.4327], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1129
agent= agent_5 distrib= tensor([0.7552, 0.2448], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1130
agent= agent_2 distrib= tensor([0.7644, 0.2356], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7541, 0.2459], grad_fn=<SoftmaxBackward0>)
Epoch : 1130 	 Measure: 0.20000000298023224
==========>Epoch= 1131
agent= agent_4 distrib= tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6801, 0.3199], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1132
agent= agent_9 distrib= tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6742, 0.3258], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1133
agent= agent_0 distrib= tensor([0.6988, 0.3012], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1134
agent= agent_2 distrib= tensor([0.7439, 0.2561], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1135
agent= agent_1 distrib= tensor([0.7191, 0.2809], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6988, 0.3012], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1136
agent= agent_8 distrib= tensor([0.5694, 0.4306], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6361, 0.3639], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1137
agent= agent_7 distrib= tensor([0.6096, 0.3904], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1138
agent= agent_4 distrib= tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5610, 0.4390], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1139
agent= agent_6 distrib= tensor([0.7657, 0.2343], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5248, 0.4752], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1140
agent= agent_1 distrib= tensor([0.7214, 0.2786], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)
Epoch : 1140 	 Measure: 0.4000000059604645
==========>Epoch= 1141
agent= agent_5 distrib= tensor([0.7330, 0.2670], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7439, 0.2561], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1142
agent= agent_0 distrib= tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6937, 0.3063], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1143
agent= agent_5 distrib= tensor([0.7526, 0.2474], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7663, 0.2337], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1144
agent= agent_5 distrib= tensor([0.7225, 0.2775], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5758, 0.4242], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1145
agent= agent_4 distrib= tensor([0.8963, 0.1037], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6753, 0.3247], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1146
agent= agent_6 distrib= tensor([0.7291, 0.2709], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7533, 0.2467], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1147
agent= agent_1 distrib= tensor([0.6770, 0.3230], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7220, 0.2780], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1148
agent= agent_6 distrib= tensor([0.7710, 0.2290], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7217, 0.2783], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1149
agent= agent_8 distrib= tensor([0.5671, 0.4329], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7646, 0.2354], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1150
agent= agent_9 distrib= tensor([0.7924, 0.2076], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5297, 0.4703], grad_fn=<SoftmaxBackward0>)
Epoch : 1150 	 Measure: 0.6000000238418579
==========>Epoch= 1151
agent= agent_0 distrib= tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1152
agent= agent_5 distrib= tensor([0.7589, 0.2411], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6357, 0.3643], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1153
agent= agent_0 distrib= tensor([0.6997, 0.3003], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7340, 0.2660], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1154
agent= agent_5 distrib= tensor([0.7491, 0.2509], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6740, 0.3260], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1155
agent= agent_3 distrib= tensor([0.7143, 0.2857], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6801, 0.3199], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1156
agent= agent_7 distrib= tensor([0.6453, 0.3547], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1157
agent= agent_8 distrib= tensor([0.5819, 0.4181], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7149, 0.2851], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1158
agent= agent_9 distrib= tensor([0.7947, 0.2053], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7178, 0.2822], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1159
agent= agent_2 distrib= tensor([0.7734, 0.2266], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7175, 0.2825], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1160
agent= agent_0 distrib= tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7174, 0.2826], grad_fn=<SoftmaxBackward0>)
Epoch : 1160 	 Measure: 0.6000000238418579
==========>Epoch= 1161
agent= agent_4 distrib= tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6280, 0.3720], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1162
agent= agent_0 distrib= tensor([0.6760, 0.3240], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6498, 0.3502], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1163
agent= agent_7 distrib= tensor([0.6166, 0.3834], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7026, 0.2974], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1164
agent= agent_7 distrib= tensor([0.6384, 0.3616], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6384, 0.3616], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1165
agent= agent_7 distrib= tensor([0.6560, 0.3440], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7686, 0.2314], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1166
agent= agent_0 distrib= tensor([0.6773, 0.3227], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1167
agent= agent_0 distrib= tensor([0.6385, 0.3615], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1168
agent= agent_7 distrib= tensor([0.6578, 0.3422], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5729, 0.4271], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1169
agent= agent_2 distrib= tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1170
agent= agent_3 distrib= tensor([0.6816, 0.3184], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)
Epoch : 1170 	 Measure: 0.4000000059604645
==========>Epoch= 1171
agent= agent_7 distrib= tensor([0.6234, 0.3766], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5466, 0.4534], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1172
agent= agent_2 distrib= tensor([0.7743, 0.2257], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7311, 0.2689], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1173
agent= agent_4 distrib= tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5878, 0.4122], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1174
agent= agent_3 distrib= tensor([0.6753, 0.3247], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7175, 0.2825], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1175
agent= agent_2 distrib= tensor([0.7667, 0.2333], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1176
agent= agent_1 distrib= tensor([0.6856, 0.3144], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1177
agent= agent_0 distrib= tensor([0.6760, 0.3240], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7076, 0.2924], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1178
agent= agent_2 distrib= tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6754, 0.3246], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1179
agent= agent_0 distrib= tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1180
agent= agent_3 distrib= tensor([0.6810, 0.3190], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7483, 0.2517], grad_fn=<SoftmaxBackward0>)
Epoch : 1180 	 Measure: 0.800000011920929
==========>Epoch= 1181
agent= agent_0 distrib= tensor([0.7039, 0.2961], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1182
agent= agent_4 distrib= tensor([0.8451, 0.1549], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7299, 0.2701], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1183
agent= agent_2 distrib= tensor([0.7717, 0.2283], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5789, 0.4211], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1184
agent= agent_1 distrib= tensor([0.6913, 0.3087], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7317, 0.2683], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1185
agent= agent_1 distrib= tensor([0.7085, 0.2915], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1186
agent= agent_2 distrib= tensor([0.7712, 0.2288], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7109, 0.2891], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1187
agent= agent_3 distrib= tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6613, 0.3387], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1188
agent= agent_6 distrib= tensor([0.7301, 0.2699], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1189
agent= agent_5 distrib= tensor([0.7479, 0.2521], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1190
agent= agent_5 distrib= tensor([0.7128, 0.2872], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)
Epoch : 1190 	 Measure: 0.5
==========>Epoch= 1191
agent= agent_8 distrib= tensor([0.5902, 0.4098], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1192
agent= agent_3 distrib= tensor([0.6811, 0.3189], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7229, 0.2771], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1193
agent= agent_5 distrib= tensor([0.7578, 0.2422], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7326, 0.2674], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1194
agent= agent_9 distrib= tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1195
agent= agent_1 distrib= tensor([0.7447, 0.2553], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7771, 0.2229], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1196
agent= agent_3 distrib= tensor([0.6819, 0.3181], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7190, 0.2810], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1197
agent= agent_9 distrib= tensor([0.8109, 0.1891], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6753, 0.3247], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1198
agent= agent_4 distrib= tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7331, 0.2669], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1199
agent= agent_6 distrib= tensor([0.7707, 0.2293], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1200
agent= agent_4 distrib= tensor([0.9212, 0.0788], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6629, 0.3371], grad_fn=<SoftmaxBackward0>)
Epoch : 1200 	 Measure: 0.699999988079071
==========>Epoch= 1201
agent= agent_8 distrib= tensor([0.5508, 0.4492], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6285, 0.3715], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1202
agent= agent_7 distrib= tensor([0.6678, 0.3322], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7484, 0.2516], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1203
agent= agent_2 distrib= tensor([0.7757, 0.2243], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7454, 0.2546], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1204
agent= agent_2 distrib= tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1205
agent= agent_4 distrib= tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6682, 0.3318], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1206
agent= agent_4 distrib= tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7692, 0.2308], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1207
agent= agent_2 distrib= tensor([0.7735, 0.2265], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6485, 0.3515], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1208
agent= agent_3 distrib= tensor([0.7195, 0.2805], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5789, 0.4211], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1209
agent= agent_2 distrib= tensor([0.7633, 0.2367], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7679, 0.2321], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1210
agent= agent_7 distrib= tensor([0.6492, 0.3508], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5913, 0.4087], grad_fn=<SoftmaxBackward0>)
Epoch : 1210 	 Measure: 0.4000000059604645
==========>Epoch= 1211
agent= agent_0 distrib= tensor([0.6750, 0.3250], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7470, 0.2530], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1212
agent= agent_1 distrib= tensor([0.7206, 0.2794], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6718, 0.3282], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1213
agent= agent_3 distrib= tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7669, 0.2331], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1214
agent= agent_1 distrib= tensor([0.6995, 0.3005], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7297, 0.2703], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1215
agent= agent_9 distrib= tensor([0.8331, 0.1669], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6724, 0.3276], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1216
agent= agent_5 distrib= tensor([0.7224, 0.2776], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7280, 0.2720], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1217
agent= agent_4 distrib= tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7560, 0.2440], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1218
agent= agent_7 distrib= tensor([0.6500, 0.3500], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7718, 0.2282], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1219
agent= agent_5 distrib= tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7468, 0.2532], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1220
agent= agent_2 distrib= tensor([0.7430, 0.2570], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6346, 0.3654], grad_fn=<SoftmaxBackward0>)
Epoch : 1220 	 Measure: 0.4000000059604645
==========>Epoch= 1221
agent= agent_0 distrib= tensor([0.6989, 0.3011], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1222
agent= agent_0 distrib= tensor([0.6991, 0.3009], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1223
agent= agent_7 distrib= tensor([0.6519, 0.3481], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1224
agent= agent_4 distrib= tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8217, 0.1783], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1225
agent= agent_5 distrib= tensor([0.7552, 0.2448], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7333, 0.2667], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1226
agent= agent_6 distrib= tensor([0.7670, 0.2330], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6523, 0.3477], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1227
agent= agent_5 distrib= tensor([0.7550, 0.2450], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7473, 0.2527], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1228
agent= agent_4 distrib= tensor([0.9016, 0.0984], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7487, 0.2513], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1229
agent= agent_2 distrib= tensor([0.7411, 0.2589], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6979, 0.3021], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1230
agent= agent_3 distrib= tensor([0.7354, 0.2646], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7673, 0.2327], grad_fn=<SoftmaxBackward0>)
Epoch : 1230 	 Measure: 0.800000011920929
==========>Epoch= 1231
agent= agent_7 distrib= tensor([0.6725, 0.3275], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7129, 0.2871], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1232
agent= agent_5 distrib= tensor([0.7088, 0.2912], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6551, 0.3449], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1233
agent= agent_6 distrib= tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7521, 0.2479], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1234
agent= agent_3 distrib= tensor([0.7359, 0.2641], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5793, 0.4207], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1235
agent= agent_7 distrib= tensor([0.6554, 0.3446], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5389, 0.4611], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1236
agent= agent_7 distrib= tensor([0.6558, 0.3442], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8238, 0.1762], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1237
agent= agent_2 distrib= tensor([0.7576, 0.2424], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6715, 0.3285], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1238
agent= agent_1 distrib= tensor([0.7541, 0.2459], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6572, 0.3428], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1239
agent= agent_1 distrib= tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5541, 0.4459], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1240
agent= agent_3 distrib= tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)
Epoch : 1240 	 Measure: 0.699999988079071
==========>Epoch= 1241
agent= agent_9 distrib= tensor([0.8420, 0.1580], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1242
agent= agent_5 distrib= tensor([0.7211, 0.2789], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.7797, 0.2203], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1243
agent= agent_2 distrib= tensor([0.7561, 0.2439], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7370, 0.2630], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1244
agent= agent_0 distrib= tensor([0.6710, 0.3290], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7369, 0.2631], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1245
agent= agent_4 distrib= tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7020, 0.2980], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1246
agent= agent_1 distrib= tensor([0.7225, 0.2775], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7538, 0.2462], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1247
agent= agent_8 distrib= tensor([0.5946, 0.4054], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6563, 0.3437], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1248
agent= agent_2 distrib= tensor([0.7512, 0.2488], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7223, 0.2777], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1249
agent= agent_8 distrib= tensor([0.5957, 0.4043], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7434, 0.2566], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1250
agent= agent_3 distrib= tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)
Epoch : 1250 	 Measure: 0.6000000238418579
==========>Epoch= 1251
agent= agent_9 distrib= tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6595, 0.3405], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1252
agent= agent_8 distrib= tensor([0.5847, 0.4153], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6817, 0.3183], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1253
agent= agent_9 distrib= tensor([0.8221, 0.1779], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7608, 0.2392], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1254
agent= agent_3 distrib= tensor([0.7066, 0.2934], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7385, 0.2615], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1255
agent= agent_8 distrib= tensor([0.5848, 0.4152], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1256
agent= agent_9 distrib= tensor([0.8500, 0.1500], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6816, 0.3184], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1257
agent= agent_3 distrib= tensor([0.7393, 0.2607], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7252, 0.2748], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1258
agent= agent_3 distrib= tensor([0.7084, 0.2916], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7211, 0.2789], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1259
agent= agent_3 distrib= tensor([0.7071, 0.2929], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7412, 0.2588], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1260
agent= agent_0 distrib= tensor([0.7042, 0.2958], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7069, 0.2931], grad_fn=<SoftmaxBackward0>)
Epoch : 1260 	 Measure: 0.5
==========>Epoch= 1261
agent= agent_9 distrib= tensor([0.7890, 0.2110], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5601, 0.4399], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1262
agent= agent_5 distrib= tensor([0.7179, 0.2821], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7304, 0.2696], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1263
agent= agent_8 distrib= tensor([0.5856, 0.4144], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7393, 0.2607], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1264
agent= agent_8 distrib= tensor([0.5449, 0.4551], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6634, 0.3366], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1265
agent= agent_2 distrib= tensor([0.7566, 0.2434], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5458, 0.4542], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1266
agent= agent_2 distrib= tensor([0.7139, 0.2861], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1267
agent= agent_9 distrib= tensor([0.8567, 0.1433], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7422, 0.2578], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1268
agent= agent_9 distrib= tensor([0.7963, 0.2037], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7423, 0.2577], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1269
agent= agent_4 distrib= tensor([0.9273, 0.0727], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7392, 0.2608], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1270
agent= agent_6 distrib= tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5480, 0.4520], grad_fn=<SoftmaxBackward0>)
Epoch : 1270 	 Measure: 0.6000000238418579
==========>Epoch= 1271
agent= agent_6 distrib= tensor([0.7262, 0.2738], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6061, 0.3939], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1272
agent= agent_5 distrib= tensor([0.7034, 0.2966], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7194, 0.2806], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1273
agent= agent_2 distrib= tensor([0.7530, 0.2470], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7035, 0.2965], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1274
agent= agent_1 distrib= tensor([0.7676, 0.2324], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7521, 0.2479], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1275
agent= agent_7 distrib= tensor([0.6635, 0.3365], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1276
agent= agent_1 distrib= tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8594, 0.1406], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1277
agent= agent_8 distrib= tensor([0.5672, 0.4328], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7224, 0.2776], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1278
agent= agent_7 distrib= tensor([0.6819, 0.3181], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1279
agent= agent_7 distrib= tensor([0.6438, 0.3562], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7070, 0.2930], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1280
agent= agent_3 distrib= tensor([0.7070, 0.2930], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7493, 0.2507], grad_fn=<SoftmaxBackward0>)
Epoch : 1280 	 Measure: 0.8999999761581421
==========>Epoch= 1281
agent= agent_3 distrib= tensor([0.7397, 0.2603], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9284, 0.0716], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1282
agent= agent_0 distrib= tensor([0.6783, 0.3217], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8614, 0.1386], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1283
agent= agent_5 distrib= tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6779, 0.3221], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1284
agent= agent_9 distrib= tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6655, 0.3345], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1285
agent= agent_5 distrib= tensor([0.7396, 0.2604], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5911, 0.4089], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1286
agent= agent_2 distrib= tensor([0.7391, 0.2609], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6848, 0.3152], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1287
agent= agent_7 distrib= tensor([0.6479, 0.3521], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5691, 0.4309], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1288
agent= agent_0 distrib= tensor([0.6399, 0.3601], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7587, 0.2413], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1289
agent= agent_7 distrib= tensor([0.6476, 0.3524], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5684, 0.4316], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1290
agent= agent_3 distrib= tensor([0.7074, 0.2926], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8030, 0.1970], grad_fn=<SoftmaxBackward0>)
Epoch : 1290 	 Measure: 0.6000000238418579
==========>Epoch= 1291
agent= agent_5 distrib= tensor([0.7057, 0.2943], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1292
agent= agent_4 distrib= tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7260, 0.2740], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1293
agent= agent_7 distrib= tensor([0.6859, 0.3141], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7365, 0.2635], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1294
agent= agent_1 distrib= tensor([0.7775, 0.2225], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.6969, 0.3031], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1295
agent= agent_1 distrib= tensor([0.7421, 0.2579], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7436, 0.2564], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1296
agent= agent_7 distrib= tensor([0.6859, 0.3141], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1297
agent= agent_2 distrib= tensor([0.7091, 0.2909], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7527, 0.2473], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1298
agent= agent_2 distrib= tensor([0.7241, 0.2759], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6477, 0.3523], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1299
agent= agent_6 distrib= tensor([0.7187, 0.2813], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7193, 0.2807], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1300
agent= agent_2 distrib= tensor([0.7228, 0.2772], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)
Epoch : 1300 	 Measure: 0.800000011920929
==========>Epoch= 1301
agent= agent_3 distrib= tensor([0.7453, 0.2547], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5914, 0.4086], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1302
agent= agent_4 distrib= tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7366, 0.2634], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1303
agent= agent_7 distrib= tensor([0.6650, 0.3350], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7530, 0.2470], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1304
agent= agent_2 distrib= tensor([0.7467, 0.2533], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7537, 0.2463], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1305
agent= agent_5 distrib= tensor([0.7428, 0.2572], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7328, 0.2672], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1306
agent= agent_4 distrib= tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7031, 0.2969], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1307
agent= agent_5 distrib= tensor([0.7435, 0.2565], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5912, 0.4088], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1308
agent= agent_0 distrib= tensor([0.6823, 0.3177], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9272, 0.0728], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1309
agent= agent_5 distrib= tensor([0.7217, 0.2783], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8068, 0.1932], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1310
agent= agent_4 distrib= tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7512, 0.2488], grad_fn=<SoftmaxBackward0>)
Epoch : 1310 	 Measure: 0.6000000238418579
==========>Epoch= 1311
agent= agent_4 distrib= tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7497, 0.2503], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1312
agent= agent_9 distrib= tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7500, 0.2500], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1313
agent= agent_1 distrib= tensor([0.7402, 0.2598], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8571, 0.1429], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1314
agent= agent_7 distrib= tensor([0.6658, 0.3342], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8591, 0.1409], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1315
agent= agent_1 distrib= tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7224, 0.2776], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1316
agent= agent_9 distrib= tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6649, 0.3351], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1317
agent= agent_4 distrib= tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1318
agent= agent_5 distrib= tensor([0.7573, 0.2427], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7156, 0.2844], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1319
agent= agent_2 distrib= tensor([0.7174, 0.2826], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7673, 0.2327], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1320
agent= agent_7 distrib= tensor([0.6826, 0.3174], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)
Epoch : 1320 	 Measure: 0.4000000059604645
==========>Epoch= 1321
agent= agent_4 distrib= tensor([0.8560, 0.1440], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6429, 0.3571], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1322
agent= agent_2 distrib= tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7918, 0.2082], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1323
agent= agent_0 distrib= tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1324
agent= agent_9 distrib= tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1325
agent= agent_5 distrib= tensor([0.7234, 0.2766], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7177, 0.2823], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1326
agent= agent_1 distrib= tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7231, 0.2769], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1327
agent= agent_5 distrib= tensor([0.7227, 0.2773], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5677, 0.4323], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1328
agent= agent_8 distrib= tensor([0.5676, 0.4324], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1329
agent= agent_4 distrib= tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7441, 0.2559], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1330
agent= agent_6 distrib= tensor([0.7453, 0.2547], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)
Epoch : 1330 	 Measure: 0.5
==========>Epoch= 1331
agent= agent_5 distrib= tensor([0.7125, 0.2875], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7113, 0.2887], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1332
agent= agent_7 distrib= tensor([0.6822, 0.3178], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7654, 0.2346], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1333
agent= agent_6 distrib= tensor([0.7113, 0.2887], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1334
agent= agent_6 distrib= tensor([0.7082, 0.2918], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7248, 0.2752], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1335
agent= agent_2 distrib= tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7450, 0.2550], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1336
agent= agent_6 distrib= tensor([0.7407, 0.2593], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5917, 0.4083], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1337
agent= agent_5 distrib= tensor([0.7259, 0.2741], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7187, 0.2813], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1338
agent= agent_4 distrib= tensor([0.8563, 0.1437], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6424, 0.3576], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1339
agent= agent_3 distrib= tensor([0.7104, 0.2896], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5508, 0.4492], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1340
agent= agent_9 distrib= tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6114, 0.3886], grad_fn=<SoftmaxBackward0>)
Epoch : 1340 	 Measure: 0.4000000059604645
==========>Epoch= 1341
agent= agent_1 distrib= tensor([0.8020, 0.1980], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7407, 0.2593], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1342
agent= agent_0 distrib= tensor([0.7126, 0.2874], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7039, 0.2961], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1343
agent= agent_8 distrib= tensor([0.5693, 0.4307], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6409, 0.3591], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1344
agent= agent_3 distrib= tensor([0.7138, 0.2862], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6580, 0.3420], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1345
agent= agent_5 distrib= tensor([0.7265, 0.2735], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5673, 0.4327], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1346
agent= agent_7 distrib= tensor([0.6357, 0.3643], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5655, 0.4345], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1347
agent= agent_2 distrib= tensor([0.7199, 0.2801], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8541, 0.1459], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1348
agent= agent_7 distrib= tensor([0.6540, 0.3460], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8581, 0.1419], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1349
agent= agent_6 distrib= tensor([0.7389, 0.2611], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7467, 0.2533], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1350
agent= agent_5 distrib= tensor([0.7290, 0.2710], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6317, 0.3683], grad_fn=<SoftmaxBackward0>)
Epoch : 1350 	 Measure: 0.6000000238418579
==========>Epoch= 1351
agent= agent_6 distrib= tensor([0.7056, 0.2944], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1352
agent= agent_7 distrib= tensor([0.6721, 0.3279], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8809, 0.1191], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1353
agent= agent_6 distrib= tensor([0.7378, 0.2622], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6847, 0.3153], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1354
agent= agent_9 distrib= tensor([0.8208, 0.1792], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7051, 0.2949], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1355
agent= agent_5 distrib= tensor([0.7594, 0.2406], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7040, 0.2960], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1356
agent= agent_1 distrib= tensor([0.8045, 0.1955], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6067, 0.3933], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1357
agent= agent_2 distrib= tensor([0.7037, 0.2963], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7170, 0.2830], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1358
agent= agent_6 distrib= tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6404, 0.3596], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1359
agent= agent_9 distrib= tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7497, 0.2503], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1360
agent= agent_9 distrib= tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)
Epoch : 1360 	 Measure: 0.20000000298023224
==========>Epoch= 1361
agent= agent_5 distrib= tensor([0.7215, 0.2785], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7200, 0.2800], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1362
agent= agent_7 distrib= tensor([0.6290, 0.3710], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7341, 0.2659], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1363
agent= agent_8 distrib= tensor([0.5649, 0.4351], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8207, 0.1793], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1364
agent= agent_9 distrib= tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7637, 0.2363], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1365
agent= agent_8 distrib= tensor([0.6074, 0.3926], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8656, 0.1344], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1366
agent= agent_5 distrib= tensor([0.7252, 0.2748], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6505, 0.3495], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1367
agent= agent_4 distrib= tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6509, 0.3491], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1368
agent= agent_1 distrib= tensor([0.8074, 0.1926], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7151, 0.2849], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1369
agent= agent_1 distrib= tensor([0.8102, 0.1898], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7152, 0.2848], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1370
agent= agent_2 distrib= tensor([0.7185, 0.2815], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8398, 0.1602], grad_fn=<SoftmaxBackward0>)
Epoch : 1370 	 Measure: 0.6000000238418579
==========>Epoch= 1371
agent= agent_2 distrib= tensor([0.7033, 0.2967], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1372
agent= agent_5 distrib= tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1373
agent= agent_2 distrib= tensor([0.7318, 0.2682], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5946, 0.4054], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1374
agent= agent_7 distrib= tensor([0.6284, 0.3716], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7384, 0.2616], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1375
agent= agent_9 distrib= tensor([0.8669, 0.1331], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1376
agent= agent_8 distrib= tensor([0.5530, 0.4470], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7181, 0.2819], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1377
agent= agent_1 distrib= tensor([0.7800, 0.2200], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1378
agent= agent_9 distrib= tensor([0.8824, 0.1176], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1379
agent= agent_3 distrib= tensor([0.7229, 0.2771], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8682, 0.1318], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1380
agent= agent_8 distrib= tensor([0.6109, 0.3891], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7053, 0.2947], grad_fn=<SoftmaxBackward0>)
Epoch : 1380 	 Measure: 0.4000000059604645
==========>Epoch= 1381
agent= agent_9 distrib= tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6517, 0.3483], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1382
agent= agent_6 distrib= tensor([0.7042, 0.2958], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6121, 0.3879], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1383
agent= agent_6 distrib= tensor([0.7039, 0.2961], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7257, 0.2743], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1384
agent= agent_3 distrib= tensor([0.7291, 0.2709], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5565, 0.4435], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1385
agent= agent_3 distrib= tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1386
agent= agent_5 distrib= tensor([0.7424, 0.2576], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8344, 0.1656], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1387
agent= agent_9 distrib= tensor([0.8260, 0.1740], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5730, 0.4270], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1388
agent= agent_7 distrib= tensor([0.6505, 0.3495], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8631, 0.1369], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1389
agent= agent_7 distrib= tensor([0.6509, 0.3491], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1390
agent= agent_3 distrib= tensor([0.7354, 0.2646], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6523, 0.3477], grad_fn=<SoftmaxBackward0>)
Epoch : 1390 	 Measure: 0.6000000238418579
==========>Epoch= 1391
agent= agent_3 distrib= tensor([0.7799, 0.2201], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1392
agent= agent_5 distrib= tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7032, 0.2968], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1393
agent= agent_8 distrib= tensor([0.6158, 0.3842], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7032, 0.2968], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1394
agent= agent_1 distrib= tensor([0.7927, 0.2073], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7504, 0.2496], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1395
agent= agent_6 distrib= tensor([0.7332, 0.2668], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1396
agent= agent_1 distrib= tensor([0.7855, 0.2145], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6895, 0.3105], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1397
agent= agent_1 distrib= tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6316, 0.3684], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1398
agent= agent_3 distrib= tensor([0.7893, 0.2107], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6566, 0.3434], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1399
agent= agent_9 distrib= tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1400
agent= agent_6 distrib= tensor([0.7035, 0.2965], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6580, 0.3420], grad_fn=<SoftmaxBackward0>)
Epoch : 1400 	 Measure: 0.20000000298023224
==========>Epoch= 1401
agent= agent_2 distrib= tensor([0.7178, 0.2822], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8320, 0.1680], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1402
agent= agent_9 distrib= tensor([0.8298, 0.1702], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6867, 0.3133], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1403
agent= agent_9 distrib= tensor([0.8891, 0.1109], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1404
agent= agent_1 distrib= tensor([0.8031, 0.1969], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7009, 0.2991], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1405
agent= agent_7 distrib= tensor([0.6594, 0.3406], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7913, 0.2087], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1406
agent= agent_0 distrib= tensor([0.6428, 0.3572], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1407
agent= agent_5 distrib= tensor([0.7351, 0.2649], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.7865, 0.2135], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1408
agent= agent_4 distrib= tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7885, 0.2115], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1409
agent= agent_6 distrib= tensor([0.7326, 0.2674], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7902, 0.2098], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1410
agent= agent_6 distrib= tensor([0.7009, 0.2991], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7480, 0.2520], grad_fn=<SoftmaxBackward0>)
Epoch : 1410 	 Measure: 0.4000000059604645
==========>Epoch= 1411
agent= agent_3 distrib= tensor([0.7603, 0.2397], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7181, 0.2819], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1412
agent= agent_4 distrib= tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1413
agent= agent_3 distrib= tensor([0.7535, 0.2465], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1414
agent= agent_1 distrib= tensor([0.7975, 0.2025], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6034, 0.3966], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1415
agent= agent_6 distrib= tensor([0.7332, 0.2668], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8310, 0.1690], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1416
agent= agent_3 distrib= tensor([0.7950, 0.2050], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6046, 0.3954], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1417
agent= agent_6 distrib= tensor([0.7339, 0.2661], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1418
agent= agent_6 distrib= tensor([0.7028, 0.2972], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8121, 0.1879], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1419
agent= agent_6 distrib= tensor([0.7351, 0.2649], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6621, 0.3379], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1420
agent= agent_8 distrib= tensor([0.5639, 0.4361], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7359, 0.2641], grad_fn=<SoftmaxBackward0>)
Epoch : 1420 	 Measure: 0.4000000059604645
==========>Epoch= 1421
agent= agent_0 distrib= tensor([0.6902, 0.3098], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7036, 0.2964], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1422
agent= agent_9 distrib= tensor([0.8760, 0.1240], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7299, 0.2701], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1423
agent= agent_5 distrib= tensor([0.7377, 0.2623], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6220, 0.3780], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1424
agent= agent_9 distrib= tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6232, 0.3768], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1425
agent= agent_9 distrib= tensor([0.8782, 0.1218], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6246, 0.3754], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1426
agent= agent_5 distrib= tensor([0.7504, 0.2496], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6416, 0.3584], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1427
agent= agent_5 distrib= tensor([0.7691, 0.2309], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8052, 0.1948], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1428
agent= agent_9 distrib= tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7707, 0.2293], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1429
agent= agent_3 distrib= tensor([0.7964, 0.2036], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7346, 0.2654], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1430
agent= agent_7 distrib= tensor([0.6434, 0.3566], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8168, 0.1832], grad_fn=<SoftmaxBackward0>)
Epoch : 1430 	 Measure: 0.6000000238418579
==========>Epoch= 1431
agent= agent_5 distrib= tensor([0.7721, 0.2279], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7335, 0.2665], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1432
agent= agent_8 distrib= tensor([0.5651, 0.4349], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8021, 0.1979], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1433
agent= agent_8 distrib= tensor([0.5800, 0.4200], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8338, 0.1662], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1434
agent= agent_7 distrib= tensor([0.6908, 0.3092], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1435
agent= agent_4 distrib= tensor([0.8789, 0.1211], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6229, 0.3771], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1436
agent= agent_5 distrib= tensor([0.7575, 0.2425], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5795, 0.4205], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1437
agent= agent_3 distrib= tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5793, 0.4207], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1438
agent= agent_9 distrib= tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8046, 0.1954], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1439
agent= agent_9 distrib= tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7458, 0.2542], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1440
agent= agent_2 distrib= tensor([0.7344, 0.2656], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8010, 0.1990], grad_fn=<SoftmaxBackward0>)
Epoch : 1440 	 Measure: 0.4000000059604645
==========>Epoch= 1441
agent= agent_9 distrib= tensor([0.8754, 0.1246], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7873, 0.2127], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1442
agent= agent_1 distrib= tensor([0.8071, 0.1929], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1443
agent= agent_7 distrib= tensor([0.6470, 0.3530], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8294, 0.1706], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1444
agent= agent_1 distrib= tensor([0.8094, 0.1906], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1445
agent= agent_0 distrib= tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8075, 0.1925], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1446
agent= agent_1 distrib= tensor([0.8274, 0.1726], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8338, 0.1662], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1447
agent= agent_2 distrib= tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7334, 0.2666], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1448
agent= agent_7 distrib= tensor([0.6946, 0.3054], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7017, 0.2983], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1449
agent= agent_6 distrib= tensor([0.7335, 0.2665], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5642, 0.4358], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1450
agent= agent_3 distrib= tensor([0.8098, 0.1902], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward0>)
Epoch : 1450 	 Measure: 0.5
==========>Epoch= 1451
agent= agent_3 distrib= tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6504, 0.3496], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1452
agent= agent_3 distrib= tensor([0.8117, 0.1883], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1453
agent= agent_3 distrib= tensor([0.8117, 0.1883], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8134, 0.1866], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1454
agent= agent_9 distrib= tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7353, 0.2647], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1455
agent= agent_3 distrib= tensor([0.7756, 0.2244], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6971, 0.3029], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1456
agent= agent_0 distrib= tensor([0.7379, 0.2621], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8772, 0.1228], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1457
agent= agent_7 distrib= tensor([0.6504, 0.3496], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7206, 0.2794], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1458
agent= agent_9 distrib= tensor([0.8355, 0.1645], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5792, 0.4208], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1459
agent= agent_8 distrib= tensor([0.6093, 0.3907], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8924, 0.1076], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1460
agent= agent_6 distrib= tensor([0.7340, 0.2660], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6733, 0.3267], grad_fn=<SoftmaxBackward0>)
Epoch : 1460 	 Measure: 0.6000000238418579
==========>Epoch= 1461
agent= agent_9 distrib= tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5798, 0.4202], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1462
agent= agent_9 distrib= tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7689, 0.2311], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1463
agent= agent_9 distrib= tensor([0.8797, 0.1203], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6243, 0.3757], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1464
agent= agent_2 distrib= tensor([0.7369, 0.2631], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8092, 0.1908], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1465
agent= agent_1 distrib= tensor([0.8243, 0.1757], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7072, 0.2928], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1466
agent= agent_7 distrib= tensor([0.6736, 0.3264], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8857, 0.1143], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1467
agent= agent_2 distrib= tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1468
agent= agent_8 distrib= tensor([0.6260, 0.3740], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1469
agent= agent_3 distrib= tensor([0.7757, 0.2243], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8382, 0.1618], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1470
agent= agent_0 distrib= tensor([0.7089, 0.2911], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7351, 0.2649], grad_fn=<SoftmaxBackward0>)
Epoch : 1470 	 Measure: 0.6000000238418579
==========>Epoch= 1471
agent= agent_5 distrib= tensor([0.7529, 0.2471], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8863, 0.1137], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1472
agent= agent_9 distrib= tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8104, 0.1896], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1473
agent= agent_7 distrib= tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6552, 0.3448], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1474
agent= agent_4 distrib= tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7082, 0.2918], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1475
agent= agent_7 distrib= tensor([0.6511, 0.3489], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1476
agent= agent_9 distrib= tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6505, 0.3495], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1477
agent= agent_2 distrib= tensor([0.7503, 0.2497], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8135, 0.1865], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1478
agent= agent_5 distrib= tensor([0.7852, 0.2148], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1479
agent= agent_1 distrib= tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7242, 0.2758], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1480
agent= agent_8 distrib= tensor([0.6145, 0.3855], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7103, 0.2897], grad_fn=<SoftmaxBackward0>)
Epoch : 1480 	 Measure: 0.30000001192092896
==========>Epoch= 1481
agent= agent_0 distrib= tensor([0.6537, 0.3463], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1482
agent= agent_8 distrib= tensor([0.5867, 0.4133], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1483
agent= agent_5 distrib= tensor([0.8001, 0.1999], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7087, 0.2913], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1484
agent= agent_3 distrib= tensor([0.8146, 0.1854], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8199, 0.1801], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1485
agent= agent_5 distrib= tensor([0.8021, 0.1979], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1486
agent= agent_6 distrib= tensor([0.7094, 0.2906], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6314, 0.3686], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1487
agent= agent_7 distrib= tensor([0.6499, 0.3501], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7038, 0.2962], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1488
agent= agent_3 distrib= tensor([0.7783, 0.2217], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7062, 0.2938], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1489
agent= agent_5 distrib= tensor([0.7936, 0.2064], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8310, 0.1690], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1490
agent= agent_5 distrib= tensor([0.8057, 0.1943], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8587, 0.1413], grad_fn=<SoftmaxBackward0>)
Epoch : 1490 	 Measure: 0.5
==========>Epoch= 1491
agent= agent_6 distrib= tensor([0.7380, 0.2620], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6532, 0.3468], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1492
agent= agent_7 distrib= tensor([0.6479, 0.3521], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8326, 0.1674], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1493
agent= agent_1 distrib= tensor([0.8359, 0.1641], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7405, 0.2595], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1494
agent= agent_7 distrib= tensor([0.6737, 0.3263], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1495
agent= agent_9 distrib= tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1496
agent= agent_9 distrib= tensor([0.8427, 0.1573], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8440, 0.1560], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1497
agent= agent_9 distrib= tensor([0.8982, 0.1018], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7404, 0.2596], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1498
agent= agent_1 distrib= tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6523, 0.3477], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1499
agent= agent_5 distrib= tensor([0.7975, 0.2025], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6948, 0.3052], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1500
agent= agent_2 distrib= tensor([0.7258, 0.2742], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6461, 0.3539], grad_fn=<SoftmaxBackward0>)
Epoch : 1500 	 Measure: 0.5
==========>Epoch= 1501
agent= agent_3 distrib= tensor([0.7750, 0.2250], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7142, 0.2858], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1502
agent= agent_4 distrib= tensor([0.8827, 0.1173], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6726, 0.3274], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1503
agent= agent_3 distrib= tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7096, 0.2904], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1504
agent= agent_8 distrib= tensor([0.5901, 0.4099], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7840, 0.2160], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1505
agent= agent_0 distrib= tensor([0.7014, 0.2986], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1506
agent= agent_6 distrib= tensor([0.7103, 0.2897], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1507
agent= agent_5 distrib= tensor([0.8020, 0.1980], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7420, 0.2580], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1508
agent= agent_1 distrib= tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7109, 0.2891], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1509
agent= agent_2 distrib= tensor([0.7140, 0.2860], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7772, 0.2228], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1510
agent= agent_7 distrib= tensor([0.6946, 0.3054], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)
Epoch : 1510 	 Measure: 0.30000001192092896
==========>Epoch= 1511
agent= agent_7 distrib= tensor([0.6461, 0.3539], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5916, 0.4084], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1512
agent= agent_9 distrib= tensor([0.8865, 0.1135], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6362, 0.3638], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1513
agent= agent_5 distrib= tensor([0.7889, 0.2111], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5946, 0.4054], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1514
agent= agent_1 distrib= tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7783, 0.2217], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1515
agent= agent_5 distrib= tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6251, 0.3749], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1516
agent= agent_5 distrib= tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5976, 0.4024], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1517
agent= agent_6 distrib= tensor([0.7441, 0.2559], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6281, 0.3719], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1518
agent= agent_0 distrib= tensor([0.6526, 0.3474], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1519
agent= agent_1 distrib= tensor([0.8512, 0.1488], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6008, 0.3992], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1520
agent= agent_2 distrib= tensor([0.7149, 0.2851], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7795, 0.2205], grad_fn=<SoftmaxBackward0>)
Epoch : 1520 	 Measure: 0.699999988079071
==========>Epoch= 1521
agent= agent_6 distrib= tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1522
agent= agent_4 distrib= tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1523
agent= agent_3 distrib= tensor([0.8244, 0.1756], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8207, 0.1793], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1524
agent= agent_7 distrib= tensor([0.6732, 0.3268], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8254, 0.1746], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1525
agent= agent_4 distrib= tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6466, 0.3534], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1526
agent= agent_6 distrib= tensor([0.7188, 0.2812], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6747, 0.3253], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1527
agent= agent_7 distrib= tensor([0.6489, 0.3511], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7292, 0.2708], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1528
agent= agent_5 distrib= tensor([0.8225, 0.1775], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1529
agent= agent_4 distrib= tensor([0.8863, 0.1137], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7455, 0.2545], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1530
agent= agent_6 distrib= tensor([0.7205, 0.2795], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6777, 0.3223], grad_fn=<SoftmaxBackward0>)
Epoch : 1530 	 Measure: 0.5
==========>Epoch= 1531
agent= agent_1 distrib= tensor([0.8413, 0.1587], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8270, 0.1730], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1532
agent= agent_9 distrib= tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6797, 0.3203], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1533
agent= agent_2 distrib= tensor([0.7167, 0.2833], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6456, 0.3544], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1534
agent= agent_9 distrib= tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7160, 0.2840], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1535
agent= agent_9 distrib= tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7032, 0.2968], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1536
agent= agent_4 distrib= tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8504, 0.1496], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1537
agent= agent_2 distrib= tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8140, 0.1860], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1538
agent= agent_5 distrib= tensor([0.8006, 0.1994], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8389, 0.1611], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1539
agent= agent_4 distrib= tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1540
agent= agent_2 distrib= tensor([0.7292, 0.2708], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6022, 0.3978], grad_fn=<SoftmaxBackward0>)
Epoch : 1540 	 Measure: 0.6000000238418579
==========>Epoch= 1541
agent= agent_7 distrib= tensor([0.6581, 0.3419], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7276, 0.2724], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1542
agent= agent_5 distrib= tensor([0.8275, 0.1725], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7124, 0.2876], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1543
agent= agent_3 distrib= tensor([0.8267, 0.1733], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7087, 0.2913], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1544
agent= agent_0 distrib= tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6866, 0.3134], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1545
agent= agent_8 distrib= tensor([0.5846, 0.4154], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8436, 0.1564], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1546
agent= agent_0 distrib= tensor([0.7148, 0.2852], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8187, 0.1813], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1547
agent= agent_7 distrib= tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7112, 0.2888], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1548
agent= agent_4 distrib= tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7244, 0.2756], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1549
agent= agent_7 distrib= tensor([0.6904, 0.3096], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8849, 0.1151], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1550
agent= agent_9 distrib= tensor([0.8860, 0.1140], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.7935, 0.2065], grad_fn=<SoftmaxBackward0>)
Epoch : 1550 	 Measure: 0.6000000238418579
==========>Epoch= 1551
agent= agent_5 distrib= tensor([0.8215, 0.1785], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7401, 0.2599], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1552
agent= agent_8 distrib= tensor([0.5835, 0.4165], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1553
agent= agent_4 distrib= tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7514, 0.2486], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1554
agent= agent_3 distrib= tensor([0.7921, 0.2079], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1555
agent= agent_4 distrib= tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7887, 0.2113], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1556
agent= agent_1 distrib= tensor([0.8547, 0.1453], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6265, 0.3735], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1557
agent= agent_0 distrib= tensor([0.6560, 0.3440], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7499, 0.2501], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1558
agent= agent_7 distrib= tensor([0.6922, 0.3078], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7901, 0.2099], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1559
agent= agent_1 distrib= tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1560
agent= agent_4 distrib= tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8360, 0.1640], grad_fn=<SoftmaxBackward0>)
Epoch : 1560 	 Measure: 0.5
==========>Epoch= 1561
agent= agent_2 distrib= tensor([0.7411, 0.2589], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1562
agent= agent_3 distrib= tensor([0.7915, 0.2085], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5818, 0.4182], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1563
agent= agent_0 distrib= tensor([0.7071, 0.2929], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8435, 0.1565], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1564
agent= agent_2 distrib= tensor([0.7523, 0.2477], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1565
agent= agent_9 distrib= tensor([0.8560, 0.1440], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8617, 0.1383], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1566
agent= agent_8 distrib= tensor([0.5814, 0.4186], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7511, 0.2489], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1567
agent= agent_1 distrib= tensor([0.8617, 0.1383], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1568
agent= agent_7 distrib= tensor([0.6707, 0.3293], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5950, 0.4050], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1569
agent= agent_2 distrib= tensor([0.7527, 0.2473], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6586, 0.3414], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1570
agent= agent_1 distrib= tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)
Epoch : 1570 	 Measure: 0.5
==========>Epoch= 1571
agent= agent_7 distrib= tensor([0.6956, 0.3044], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7524, 0.2476], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1572
agent= agent_3 distrib= tensor([0.8334, 0.1666], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6257, 0.3743], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1573
agent= agent_7 distrib= tensor([0.6972, 0.3028], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8375, 0.1625], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1574
agent= agent_6 distrib= tensor([0.7570, 0.2430], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7228, 0.2772], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1575
agent= agent_8 distrib= tensor([0.6382, 0.3618], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1576
agent= agent_7 distrib= tensor([0.7241, 0.2759], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7427, 0.2573], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1577
agent= agent_2 distrib= tensor([0.7253, 0.2747], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1578
agent= agent_3 distrib= tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7541, 0.2459], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1579
agent= agent_1 distrib= tensor([0.8838, 0.1162], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1580
agent= agent_9 distrib= tensor([0.8991, 0.1009], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)
Epoch : 1580 	 Measure: 0.5
==========>Epoch= 1581
agent= agent_2 distrib= tensor([0.7547, 0.2453], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6599, 0.3401], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1582
agent= agent_3 distrib= tensor([0.8009, 0.1991], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1583
agent= agent_6 distrib= tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1584
agent= agent_1 distrib= tensor([0.8849, 0.1151], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7063, 0.2937], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1585
agent= agent_8 distrib= tensor([0.6273, 0.3727], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1586
agent= agent_9 distrib= tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1587
agent= agent_6 distrib= tensor([0.7326, 0.2674], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6397, 0.3603], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1588
agent= agent_2 distrib= tensor([0.7266, 0.2734], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7264, 0.2736], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1589
agent= agent_7 distrib= tensor([0.6807, 0.3193], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1590
agent= agent_9 distrib= tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7357, 0.2643], grad_fn=<SoftmaxBackward0>)
Epoch : 1590 	 Measure: 0.800000011920929
==========>Epoch= 1591
agent= agent_9 distrib= tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8401, 0.1599], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1592
agent= agent_4 distrib= tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1593
agent= agent_1 distrib= tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6291, 0.3709], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1594
agent= agent_4 distrib= tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1595
agent= agent_3 distrib= tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1596
agent= agent_7 distrib= tensor([0.7291, 0.2709], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1597
agent= agent_9 distrib= tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8029, 0.1971], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1598
agent= agent_8 distrib= tensor([0.6004, 0.3996], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8694, 0.1306], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1599
agent= agent_0 distrib= tensor([0.6624, 0.3376], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7571, 0.2429], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1600
agent= agent_8 distrib= tensor([0.6428, 0.3572], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)
Epoch : 1600 	 Measure: 0.699999988079071
==========>Epoch= 1601
agent= agent_2 distrib= tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1602
agent= agent_0 distrib= tensor([0.7255, 0.2745], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6326, 0.3674], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1603
agent= agent_7 distrib= tensor([0.6840, 0.3160], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7312, 0.2688], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1604
agent= agent_1 distrib= tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7128, 0.2872], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1605
agent= agent_2 distrib= tensor([0.7612, 0.2388], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1606
agent= agent_8 distrib= tensor([0.6338, 0.3662], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1607
agent= agent_4 distrib= tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1608
agent= agent_5 distrib= tensor([0.8089, 0.1911], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1609
agent= agent_1 distrib= tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6443, 0.3557], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1610
agent= agent_5 distrib= tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7107, 0.2893], grad_fn=<SoftmaxBackward0>)
Epoch : 1610 	 Measure: 0.6000000238418579
==========>Epoch= 1611
agent= agent_1 distrib= tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6437, 0.3563], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1612
agent= agent_8 distrib= tensor([0.6029, 0.3971], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8775, 0.1225], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1613
agent= agent_1 distrib= tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1614
agent= agent_6 distrib= tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1615
agent= agent_9 distrib= tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6011, 0.3989], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1616
agent= agent_7 distrib= tensor([0.7381, 0.2619], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8455, 0.1545], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1617
agent= agent_0 distrib= tensor([0.7164, 0.2836], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.6922, 0.3078], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1618
agent= agent_1 distrib= tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1619
agent= agent_4 distrib= tensor([0.9277, 0.0723], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8407, 0.1593], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1620
agent= agent_1 distrib= tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8568, 0.1432], grad_fn=<SoftmaxBackward0>)
Epoch : 1620 	 Measure: 0.4000000059604645
==========>Epoch= 1621
agent= agent_3 distrib= tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7188, 0.2812], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1622
agent= agent_8 distrib= tensor([0.5854, 0.4146], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7645, 0.2355], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1623
agent= agent_5 distrib= tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1624
agent= agent_2 distrib= tensor([0.7216, 0.2784], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1625
agent= agent_6 distrib= tensor([0.7369, 0.2631], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8086, 0.1914], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1626
agent= agent_6 distrib= tensor([0.7372, 0.2628], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1627
agent= agent_6 distrib= tensor([0.7298, 0.2702], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1628
agent= agent_4 distrib= tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1629
agent= agent_0 distrib= tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1630
agent= agent_6 distrib= tensor([0.7302, 0.2698], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)
Epoch : 1630 	 Measure: 0.4000000059604645
==========>Epoch= 1631
agent= agent_0 distrib= tensor([0.6800, 0.3200], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1632
agent= agent_9 distrib= tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8706, 0.1294], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1633
agent= agent_1 distrib= tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7292, 0.2708], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1634
agent= agent_9 distrib= tensor([0.8740, 0.1260], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7294, 0.2706], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1635
agent= agent_8 distrib= tensor([0.5841, 0.4159], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7218, 0.2782], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1636
agent= agent_8 distrib= tensor([0.6227, 0.3773], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7448, 0.2552], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1637
agent= agent_2 distrib= tensor([0.7225, 0.2775], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1638
agent= agent_9 distrib= tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7224, 0.2776], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1639
agent= agent_8 distrib= tensor([0.5936, 0.4064], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1640
agent= agent_4 distrib= tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7179, 0.2821], grad_fn=<SoftmaxBackward0>)
Epoch : 1640 	 Measure: 0.699999988079071
==========>Epoch= 1641
agent= agent_4 distrib= tensor([0.9319, 0.0681], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7535, 0.2465], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1642
agent= agent_2 distrib= tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8153, 0.1847], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1643
agent= agent_3 distrib= tensor([0.8135, 0.1865], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6865, 0.3135], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1644
agent= agent_4 distrib= tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8563, 0.1437], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1645
agent= agent_7 distrib= tensor([0.6951, 0.3049], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7351, 0.2649], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1646
agent= agent_7 distrib= tensor([0.7426, 0.2574], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1647
agent= agent_5 distrib= tensor([0.8433, 0.1567], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1648
agent= agent_6 distrib= tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7194, 0.2806], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1649
agent= agent_4 distrib= tensor([0.9327, 0.0673], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7638, 0.2362], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1650
agent= agent_9 distrib= tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)
Epoch : 1650 	 Measure: 0.30000001192092896
==========>Epoch= 1651
agent= agent_7 distrib= tensor([0.6967, 0.3033], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8199, 0.1801], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1652
agent= agent_1 distrib= tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6315, 0.3685], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1653
agent= agent_3 distrib= tensor([0.8189, 0.1811], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1654
agent= agent_7 distrib= tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6303, 0.3697], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1655
agent= agent_0 distrib= tensor([0.7795, 0.2205], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7353, 0.2647], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1656
agent= agent_0 distrib= tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1657
agent= agent_0 distrib= tensor([0.7839, 0.2161], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1658
agent= agent_4 distrib= tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7631, 0.2369], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1659
agent= agent_5 distrib= tensor([0.8276, 0.1724], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1660
agent= agent_8 distrib= tensor([0.6159, 0.3841], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9342, 0.0658], grad_fn=<SoftmaxBackward0>)
Epoch : 1660 	 Measure: 0.5
==========>Epoch= 1661
agent= agent_7 distrib= tensor([0.7214, 0.2786], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7633, 0.2367], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1662
agent= agent_7 distrib= tensor([0.7222, 0.2778], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1663
agent= agent_6 distrib= tensor([0.7589, 0.2411], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5735, 0.4265], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1664
agent= agent_0 distrib= tensor([0.7860, 0.2140], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1665
agent= agent_6 distrib= tensor([0.7333, 0.2667], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7635, 0.2365], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1666
agent= agent_1 distrib= tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6270, 0.3730], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1667
agent= agent_0 distrib= tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1668
agent= agent_9 distrib= tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7550, 0.2450], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1669
agent= agent_0 distrib= tensor([0.7023, 0.2977], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7534, 0.2466], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1670
agent= agent_0 distrib= tensor([0.7642, 0.2358], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8448, 0.1552], grad_fn=<SoftmaxBackward0>)
Epoch : 1670 	 Measure: 0.5
==========>Epoch= 1671
agent= agent_5 distrib= tensor([0.8431, 0.1569], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7571, 0.2429], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1672
agent= agent_2 distrib= tensor([0.7352, 0.2648], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8688, 0.1312], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1673
agent= agent_6 distrib= tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8603, 0.1397], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1674
agent= agent_7 distrib= tensor([0.7231, 0.2769], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8228, 0.1772], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1675
agent= agent_4 distrib= tensor([0.9353, 0.0647], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8634, 0.1366], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1676
agent= agent_3 distrib= tensor([0.8247, 0.1753], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1677
agent= agent_3 distrib= tensor([0.8264, 0.1736], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1678
agent= agent_7 distrib= tensor([0.7250, 0.2750], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7911, 0.2089], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1679
agent= agent_0 distrib= tensor([0.7030, 0.2970], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7516, 0.2484], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1680
agent= agent_6 distrib= tensor([0.7514, 0.2486], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)
Epoch : 1680 	 Measure: 0.30000001192092896
==========>Epoch= 1681
agent= agent_8 distrib= tensor([0.6257, 0.3743], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1682
agent= agent_1 distrib= tensor([0.8600, 0.1400], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7029, 0.2971], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1683
agent= agent_4 distrib= tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6247, 0.3753], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1684
agent= agent_8 distrib= tensor([0.6241, 0.3759], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8127, 0.1873], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1685
agent= agent_8 distrib= tensor([0.6093, 0.3907], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8634, 0.1366], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1686
agent= agent_0 distrib= tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8717, 0.1283], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1687
agent= agent_6 distrib= tensor([0.7287, 0.2713], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1688
agent= agent_4 distrib= tensor([0.9369, 0.0631], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7584, 0.2416], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1689
agent= agent_1 distrib= tensor([0.8505, 0.1495], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5671, 0.4329], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1690
agent= agent_7 distrib= tensor([0.7511, 0.2489], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8650, 0.1350], grad_fn=<SoftmaxBackward0>)
Epoch : 1690 	 Measure: 0.699999988079071
==========>Epoch= 1691
agent= agent_7 distrib= tensor([0.7526, 0.2474], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8403, 0.1597], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1692
agent= agent_1 distrib= tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1693
agent= agent_0 distrib= tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7596, 0.2404], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1694
agent= agent_9 distrib= tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8742, 0.1258], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1695
agent= agent_7 distrib= tensor([0.7319, 0.2681], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8515, 0.1485], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1696
agent= agent_4 distrib= tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1697
agent= agent_5 distrib= tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7391, 0.2609], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1698
agent= agent_8 distrib= tensor([0.6131, 0.3869], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1699
agent= agent_2 distrib= tensor([0.7619, 0.2381], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1700
agent= agent_4 distrib= tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7348, 0.2652], grad_fn=<SoftmaxBackward0>)
Epoch : 1700 	 Measure: 0.5
==========>Epoch= 1701
agent= agent_2 distrib= tensor([0.7630, 0.2370], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9392, 0.0608], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1702
agent= agent_0 distrib= tensor([0.7026, 0.2974], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7509, 0.2491], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1703
agent= agent_0 distrib= tensor([0.7487, 0.2513], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7420, 0.2580], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1704
agent= agent_3 distrib= tensor([0.8348, 0.1652], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7115, 0.2885], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1705
agent= agent_0 distrib= tensor([0.7468, 0.2532], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1706
agent= agent_3 distrib= tensor([0.8700, 0.1300], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9299, 0.0701], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1707
agent= agent_9 distrib= tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1708
agent= agent_9 distrib= tensor([0.9205, 0.0795], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7379, 0.2621], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1709
agent= agent_5 distrib= tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1710
agent= agent_5 distrib= tensor([0.8486, 0.1514], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9212, 0.0788], grad_fn=<SoftmaxBackward0>)
Epoch : 1710 	 Measure: 0.4000000059604645
==========>Epoch= 1711
agent= agent_4 distrib= tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1712
agent= agent_1 distrib= tensor([0.8625, 0.1375], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1713
agent= agent_2 distrib= tensor([0.7409, 0.2591], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1714
agent= agent_8 distrib= tensor([0.5692, 0.4308], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1715
agent= agent_3 distrib= tensor([0.8722, 0.1278], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7719, 0.2281], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1716
agent= agent_9 distrib= tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7392, 0.2608], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1717
agent= agent_2 distrib= tensor([0.7305, 0.2695], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1718
agent= agent_1 distrib= tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9407, 0.0593], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1719
agent= agent_0 distrib= tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1720
agent= agent_4 distrib= tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)
Epoch : 1720 	 Measure: 0.800000011920929
==========>Epoch= 1721
agent= agent_3 distrib= tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8679, 0.1321], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1722
agent= agent_2 distrib= tensor([0.7401, 0.2599], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8863, 0.1137], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1723
agent= agent_2 distrib= tensor([0.7640, 0.2360], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1724
agent= agent_0 distrib= tensor([0.7576, 0.2424], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8364, 0.1636], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1725
agent= agent_3 distrib= tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7849, 0.2151], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1726
agent= agent_2 distrib= tensor([0.7642, 0.2358], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7624, 0.2376], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1727
agent= agent_9 distrib= tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6317, 0.3683], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1728
agent= agent_7 distrib= tensor([0.7171, 0.2829], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8841, 0.1159], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1729
agent= agent_4 distrib= tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1730
agent= agent_2 distrib= tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7434, 0.2566], grad_fn=<SoftmaxBackward0>)
Epoch : 1730 	 Measure: 0.5
==========>Epoch= 1731
agent= agent_0 distrib= tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5680, 0.4320], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1732
agent= agent_5 distrib= tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1733
agent= agent_3 distrib= tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7556, 0.2444], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1734
agent= agent_8 distrib= tensor([0.5876, 0.4124], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1735
agent= agent_3 distrib= tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8210, 0.1790], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1736
agent= agent_0 distrib= tensor([0.7548, 0.2452], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1737
agent= agent_6 distrib= tensor([0.7196, 0.2804], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7197, 0.2803], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1738
agent= agent_2 distrib= tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7678, 0.2322], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1739
agent= agent_6 distrib= tensor([0.7558, 0.2442], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7659, 0.2341], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1740
agent= agent_6 distrib= tensor([0.7295, 0.2705], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)
Epoch : 1740 	 Measure: 0.6000000238418579
==========>Epoch= 1741
agent= agent_8 distrib= tensor([0.5876, 0.4124], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7405, 0.2595], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1742
agent= agent_9 distrib= tensor([0.9189, 0.0811], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7726, 0.2274], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1743
agent= agent_1 distrib= tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9424, 0.0576], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1744
agent= agent_3 distrib= tensor([0.8817, 0.1183], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1745
agent= agent_1 distrib= tensor([0.8669, 0.1331], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1746
agent= agent_1 distrib= tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7303, 0.2697], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1747
agent= agent_2 distrib= tensor([0.7646, 0.2354], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7541, 0.2459], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1748
agent= agent_7 distrib= tensor([0.7448, 0.2552], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7321, 0.2679], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1749
agent= agent_9 distrib= tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1750
agent= agent_9 distrib= tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7825, 0.2175], grad_fn=<SoftmaxBackward0>)
Epoch : 1750 	 Measure: 0.6000000238418579
==========>Epoch= 1751
agent= agent_4 distrib= tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1752
agent= agent_7 distrib= tensor([0.7439, 0.2561], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7326, 0.2674], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1753
agent= agent_6 distrib= tensor([0.7584, 0.2416], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1754
agent= agent_7 distrib= tensor([0.7438, 0.2562], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7539, 0.2461], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1755
agent= agent_8 distrib= tensor([0.6342, 0.3658], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1756
agent= agent_4 distrib= tensor([0.8838, 0.1162], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7225, 0.2775], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1757
agent= agent_3 distrib= tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1758
agent= agent_1 distrib= tensor([0.8742, 0.1258], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6173, 0.3827], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1759
agent= agent_5 distrib= tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5680, 0.4320], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1760
agent= agent_3 distrib= tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6371, 0.3629], grad_fn=<SoftmaxBackward0>)
Epoch : 1760 	 Measure: 0.4000000059604645
==========>Epoch= 1761
agent= agent_0 distrib= tensor([0.7537, 0.2463], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8390, 0.1610], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1762
agent= agent_6 distrib= tensor([0.7230, 0.2770], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8241, 0.1759], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1763
agent= agent_1 distrib= tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6382, 0.3618], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1764
agent= agent_2 distrib= tensor([0.7331, 0.2669], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6407, 0.3593], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1765
agent= agent_5 distrib= tensor([0.8105, 0.1895], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7560, 0.2440], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1766
agent= agent_8 distrib= tensor([0.6443, 0.3557], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1767
agent= agent_6 distrib= tensor([0.7625, 0.2375], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6297, 0.3703], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1768
agent= agent_8 distrib= tensor([0.6533, 0.3467], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1769
agent= agent_6 distrib= tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1770
agent= agent_9 distrib= tensor([0.9293, 0.0707], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)
Epoch : 1770 	 Measure: 0.20000000298023224
==========>Epoch= 1771
agent= agent_1 distrib= tensor([0.8739, 0.1261], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6046, 0.3954], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1772
agent= agent_0 distrib= tensor([0.7396, 0.2604], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1773
agent= agent_8 distrib= tensor([0.6055, 0.3945], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7222, 0.2778], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1774
agent= agent_0 distrib= tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9261, 0.0739], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1775
agent= agent_3 distrib= tensor([0.8515, 0.1485], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7277, 0.2723], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1776
agent= agent_4 distrib= tensor([0.9445, 0.0555], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7503, 0.2497], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1777
agent= agent_6 distrib= tensor([0.7674, 0.2326], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7663, 0.2337], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1778
agent= agent_5 distrib= tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1779
agent= agent_8 distrib= tensor([0.5822, 0.4178], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8637, 0.1363], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1780
agent= agent_2 distrib= tensor([0.7650, 0.2350], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)
Epoch : 1780 	 Measure: 0.5
==========>Epoch= 1781
agent= agent_5 distrib= tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1782
agent= agent_5 distrib= tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7701, 0.2299], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1783
agent= agent_7 distrib= tensor([0.7519, 0.2481], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8483, 0.1517], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1784
agent= agent_4 distrib= tensor([0.9240, 0.0760], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6622, 0.3378], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1785
agent= agent_5 distrib= tensor([0.8279, 0.1721], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1786
agent= agent_4 distrib= tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8286, 0.1714], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1787
agent= agent_4 distrib= tensor([0.9463, 0.0537], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1788
agent= agent_1 distrib= tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7531, 0.2469], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1789
agent= agent_2 distrib= tensor([0.7415, 0.2585], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6077, 0.3923], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1790
agent= agent_1 distrib= tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)
Epoch : 1790 	 Measure: 0.6000000238418579
==========>Epoch= 1791
agent= agent_9 distrib= tensor([0.9296, 0.0704], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7669, 0.2331], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1792
agent= agent_1 distrib= tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9264, 0.0736], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1793
agent= agent_2 distrib= tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6876, 0.3124], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1794
agent= agent_3 distrib= tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1795
agent= agent_8 distrib= tensor([0.6650, 0.3350], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7561, 0.2439], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1796
agent= agent_1 distrib= tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1797
agent= agent_2 distrib= tensor([0.7301, 0.2699], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8577, 0.1423], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1798
agent= agent_7 distrib= tensor([0.7319, 0.2681], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1799
agent= agent_2 distrib= tensor([0.7402, 0.2598], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6093, 0.3907], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1800
agent= agent_4 distrib= tensor([0.9278, 0.0722], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)
Epoch : 1800 	 Measure: 0.5
==========>Epoch= 1801
agent= agent_8 distrib= tensor([0.5854, 0.4146], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7552, 0.2448], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1802
agent= agent_2 distrib= tensor([0.7614, 0.2386], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9302, 0.0698], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1803
agent= agent_8 distrib= tensor([0.6685, 0.3315], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6874, 0.3126], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1804
agent= agent_7 distrib= tensor([0.7565, 0.2435], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7385, 0.2615], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1805
agent= agent_3 distrib= tensor([0.8822, 0.1178], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1806
agent= agent_6 distrib= tensor([0.7287, 0.2713], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8473, 0.1527], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1807
agent= agent_6 distrib= tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8473, 0.1527], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1808
agent= agent_3 distrib= tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9284, 0.0716], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1809
agent= agent_8 distrib= tensor([0.5864, 0.4136], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7707, 0.2293], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1810
agent= agent_8 distrib= tensor([0.6130, 0.3870], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7411, 0.2589], grad_fn=<SoftmaxBackward0>)
Epoch : 1810 	 Measure: 0.699999988079071
==========>Epoch= 1811
agent= agent_7 distrib= tensor([0.7577, 0.2423], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7298, 0.2702], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1812
agent= agent_6 distrib= tensor([0.7659, 0.2341], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1813
agent= agent_8 distrib= tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8467, 0.1533], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1814
agent= agent_8 distrib= tensor([0.6772, 0.3228], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6884, 0.3116], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1815
agent= agent_2 distrib= tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7768, 0.2232], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1816
agent= agent_2 distrib= tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1817
agent= agent_8 distrib= tensor([0.6190, 0.3810], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1818
agent= agent_6 distrib= tensor([0.7288, 0.2712], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7400, 0.2600], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1819
agent= agent_7 distrib= tensor([0.7810, 0.2190], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6578, 0.3422], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1820
agent= agent_2 distrib= tensor([0.7264, 0.2736], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7613, 0.2387], grad_fn=<SoftmaxBackward0>)
Epoch : 1820 	 Measure: 0.5
==========>Epoch= 1821
agent= agent_0 distrib= tensor([0.6840, 0.3160], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6777, 0.3223], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1822
agent= agent_1 distrib= tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7625, 0.2375], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1823
agent= agent_9 distrib= tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1824
agent= agent_9 distrib= tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1825
agent= agent_0 distrib= tensor([0.6812, 0.3188], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7679, 0.2321], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1826
agent= agent_8 distrib= tensor([0.5972, 0.4028], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8521, 0.1479], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1827
agent= agent_7 distrib= tensor([0.7388, 0.2612], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8318, 0.1682], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1828
agent= agent_9 distrib= tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.5981, 0.4019], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1829
agent= agent_5 distrib= tensor([0.8490, 0.1510], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1830
agent= agent_4 distrib= tensor([0.9324, 0.0676], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6802, 0.3198], grad_fn=<SoftmaxBackward0>)
Epoch : 1830 	 Measure: 0.699999988079071
==========>Epoch= 1831
agent= agent_4 distrib= tensor([0.9491, 0.0509], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7560, 0.2440], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1832
agent= agent_8 distrib= tensor([0.6785, 0.3215], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9302, 0.0698], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1833
agent= agent_4 distrib= tensor([0.8963, 0.1037], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8339, 0.1661], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1834
agent= agent_7 distrib= tensor([0.7849, 0.2151], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1835
agent= agent_0 distrib= tensor([0.7392, 0.2608], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6601, 0.3399], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1836
agent= agent_8 distrib= tensor([0.6018, 0.3982], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7662, 0.2338], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1837
agent= agent_1 distrib= tensor([0.8532, 0.1468], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7302, 0.2698], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1838
agent= agent_4 distrib= tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6259, 0.3741], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1839
agent= agent_9 distrib= tensor([0.9324, 0.0676], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6667, 0.3333], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1840
agent= agent_8 distrib= tensor([0.6294, 0.3706], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)
Epoch : 1840 	 Measure: 0.6000000238418579
==========>Epoch= 1841
agent= agent_3 distrib= tensor([0.8875, 0.1125], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1842
agent= agent_9 distrib= tensor([0.9336, 0.0664], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8515, 0.1485], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1843
agent= agent_5 distrib= tensor([0.8225, 0.1775], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7652, 0.2348], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1844
agent= agent_9 distrib= tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7214, 0.2786], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1845
agent= agent_6 distrib= tensor([0.7388, 0.2612], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7638, 0.2362], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1846
agent= agent_3 distrib= tensor([0.8886, 0.1114], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9350, 0.0650], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1847
agent= agent_7 distrib= tensor([0.7441, 0.2559], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8385, 0.1615], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1848
agent= agent_8 distrib= tensor([0.6101, 0.3899], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1849
agent= agent_0 distrib= tensor([0.7359, 0.2641], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1850
agent= agent_2 distrib= tensor([0.7241, 0.2759], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)
Epoch : 1850 	 Measure: 0.699999988079071
==========>Epoch= 1851
agent= agent_9 distrib= tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6772, 0.3228], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1852
agent= agent_7 distrib= tensor([0.7898, 0.2102], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9511, 0.0489], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1853
agent= agent_8 distrib= tensor([0.6894, 0.3106], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7735, 0.2265], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1854
agent= agent_8 distrib= tensor([0.6744, 0.3256], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9515, 0.0485], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1855
agent= agent_8 distrib= tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1856
agent= agent_0 distrib= tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1857
agent= agent_5 distrib= tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1858
agent= agent_6 distrib= tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1859
agent= agent_4 distrib= tensor([0.9369, 0.0631], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8283, 0.1717], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1860
agent= agent_2 distrib= tensor([0.7550, 0.2450], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9359, 0.0641], grad_fn=<SoftmaxBackward0>)
Epoch : 1860 	 Measure: 0.30000001192092896
==========>Epoch= 1861
agent= agent_0 distrib= tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1862
agent= agent_4 distrib= tensor([0.9374, 0.0626], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7232, 0.2768], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1863
agent= agent_9 distrib= tensor([0.9369, 0.0631], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1864
agent= agent_1 distrib= tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8615, 0.1385], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1865
agent= agent_6 distrib= tensor([0.7384, 0.2616], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9379, 0.0621], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1866
agent= agent_9 distrib= tensor([0.9278, 0.0722], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7664, 0.2336], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1867
agent= agent_3 distrib= tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1868
agent= agent_4 distrib= tensor([0.9385, 0.0615], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8303, 0.1697], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1869
agent= agent_9 distrib= tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8477, 0.1523], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1870
agent= agent_7 distrib= tensor([0.7499, 0.2501], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6385, 0.3615], grad_fn=<SoftmaxBackward0>)
Epoch : 1870 	 Measure: 0.5
==========>Epoch= 1871
agent= agent_7 distrib= tensor([0.7967, 0.2033], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9537, 0.0463], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1872
agent= agent_9 distrib= tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1873
agent= agent_6 distrib= tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6789, 0.3211], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1874
agent= agent_5 distrib= tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1875
agent= agent_2 distrib= tensor([0.7663, 0.2337], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7809, 0.2191], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1876
agent= agent_4 distrib= tensor([0.9400, 0.0600], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1877
agent= agent_1 distrib= tensor([0.8694, 0.1306], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7640, 0.2360], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1878
agent= agent_6 distrib= tensor([0.7654, 0.2346], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9388, 0.0612], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1879
agent= agent_4 distrib= tensor([0.9548, 0.0452], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1880
agent= agent_9 distrib= tensor([0.9300, 0.0700], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7663, 0.2337], grad_fn=<SoftmaxBackward0>)
Epoch : 1880 	 Measure: 0.30000001192092896
==========>Epoch= 1881
agent= agent_0 distrib= tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9376, 0.0624], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1882
agent= agent_4 distrib= tensor([0.9380, 0.0620], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1883
agent= agent_4 distrib= tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6399, 0.3601], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1884
agent= agent_5 distrib= tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8688, 0.1312], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1885
agent= agent_2 distrib= tensor([0.7667, 0.2333], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6221, 0.3779], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1886
agent= agent_1 distrib= tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9562, 0.0438], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1887
agent= agent_3 distrib= tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.8982, 0.1018], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1888
agent= agent_2 distrib= tensor([0.7669, 0.2331], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8678, 0.1322], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1889
agent= agent_1 distrib= tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1890
agent= agent_9 distrib= tensor([0.9401, 0.0599], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8987, 0.1013], grad_fn=<SoftmaxBackward0>)
Epoch : 1890 	 Measure: 0.5
==========>Epoch= 1891
agent= agent_5 distrib= tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6237, 0.3763], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1892
agent= agent_8 distrib= tensor([0.7016, 0.2984], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7833, 0.2167], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1893
agent= agent_8 distrib= tensor([0.6264, 0.3736], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9434, 0.0566], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1894
agent= agent_9 distrib= tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7301, 0.2699], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1895
agent= agent_6 distrib= tensor([0.7664, 0.2336], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1896
agent= agent_9 distrib= tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1897
agent= agent_8 distrib= tensor([0.6893, 0.3107], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9574, 0.0426], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1898
agent= agent_9 distrib= tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9411, 0.0589], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1899
agent= agent_9 distrib= tensor([0.9416, 0.0584], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7668, 0.2332], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1900
agent= agent_3 distrib= tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)
Epoch : 1900 	 Measure: 0.4000000059604645
==========>Epoch= 1901
agent= agent_4 distrib= tensor([0.9416, 0.0584], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7673, 0.2327], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1902
agent= agent_8 distrib= tensor([0.6469, 0.3531], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7384, 0.2616], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1903
agent= agent_5 distrib= tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7677, 0.2323], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1904
agent= agent_9 distrib= tensor([0.9332, 0.0668], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7648, 0.2352], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1905
agent= agent_9 distrib= tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8445, 0.1555], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1906
agent= agent_3 distrib= tensor([0.8663, 0.1337], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1907
agent= agent_1 distrib= tensor([0.8412, 0.1588], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1908
agent= agent_4 distrib= tensor([0.9421, 0.0579], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1909
agent= agent_1 distrib= tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7863, 0.2137], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1910
agent= agent_0 distrib= tensor([0.7657, 0.2343], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9426, 0.0574], grad_fn=<SoftmaxBackward0>)
Epoch : 1910 	 Measure: 0.699999988079071
==========>Epoch= 1911
agent= agent_9 distrib= tensor([0.9435, 0.0565], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1912
agent= agent_9 distrib= tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8682, 0.1318], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1913
agent= agent_8 distrib= tensor([0.6920, 0.3080], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7398, 0.2602], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1914
agent= agent_8 distrib= tensor([0.6316, 0.3684], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7680, 0.2320], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1915
agent= agent_8 distrib= tensor([0.6949, 0.3051], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7560, 0.2440], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1916
agent= agent_7 distrib= tensor([0.7892, 0.2108], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9302, 0.0698], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1917
agent= agent_1 distrib= tensor([0.8550, 0.1450], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6932, 0.3068], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1918
agent= agent_2 distrib= tensor([0.7683, 0.2317], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7416, 0.2584], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1919
agent= agent_6 distrib= tensor([0.7421, 0.2579], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1920
agent= agent_5 distrib= tensor([0.8717, 0.1283], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)
Epoch : 1920 	 Measure: 0.30000001192092896
==========>Epoch= 1921
agent= agent_8 distrib= tensor([0.6498, 0.3502], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7662, 0.2338], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1922
agent= agent_6 distrib= tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8700, 0.1300], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1923
agent= agent_3 distrib= tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7541, 0.2459], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1924
agent= agent_9 distrib= tensor([0.9311, 0.0689], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1925
agent= agent_8 distrib= tensor([0.6500, 0.3500], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1926
agent= agent_8 distrib= tensor([0.6501, 0.3499], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1927
agent= agent_4 distrib= tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7257, 0.2743], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1928
agent= agent_7 distrib= tensor([0.7912, 0.2088], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8444, 0.1556], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1929
agent= agent_6 distrib= tensor([0.7702, 0.2298], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9596, 0.0404], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1930
agent= agent_0 distrib= tensor([0.7264, 0.2736], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)
Epoch : 1930 	 Measure: 0.800000011920929
==========>Epoch= 1931
agent= agent_3 distrib= tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8459, 0.1541], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1932
agent= agent_4 distrib= tensor([0.9603, 0.0397], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1933
agent= agent_8 distrib= tensor([0.7080, 0.2920], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1934
agent= agent_7 distrib= tensor([0.7941, 0.2059], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7441, 0.2559], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1935
agent= agent_8 distrib= tensor([0.7084, 0.2916], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9452, 0.0548], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1936
agent= agent_1 distrib= tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.8182, 0.1818], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1937
agent= agent_4 distrib= tensor([0.9458, 0.0542], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1938
agent= agent_8 distrib= tensor([0.6515, 0.3485], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8613, 0.1387], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1939
agent= agent_0 distrib= tensor([0.7694, 0.2306], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9463, 0.0537], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1940
agent= agent_5 distrib= tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7534, 0.2466], grad_fn=<SoftmaxBackward0>)
Epoch : 1940 	 Measure: 0.4000000059604645
==========>Epoch= 1941
agent= agent_3 distrib= tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6947, 0.3053], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1942
agent= agent_7 distrib= tensor([0.7782, 0.2218], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7394, 0.2606], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1943
agent= agent_1 distrib= tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.7099, 0.2901], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1944
agent= agent_5 distrib= tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7702, 0.2298], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1945
agent= agent_2 distrib= tensor([0.7535, 0.2465], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1946
agent= agent_2 distrib= tensor([0.7405, 0.2595], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1947
agent= agent_0 distrib= tensor([0.7710, 0.2290], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9468, 0.0532], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1948
agent= agent_4 distrib= tensor([0.9473, 0.0527], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7719, 0.2281], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1949
agent= agent_0 distrib= tensor([0.7729, 0.2271], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1950
agent= agent_2 distrib= tensor([0.7698, 0.2302], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)
Epoch : 1950 	 Measure: 0.5
==========>Epoch= 1951
agent= agent_6 distrib= tensor([0.7723, 0.2277], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.8230, 0.1770], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1952
agent= agent_6 distrib= tensor([0.7369, 0.2631], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1953
agent= agent_4 distrib= tensor([0.9509, 0.0491], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1954
agent= agent_9 distrib= tensor([0.9315, 0.0685], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.9051, 0.0949], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1955
agent= agent_7 distrib= tensor([0.7833, 0.2167], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6542, 0.3458], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1956
agent= agent_0 distrib= tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9458, 0.0542], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1957
agent= agent_7 distrib= tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.6934, 0.3066], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1958
agent= agent_0 distrib= tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8496, 0.1504], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1959
agent= agent_1 distrib= tensor([0.8477, 0.1523], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1960
agent= agent_3 distrib= tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7708, 0.2292], grad_fn=<SoftmaxBackward0>)
Epoch : 1960 	 Measure: 0.699999988079071
==========>Epoch= 1961
agent= agent_7 distrib= tensor([0.8305, 0.1695], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8827, 0.1173], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1962
agent= agent_8 distrib= tensor([0.6363, 0.3637], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9514, 0.0486], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1963
agent= agent_0 distrib= tensor([0.7793, 0.2207], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1964
agent= agent_0 distrib= tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1965
agent= agent_8 distrib= tensor([0.6557, 0.3443], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8679, 0.1321], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1966
agent= agent_1 distrib= tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7557, 0.2443], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1967
agent= agent_6 distrib= tensor([0.7686, 0.2314], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7251, 0.2749], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1968
agent= agent_1 distrib= tensor([0.8515, 0.1485], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7409, 0.2591], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1969
agent= agent_5 distrib= tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1970
agent= agent_9 distrib= tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.7942, 0.2058], grad_fn=<SoftmaxBackward0>)
Epoch : 1970 	 Measure: 0.699999988079071
==========>Epoch= 1971
agent= agent_3 distrib= tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7456, 0.2544], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1972
agent= agent_0 distrib= tensor([0.7838, 0.2162], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.6379, 0.3621], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1973
agent= agent_5 distrib= tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9464, 0.0536], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1974
agent= agent_3 distrib= tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7609, 0.2391], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1975
agent= agent_3 distrib= tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7693, 0.2307], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1976
agent= agent_6 distrib= tensor([0.7754, 0.2246], grad_fn=<SoftmaxBackward0>)
agent= agent_1 distrib= tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1977
agent= agent_4 distrib= tensor([0.9518, 0.0482], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7267, 0.2733], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1978
agent= agent_1 distrib= tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1979
agent= agent_0 distrib= tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1980
agent= agent_1 distrib= tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)
Epoch : 1980 	 Measure: 0.30000001192092896
==========>Epoch= 1981
agent= agent_5 distrib= tensor([0.8628, 0.1372], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9521, 0.0479], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1982
agent= agent_9 distrib= tensor([0.9384, 0.0616], grad_fn=<SoftmaxBackward0>)
agent= agent_4 distrib= tensor([0.9525, 0.0475], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1983
agent= agent_8 distrib= tensor([0.7143, 0.2857], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1984
agent= agent_0 distrib= tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)
agent= agent_7 distrib= tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1985
agent= agent_3 distrib= tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.7152, 0.2848], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1986
agent= agent_3 distrib= tensor([0.8847, 0.1153], grad_fn=<SoftmaxBackward0>)
agent= agent_9 distrib= tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1987
agent= agent_9 distrib= tensor([0.9390, 0.0610], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1988
agent= agent_1 distrib= tensor([0.8550, 0.1450], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7530, 0.2470], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1989
agent= agent_7 distrib= tensor([0.8198, 0.1802], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1990
agent= agent_4 distrib= tensor([0.9528, 0.0472], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)
Epoch : 1990 	 Measure: 0.699999988079071
==========>Epoch= 1991
agent= agent_5 distrib= tensor([0.8650, 0.1350], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8886, 0.1114], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1992
agent= agent_5 distrib= tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)
agent= agent_0 distrib= tensor([0.7956, 0.2044], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1993
agent= agent_7 distrib= tensor([0.8419, 0.1581], grad_fn=<SoftmaxBackward0>)
agent= agent_8 distrib= tensor([0.7014, 0.2986], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1994
agent= agent_6 distrib= tensor([0.7492, 0.2508], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1995
agent= agent_5 distrib= tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1996
agent= agent_9 distrib= tensor([0.9393, 0.0607], grad_fn=<SoftmaxBackward0>)
agent= agent_3 distrib= tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1997
agent= agent_6 distrib= tensor([0.7405, 0.2595], grad_fn=<SoftmaxBackward0>)
agent= agent_5 distrib= tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1998
agent= agent_8 distrib= tensor([0.6994, 0.3006], grad_fn=<SoftmaxBackward0>)
agent= agent_6 distrib= tensor([0.7780, 0.2220], grad_fn=<SoftmaxBackward0>)
==========>Epoch= 1999
agent= agent_6 distrib= tensor([0.7517, 0.2483], grad_fn=<SoftmaxBackward0>)
agent= agent_2 distrib= tensor([0.7759, 0.2241], grad_fn=<SoftmaxBackward0>)